{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c88172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'python3.10' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# Create virtual environment\n",
    "python3.10 -m venv ear_seg_env\n",
    "\n",
    "# Activate it\n",
    "!ear_seg_env\\Scripts\\activate\n",
    "\n",
    "# Your prompt should change to show (ear_seg_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67301269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Ear-segmentation-ai'...\n"
     ]
    }
   ],
   "source": [
    "# 1. Clone and setup\n",
    "!git clone https://github.com/umitkacar/Ear-segmentation-ai\n",
    "!cd Ear-segmentation-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb2489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: earsegmentationai in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: imgviz<2.0.0,>=1.7.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (1.7.6)\n",
      "Requirement already satisfied: poethepoet<0.19.0,>=0.18.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.18.1)\n",
      "Requirement already satisfied: numpy==1.24.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (1.24.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.4.6)\n",
      "Requirement already satisfied: torchvision<0.15.0,>=0.14.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.14.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (4.67.1)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.13.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (1.13.1)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (8.3.0)\n",
      "Requirement already satisfied: pillow==9.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (9.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.7.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.7.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (2.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (2.32.5)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.9.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (13.9.4)\n",
      "Requirement already satisfied: opencv-python<5.0.0.0,>=4.6.0.66 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (4.11.0.86)\n",
      "Requirement already satisfied: segmentation-models-pytorch<0.4.0,>=0.3.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (0.3.4)\n",
      "Requirement already satisfied: albumentations<2.0.0,>=1.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (1.3.1)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.5.0.post1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from earsegmentationai) (1.5.4)\n",
      "Requirement already satisfied: PyYAML in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from albumentations<2.0.0,>=1.3.0->earsegmentationai) (6.0.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from albumentations<2.0.0,>=1.3.0->earsegmentationai) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from albumentations<2.0.0,>=1.3.0->earsegmentationai) (1.15.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from albumentations<2.0.0,>=1.3.0->earsegmentationai) (4.11.0.86)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from albumentations<2.0.0,>=1.3.0->earsegmentationai) (0.24.0)\n",
      "Requirement already satisfied: matplotlib in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from imgviz<2.0.0,>=1.7.2->earsegmentationai) (3.10.7)\n",
      "Requirement already satisfied: tomli>=1.2.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from poethepoet<0.19.0,>=0.18.1->earsegmentationai) (2.3.0)\n",
      "Requirement already satisfied: pastel<0.3.0,>=0.2.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from poethepoet<0.19.0,>=0.18.1->earsegmentationai) (0.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.2->earsegmentationai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.2->earsegmentationai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.2->earsegmentationai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.2->earsegmentationai) (2025.10.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich<14.0.0,>=13.3.1->earsegmentationai) (4.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich<14.0.0,>=13.3.1->earsegmentationai) (4.15.0)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (0.7.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (0.7.1)\n",
      "Requirement already satisfied: six in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (1.17.0)\n",
      "Requirement already satisfied: timm==0.9.7 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (0.9.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.6 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (0.36.0)\n",
      "Requirement already satisfied: munch in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (4.0.0)\n",
      "Requirement already satisfied: safetensors in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from timm==0.9.7->segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (0.6.2)\n",
      "Requirement already satisfied: filelock in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch<0.4.0,>=0.3.2->earsegmentationai) (25.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.3.1->earsegmentationai) (0.1.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from qudida>=0.0.4->albumentations<2.0.0,>=1.3.0->earsegmentationai) (1.7.2)\n",
      "Requirement already satisfied: networkx>=2.8 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations<2.0.0,>=1.3.0->earsegmentationai) (3.4.2)\n",
      "Requirement already satisfied: imageio>=2.33 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations<2.0.0,>=1.3.0->earsegmentationai) (2.37.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations<2.0.0,>=1.3.0->earsegmentationai) (0.4)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations<2.0.0,>=1.3.0->earsegmentationai) (2025.5.10)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (4.60.1)\n",
      "Requirement already satisfied: pyparsing>=3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (3.2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (1.4.9)\n",
      "Requirement already satisfied: cycler>=0.10 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib->imgviz<2.0.0,>=1.7.2->earsegmentationai) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<2.0.0,>=1.3.0->earsegmentationai) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<2.0.0,>=1.3.0->earsegmentationai) (1.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (2.12.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from pydantic) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from pydantic) (0.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typer in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (0.7.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "earsegmentationai 2.0.0 requires typer<0.8.0,>=0.7.0, but you have typer 0.20.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting typer\n",
      "  Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 30.7/47.0 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 30.7/47.0 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 30.7/47.0 kB ? eta -:--:--\n",
      "     --------------------------------- ---- 41.0/47.0 kB 196.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 47.0/47.0 kB 235.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer) (4.15.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer) (1.5.4)\n",
      "Requirement already satisfied: colorama in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from click) (0.4.6)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich>=10.11.0->typer) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich>=10.11.0->typer) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer) (0.1.2)\n",
      "Installing collected packages: typer\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "Successfully installed typer-0.20.0\n",
      "Requirement already satisfied: typer[all] in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: click>=8.0.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer[all]) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer[all]) (4.15.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer[all]) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer[all]) (1.5.4)\n",
      "Requirement already satisfied: colorama in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from click>=8.0.0->typer[all]) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich>=10.11.0->typer[all]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from rich>=10.11.0->typer[all]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: typer 0.20.0 does not provide the extra 'all'\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typer==0.9.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     -------------------------- ------------- 30.7/45.9 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 30.7/45.9 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 30.7/45.9 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 45.9/45.9 kB 228.3 kB/s eta 0:00:00\n",
      "Collecting click==8.1.7\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 41.0/97.9 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 61.4/97.9 kB 156.1 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 71.7/97.9 kB 71.4 kB/s eta 0:00:01\n",
      "     --------------------------------------- 97.9/97.9 kB 76.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from typer==0.9.0) (4.15.0)\n",
      "Requirement already satisfied: colorama in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from click==8.1.7) (0.4.6)\n",
      "Installing collected packages: click, typer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.3.0\n",
      "    Uninstalling click-8.3.0:\n",
      "      Successfully uninstalled click-8.3.0\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.20.0\n",
      "    Uninstalling typer-0.20.0:\n",
      "      Successfully uninstalled typer-0.20.0\n",
      "Successfully installed click-8.1.7 typer-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "earsegmentationai 2.0.0 requires typer<0.8.0,>=0.7.0, but you have typer 0.9.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Now install should work\n",
    "!pip install earsegmentationai\n",
    "!pip install pydantic\n",
    "!pip install --upgrade typer click\n",
    "!pip install typer[all]\n",
    "!pip install typer==0.9.0 click==8.1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a67153f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                               \n",
      " Usage: earsegmentationai [OPTIONS] COMMAND [ARGS]...                          \n",
      "                                                                               \n",
      " Ear Segmentation AI - Detect and segment ears in images and videos            \n",
      "                                                                               \n",
      "┌─ Options ───────────────────────────────────────────────────────────────────┐\n",
      "│ --install-completion          Install completion for the current shell.     │\n",
      "│ --show-completion             Show completion for the current shell, to     │\n",
      "│                               copy it or customize the installation.        │\n",
      "│ --help                        Show this message and exit.                   │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "┌─ Commands ──────────────────────────────────────────────────────────────────┐\n",
      "│ benchmark             Benchmark model performance.                          │\n",
      "│ download-model        Download the ear segmentation model.                  │\n",
      "│ picture-capture       Process image(s) for ear segmentation.                │\n",
      "│ process-image         Process image(s) for ear segmentation.                │\n",
      "│ process-video         Process video stream for ear segmentation.            │\n",
      "│ version               Show version information.                             │\n",
      "│ video-capture         Process video stream for ear segmentation.            │\n",
      "│ webcam                Real-time ear segmentation from webcam.               │\n",
      "│ webcam-capture        Real-time ear segmentation from webcam.               │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test installation\n",
    "!earsegmentationai --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f412c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ear segmentation model...\n",
      "✓ Model downloaded successfully!\n",
      "Model path: \n",
      "C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\earsegmentation_model_v1_46.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/25/25 23:15:05] INFO     ModelManager initialized                          \n",
      "                    INFO     Downloading model from                            \n",
      "                             https://github.com/umitkacar/Ear-segmentation-ai/r\n",
      "                             eleases/download/v1.0.0/earsegmentation_model_v1_4\n",
      "                             6.pth                                             \n",
      "\n",
      "Downloading model:   0%|          | 0.00/57.4M [00:00<?, ?B/s]\n",
      "Downloading model:   1%|          | 492k/57.4M [00:00<00:12, 4.67MB/s]\n",
      "Downloading model:   5%|▍         | 2.61M/57.4M [00:00<00:04, 12.9MB/s]\n",
      "Downloading model:   7%|▋         | 3.86M/57.4M [00:00<00:07, 7.48MB/s]\n",
      "Downloading model:   9%|▉         | 5.17M/57.4M [00:00<00:05, 8.97MB/s]\n",
      "Downloading model:  12%|█▏        | 6.65M/57.4M [00:00<00:04, 10.6MB/s]\n",
      "Downloading model:  18%|█▊        | 10.5M/57.4M [00:01<00:04, 9.94MB/s]\n",
      "Downloading model:  24%|██▍       | 14.0M/57.4M [00:01<00:03, 14.3MB/s]\n",
      "Downloading model:  28%|██▊       | 15.9M/57.4M [00:01<00:03, 11.4MB/s]\n",
      "Downloading model:  30%|███       | 17.4M/57.4M [00:01<00:04, 9.46MB/s]\n",
      "Downloading model:  32%|███▏      | 18.6M/57.4M [00:01<00:04, 8.84MB/s]\n",
      "Downloading model:  34%|███▍      | 19.7M/57.4M [00:02<00:04, 7.67MB/s]\n",
      "Downloading model:  36%|███▌      | 20.6M/57.4M [00:02<00:05, 7.03MB/s]\n",
      "Downloading model:  37%|███▋      | 21.4M/57.4M [00:02<00:05, 6.61MB/s]\n",
      "Downloading model:  38%|███▊      | 22.1M/57.4M [00:02<00:05, 6.21MB/s]\n",
      "Downloading model:  40%|███▉      | 22.7M/57.4M [00:02<00:05, 6.07MB/s]\n",
      "Downloading model:  41%|████      | 23.3M/57.4M [00:02<00:05, 6.00MB/s]\n",
      "Downloading model:  42%|████▏     | 23.9M/57.4M [00:02<00:05, 5.92MB/s]\n",
      "Downloading model:  43%|████▎     | 24.5M/57.4M [00:02<00:05, 5.81MB/s]\n",
      "Downloading model:  44%|████▍     | 25.1M/57.4M [00:03<00:05, 5.86MB/s]\n",
      "Downloading model:  45%|████▍     | 25.8M/57.4M [00:03<00:05, 5.98MB/s]\n",
      "Downloading model:  46%|████▌     | 26.4M/57.4M [00:03<00:05, 6.02MB/s]\n",
      "Downloading model:  47%|████▋     | 27.0M/57.4M [00:03<00:04, 6.13MB/s]\n",
      "Downloading model:  48%|████▊     | 27.7M/57.4M [00:03<00:04, 6.22MB/s]\n",
      "Downloading model:  49%|████▉     | 28.4M/57.4M [00:03<00:04, 6.30MB/s]\n",
      "Downloading model:  51%|█████     | 29.0M/57.4M [00:03<00:04, 6.39MB/s]\n",
      "Downloading model:  52%|█████▏    | 29.7M/57.4M [00:03<00:04, 6.50MB/s]\n",
      "Downloading model:  53%|█████▎    | 30.4M/57.4M [00:03<00:04, 6.56MB/s]\n",
      "Downloading model:  54%|█████▍    | 31.1M/57.4M [00:04<00:03, 6.65MB/s]\n",
      "Downloading model:  55%|█████▌    | 31.8M/57.4M [00:04<00:03, 6.75MB/s]\n",
      "Downloading model:  57%|█████▋    | 32.5M/57.4M [00:04<00:03, 6.84MB/s]\n",
      "Downloading model:  58%|█████▊    | 33.3M/57.4M [00:04<00:03, 6.95MB/s]\n",
      "Downloading model:  59%|█████▉    | 34.0M/57.4M [00:04<00:03, 7.02MB/s]\n",
      "Downloading model:  60%|██████    | 34.8M/57.4M [00:04<00:03, 7.14MB/s]\n",
      "Downloading model:  62%|██████▏   | 35.5M/57.4M [00:04<00:03, 7.03MB/s]\n",
      "Downloading model:  63%|██████▎   | 36.2M/57.4M [00:04<00:03, 6.72MB/s]\n",
      "Downloading model:  64%|██████▍   | 36.9M/57.4M [00:04<00:03, 6.75MB/s]\n",
      "Downloading model:  65%|██████▌   | 37.6M/57.4M [00:04<00:03, 6.38MB/s]\n",
      "Downloading model:  67%|██████▋   | 38.2M/57.4M [00:05<00:03, 6.07MB/s]\n",
      "Downloading model:  68%|██████▊   | 38.9M/57.4M [00:05<00:03, 6.06MB/s]\n",
      "Downloading model:  69%|██████▊   | 39.5M/57.4M [00:05<00:02, 6.05MB/s]\n",
      "Downloading model:  70%|██████▉   | 40.1M/57.4M [00:05<00:02, 5.98MB/s]\n",
      "Downloading model:  71%|███████   | 40.7M/57.4M [00:05<00:02, 6.02MB/s]\n",
      "Downloading model:  72%|███████▏  | 41.4M/57.4M [00:05<00:02, 6.10MB/s]\n",
      "Downloading model:  73%|███████▎  | 42.0M/57.4M [00:05<00:02, 6.18MB/s]\n",
      "Downloading model:  74%|███████▍  | 42.6M/57.4M [00:05<00:02, 6.28MB/s]\n",
      "Downloading model:  75%|███████▌  | 43.3M/57.4M [00:05<00:02, 6.32MB/s]\n",
      "Downloading model:  77%|███████▋  | 44.0M/57.4M [00:06<00:02, 6.43MB/s]\n",
      "Downloading model:  78%|███████▊  | 44.6M/57.4M [00:06<00:01, 6.46MB/s]\n",
      "Downloading model:  79%|███████▉  | 45.3M/57.4M [00:06<00:01, 6.54MB/s]\n",
      "Downloading model:  80%|████████  | 46.0M/57.4M [00:06<00:01, 6.65MB/s]\n",
      "Downloading model:  81%|████████▏ | 46.7M/57.4M [00:06<00:01, 6.75MB/s]\n",
      "Downloading model:  83%|████████▎ | 47.4M/57.4M [00:06<00:01, 6.33MB/s]\n",
      "Downloading model:  84%|████████▎ | 48.0M/57.4M [00:06<00:01, 5.73MB/s]\n",
      "Downloading model:  85%|████████▍ | 48.6M/57.4M [00:06<00:01, 5.51MB/s]\n",
      "Downloading model:  86%|████████▌ | 49.2M/57.4M [00:06<00:01, 5.40MB/s]\n",
      "Downloading model:  87%|████████▋ | 49.7M/57.4M [00:07<00:01, 5.41MB/s]\n",
      "Downloading model:  88%|████████▊ | 50.3M/57.4M [00:07<00:01, 5.36MB/s]\n",
      "Downloading model:  89%|████████▊ | 50.8M/57.4M [00:07<00:01, 5.39MB/s]\n",
      "Downloading model:  89%|████████▉ | 51.4M/57.4M [00:07<00:01, 5.37MB/s]\n",
      "Downloading model:  90%|█████████ | 52.0M/57.4M [00:07<00:01, 5.44MB/s]\n",
      "Downloading model:  91%|█████████▏| 52.6M/57.4M [00:07<00:00, 5.54MB/s]\n",
      "Downloading model:  92%|█████████▏| 53.1M/57.4M [00:07<00:00, 5.51MB/s]\n",
      "Downloading model:  93%|█████████▎| 53.7M/57.4M [00:07<00:00, 5.59MB/s]\n",
      "Downloading model:  94%|█████████▍| 54.3M/57.4M [00:07<00:00, 5.53MB/s]\n",
      "Downloading model:  96%|█████████▌| 55.0M/57.4M [00:07<00:00, 5.91MB/s]\n",
      "Downloading model:  97%|█████████▋| 55.6M/57.4M [00:08<00:00, 5.94MB/s]\n",
      "Downloading model:  98%|█████████▊| 56.2M/57.4M [00:08<00:00, 6.04MB/s]\n",
      "Downloading model:  99%|█████████▉| 56.9M/57.4M [00:08<00:00, 6.19MB/s]\n",
      "Downloading model: 100%|██████████| 57.4M/57.4M [00:08<00:00, 6.90MB/s]\n",
      "[10/25/25 23:15:14] INFO     Model downloaded successfully to                  \n",
      "                             C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\ear\n",
      "                             segmentation_model_v1_46.pth                      \n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\Trise/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n",
      "\n",
      "  0%|          | 0.00/44.7M [00:00<?, ?B/s]\n",
      "  2%|▏         | 0.98M/44.7M [00:00<00:05, 8.93MB/s]\n",
      "  7%|▋         | 3.31M/44.7M [00:00<00:02, 17.0MB/s]\n",
      " 11%|█         | 4.96M/44.7M [00:00<00:03, 11.7MB/s]\n",
      " 14%|█▍        | 6.22M/44.7M [00:00<00:03, 10.3MB/s]\n",
      " 16%|█▋        | 7.29M/44.7M [00:00<00:04, 8.60MB/s]\n",
      " 18%|█▊        | 8.19M/44.7M [00:00<00:04, 7.77MB/s]\n",
      " 20%|██        | 8.98M/44.7M [00:01<00:05, 7.15MB/s]\n",
      " 22%|██▏       | 9.69M/44.7M [00:01<00:05, 6.97MB/s]\n",
      " 23%|██▎       | 10.4M/44.7M [00:01<00:05, 6.76MB/s]\n",
      " 25%|██▍       | 11.0M/44.7M [00:01<00:05, 6.55MB/s]\n",
      " 26%|██▌       | 11.7M/44.7M [00:01<00:05, 6.44MB/s]\n",
      " 28%|██▊       | 12.4M/44.7M [00:01<00:05, 6.73MB/s]\n",
      " 29%|██▉       | 13.0M/44.7M [00:01<00:06, 5.23MB/s]\n",
      " 32%|███▏      | 14.3M/44.7M [00:01<00:04, 7.19MB/s]\n",
      " 34%|███▍      | 15.1M/44.7M [00:02<00:04, 6.86MB/s]\n",
      " 35%|███▌      | 15.8M/44.7M [00:02<00:04, 6.67MB/s]\n",
      " 37%|███▋      | 16.5M/44.7M [00:02<00:04, 6.54MB/s]\n",
      " 38%|███▊      | 17.2M/44.7M [00:02<00:04, 6.43MB/s]\n",
      " 40%|███▉      | 17.8M/44.7M [00:02<00:04, 6.34MB/s]\n",
      " 41%|████▏     | 18.4M/44.7M [00:02<00:04, 6.31MB/s]\n",
      " 43%|████▎     | 19.0M/44.7M [00:02<00:04, 6.28MB/s]\n",
      " 44%|████▍     | 19.6M/44.7M [00:02<00:04, 6.25MB/s]\n",
      " 46%|████▌     | 20.3M/44.7M [00:02<00:03, 6.48MB/s]\n",
      " 47%|████▋     | 21.0M/44.7M [00:03<00:04, 6.19MB/s]\n",
      " 48%|████▊     | 21.6M/44.7M [00:03<00:03, 6.44MB/s]\n",
      " 50%|████▉     | 22.3M/44.7M [00:03<00:03, 6.37MB/s]\n",
      " 51%|█████     | 22.9M/44.7M [00:03<00:03, 6.32MB/s]\n",
      " 53%|█████▎    | 23.5M/44.7M [00:03<00:03, 6.29MB/s]\n",
      " 54%|█████▍    | 24.1M/44.7M [00:03<00:03, 6.23MB/s]\n",
      " 55%|█████▌    | 24.7M/44.7M [00:03<00:03, 6.24MB/s]\n",
      " 57%|█████▋    | 25.3M/44.7M [00:03<00:03, 6.19MB/s]\n",
      " 58%|█████▊    | 25.9M/44.7M [00:03<00:03, 6.19MB/s]\n",
      " 59%|█████▉    | 26.5M/44.7M [00:03<00:03, 6.20MB/s]\n",
      " 61%|██████    | 27.1M/44.7M [00:04<00:02, 6.18MB/s]\n",
      " 62%|██████▏   | 27.7M/44.7M [00:04<00:02, 6.10MB/s]\n",
      " 63%|██████▎   | 28.3M/44.7M [00:04<00:02, 6.22MB/s]\n",
      " 65%|██████▍   | 29.0M/44.7M [00:04<00:02, 6.48MB/s]\n",
      " 66%|██████▋   | 29.6M/44.7M [00:04<00:02, 6.43MB/s]\n",
      " 68%|██████▊   | 30.3M/44.7M [00:04<00:02, 6.41MB/s]\n",
      " 69%|██████▉   | 30.9M/44.7M [00:04<00:02, 6.36MB/s]\n",
      " 71%|███████   | 31.5M/44.7M [00:04<00:02, 6.29MB/s]\n",
      " 72%|███████▏  | 32.1M/44.7M [00:04<00:02, 6.31MB/s]\n",
      " 73%|███████▎  | 32.7M/44.7M [00:05<00:01, 6.29MB/s]\n",
      " 75%|███████▍  | 33.3M/44.7M [00:05<00:01, 6.29MB/s]\n",
      " 76%|███████▌  | 33.9M/44.7M [00:05<00:01, 6.26MB/s]\n",
      " 77%|███████▋  | 34.5M/44.7M [00:05<00:01, 6.29MB/s]\n",
      " 79%|███████▊  | 35.1M/44.7M [00:05<00:01, 6.22MB/s]\n",
      " 80%|████████  | 35.7M/44.7M [00:05<00:01, 6.27MB/s]\n",
      " 81%|████████▏ | 36.3M/44.7M [00:05<00:01, 5.98MB/s]\n",
      " 83%|████████▎ | 37.0M/44.7M [00:05<00:01, 6.34MB/s]\n",
      " 84%|████████▍ | 37.6M/44.7M [00:05<00:01, 6.03MB/s]\n",
      " 86%|████████▌ | 38.2M/44.7M [00:05<00:01, 6.09MB/s]\n",
      " 87%|████████▋ | 38.9M/44.7M [00:06<00:00, 6.14MB/s]\n",
      " 88%|████████▊ | 39.5M/44.7M [00:06<00:00, 6.18MB/s]\n",
      " 90%|████████▉ | 40.1M/44.7M [00:06<00:00, 6.14MB/s]\n",
      " 91%|█████████ | 40.7M/44.7M [00:06<00:00, 6.11MB/s]\n",
      " 92%|█████████▏| 41.3M/44.7M [00:06<00:00, 6.02MB/s]\n",
      " 94%|█████████▍| 42.0M/44.7M [00:06<00:00, 6.24MB/s]\n",
      " 96%|█████████▌| 42.7M/44.7M [00:06<00:00, 6.22MB/s]\n",
      " 97%|█████████▋| 43.4M/44.7M [00:06<00:00, 6.31MB/s]\n",
      " 98%|█████████▊| 44.0M/44.7M [00:06<00:00, 6.31MB/s]\n",
      "100%|█████████▉| 44.6M/44.7M [00:07<00:00, 6.28MB/s]\n",
      "100%|██████████| 44.7M/44.7M [00:07<00:00, 6.66MB/s]\n",
      "[10/25/25 23:15:22] INFO     Created Unet model with resnet18 encoder          \n",
      "                    INFO     Loading model weights from                        \n",
      "                             C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\ear\n",
      "                             segmentation_model_v1_46.pth                      \n",
      "                    WARNING  CUDA not available, falling back to CPU           \n",
      "                    WARNING  Loading legacy model format                       \n",
      "                    INFO     Model loaded successfully                         \n"
     ]
    }
   ],
   "source": [
    "!earsegmentationai download-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f62e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⠋ Initializing model...\n",
      "⠙ Initializing model...\n",
      "⠙ Initializing model...\n",
      "\n",
      "Processing: input\n",
      "           Processing Results           \n",
      "┌──────────────┬──────────────┬────────┐\n",
      "│ File         │ Ear Detected │ Area % │\n",
      "├──────────────┼──────────────┼────────┤\n",
      "│ 2D EAR 1.jpg │ ✗            │ -      │\n",
      "│ 2D EAR 2.jpg │ ✓            │ 1.7    │\n",
      "│ 2D EAR 3.jpg │ ✓            │ 13.2   │\n",
      "│ 2D EAR 4.jpg │ ✓            │ 9.2    │\n",
      "│ 2D EAR 5.jpg │ ✓            │ 11.9   │\n",
      "└──────────────┴──────────────┴────────┘\n",
      "\n",
      "Summary:\n",
      "Total images: 5\n",
      "Detection rate: 80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/25/25 23:16:51] INFO     ModelManager initialized                          \n",
      "                    INFO     EarPredictor initialized with threshold=0.5       \n",
      "                    INFO     ImageProcessor initialized with device=cpu        \n",
      "                    INFO     Processing 5 images from input                    \n",
      "                    INFO     Running batch prediction on 5 images              \n",
      "[10/25/25 23:16:52] INFO     Created Unet model with resnet18 encoder          \n",
      "                    INFO     Loading model weights from                        \n",
      "                             C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\ear\n",
      "                             segmentation_model_v1_46.pth                      \n",
      "                    WARNING  Loading legacy model format                       \n",
      "                    INFO     Model loaded successfully                         \n",
      "[10/25/25 23:16:53] INFO     Batch processing complete. Detection rate: 80.0%  \n"
     ]
    }
   ],
   "source": [
    "# Process all images in a directory\n",
    "!earsegmentationai process-image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64ba299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⠋ Initializing model...\n",
      "⠙ Initializing model...\n",
      "⠙ Initializing model...\n",
      "\n",
      "No output directory specified, using: a:\\PROJECT\\AUTO \n",
      "MICROTIA\\Ear-segmentation-ai\\output\n",
      "Processing: input\n",
      "           Processing Results           \n",
      "┌──────────────┬──────────────┬────────┐\n",
      "│ File         │ Ear Detected │ Area % │\n",
      "├──────────────┼──────────────┼────────┤\n",
      "│ 2D EAR 1.jpg │ ✗            │ -      │\n",
      "│ 2D EAR 2.jpg │ ✓            │ 1.7    │\n",
      "│ 2D EAR 3.jpg │ ✓            │ 13.2   │\n",
      "│ 2D EAR 4.jpg │ ✓            │ 9.2    │\n",
      "│ 2D EAR 5.jpg │ ✓            │ 11.9   │\n",
      "└──────────────┴──────────────┴────────┘\n",
      "\n",
      "Summary:\n",
      "Total images: 5\n",
      "Detection rate: 80.0%\n",
      "\n",
      "Results saved to: a:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/26/25 09:55:55] INFO     ModelManager initialized                          \n",
      "                    INFO     EarPredictor initialized with threshold=0.5       \n",
      "                    INFO     ImageProcessor initialized with device=cpu        \n",
      "                    INFO     Processing 5 images from input                    \n",
      "                    INFO     Running batch prediction on 5 images              \n",
      "[10/26/25 09:55:56] INFO     Created Unet model with resnet18 encoder          \n",
      "                    INFO     Loading model weights from                        \n",
      "                             C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\ear\n",
      "                             segmentation_model_v1_46.pth                      \n",
      "                    WARNING  Loading legacy model format                       \n",
      "                    INFO     Model loaded successfully                         \n",
      "[10/26/25 09:55:58] INFO     Saved batch results to a:\\PROJECT\\AUTO            \n",
      "                             MICROTIA\\Ear-segmentation-ai\\output               \n",
      "                    INFO     Batch processing complete. Detection rate: 80.0%  \n"
     ]
    }
   ],
   "source": [
    "# Process with visualization\n",
    "!earsegmentationai process-image input --save-viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4942253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⠋ Initializing model...\n",
      "⠙ Initializing model...\n",
      "⠙ Initializing model...\n",
      "\n",
      "Processing: input_2\n",
      "            Processing Results             \n",
      "┌─────────────────┬──────────────┬────────┐\n",
      "│ File            │ Ear Detected │ Area % │\n",
      "├─────────────────┼──────────────┼────────┤\n",
      "│ 100gr (10).png  │ ✗            │ -      │\n",
      "│ 100gr (11).png  │ ✗            │ -      │\n",
      "│ 100gr (12).png  │ ✗            │ -      │\n",
      "│ 100gr (13).png  │ ✗            │ -      │\n",
      "│ 100gr (2).png   │ ✗            │ -      │\n",
      "│ 100gr (3).png   │ ✓            │ 1.2    │\n",
      "│ 100gr (4).png   │ ✗            │ -      │\n",
      "│ 100gr (5).png   │ ✗            │ -      │\n",
      "│ 100gr (6).png   │ ✗            │ -      │\n",
      "│ 100gr (7).png   │ ✗            │ -      │\n",
      "│ 100gr (8).png   │ ✗            │ -      │\n",
      "│ 100gr (9).png   │ ✗            │ -      │\n",
      "│ 100gr.png       │ ✗            │ -      │\n",
      "│ 100rfb (10).png │ ✓            │ 0.1    │\n",
      "│ 100rfb (11).png │ ✗            │ -      │\n",
      "│ 100rfb (12).png │ ✗            │ -      │\n",
      "│ 100rfb (13).png │ ✗            │ -      │\n",
      "│ 100rfb (2).png  │ ✓            │ 0.3    │\n",
      "│ 100rfb (3).png  │ ✗            │ -      │\n",
      "│ 100rfb (4).png  │ ✗            │ -      │\n",
      "│ 100rfb (5).png  │ ✗            │ -      │\n",
      "│ 100rfb (6).png  │ ✗            │ -      │\n",
      "│ 100rfb (7).png  │ ✗            │ -      │\n",
      "│ 100rfb (8).png  │ ✗            │ -      │\n",
      "│ 100rfb (9).png  │ ✗            │ -      │\n",
      "│ 100rfb.png      │ ✗            │ -      │\n",
      "│ 81gr (10).png   │ ✗            │ -      │\n",
      "│ 81gr (11).png   │ ✗            │ -      │\n",
      "│ 81gr (12).png   │ ✗            │ -      │\n",
      "│ 81gr (13).png   │ ✗            │ -      │\n",
      "│ 81gr (2).png    │ ✓            │ 3.0    │\n",
      "│ 81gr (3).png    │ ✗            │ -      │\n",
      "│ 81gr (4).png    │ ✗            │ -      │\n",
      "│ 81gr (5).png    │ ✗            │ -      │\n",
      "│ 81gr (6).png    │ ✗            │ -      │\n",
      "│ 81gr (7).png    │ ✗            │ -      │\n",
      "│ 81gr (8).png    │ ✓            │ 0.1    │\n",
      "│ 81gr (9).png    │ ✗            │ -      │\n",
      "│ 81gr.png        │ ✗            │ -      │\n",
      "│ 81rfb (10).png  │ ✗            │ -      │\n",
      "│ 81rfb (11).png  │ ✗            │ -      │\n",
      "│ 81rfb (12).png  │ ✓            │ 2.4    │\n",
      "│ 81rfb (13).png  │ ✗            │ -      │\n",
      "│ 81rfb (2).png   │ ✓            │ 0.9    │\n",
      "│ 81rfb (3).png   │ ✗            │ -      │\n",
      "│ 81rfb (4).png   │ ✗            │ -      │\n",
      "│ 81rfb (5).png   │ ✗            │ -      │\n",
      "│ 81rfb (6).png   │ ✓            │ 3.6    │\n",
      "│ 81rfb (7).png   │ ✗            │ -      │\n",
      "│ 81rfb (8).png   │ ✗            │ -      │\n",
      "│ 81rfb (9).png   │ ✗            │ -      │\n",
      "│ 81rfb.png       │ ✗            │ -      │\n",
      "│ 82gr (10).png   │ ✗            │ -      │\n",
      "│ 82gr (11).png   │ ✗            │ -      │\n",
      "│ 82gr (12).png   │ ✗            │ -      │\n",
      "│ 82gr (13).png   │ ✗            │ -      │\n",
      "│ 82gr (2).png    │ ✓            │ 3.5    │\n",
      "│ 82gr (3).png    │ ✗            │ -      │\n",
      "│ 82gr (4).png    │ ✗            │ -      │\n",
      "│ 82gr (5).png    │ ✗            │ -      │\n",
      "│ 82gr (6).png    │ ✗            │ -      │\n",
      "│ 82gr (7).png    │ ✗            │ -      │\n",
      "│ 82gr (8).png    │ ✓            │ 1.0    │\n",
      "│ 82gr (9).png    │ ✗            │ -      │\n",
      "│ 82gr.png        │ ✗            │ -      │\n",
      "│ 82rfb (10).png  │ ✗            │ -      │\n",
      "│ 82rfb (11).png  │ ✗            │ -      │\n",
      "│ 82rfb (12).png  │ ✗            │ -      │\n",
      "│ 82rfb (13).png  │ ✗            │ -      │\n",
      "│ 82rfb (2).png   │ ✓            │ 3.1    │\n",
      "│ 82rfb (3).png   │ ✗            │ -      │\n",
      "│ 82rfb (4).png   │ ✗            │ -      │\n",
      "│ 82rfb (5).png   │ ✗            │ -      │\n",
      "│ 82rfb (6).png   │ ✗            │ -      │\n",
      "│ 82rfb (7).png   │ ✗            │ -      │\n",
      "│ 82rfb (8).png   │ ✓            │ 0.0    │\n",
      "│ 82rfb (9).png   │ ✗            │ -      │\n",
      "│ 82rfb.png       │ ✗            │ -      │\n",
      "│ 83gr (10).png   │ ✗            │ -      │\n",
      "│ 83gr (11).png   │ ✗            │ -      │\n",
      "│ 83gr (12).png   │ ✗            │ -      │\n",
      "│ 83gr (13).png   │ ✗            │ -      │\n",
      "│ 83gr (2).png    │ ✗            │ -      │\n",
      "│ 83gr (3).png    │ ✗            │ -      │\n",
      "│ 83gr (4).png    │ ✗            │ -      │\n",
      "│ 83gr (5).png    │ ✗            │ -      │\n",
      "│ 83gr (6).png    │ ✗            │ -      │\n",
      "│ 83gr (7).png    │ ✗            │ -      │\n",
      "│ 83gr (8).png    │ ✗            │ -      │\n",
      "│ 83gr (9).png    │ ✗            │ -      │\n",
      "│ 83gr.png        │ ✗            │ -      │\n",
      "│ 83rfb (10).png  │ ✗            │ -      │\n",
      "│ 83rfb (11).png  │ ✗            │ -      │\n",
      "│ 83rfb (12).png  │ ✗            │ -      │\n",
      "│ 83rfb (13).png  │ ✗            │ -      │\n",
      "│ 83rfb (2).png   │ ✗            │ -      │\n",
      "│ 83rfb (3).png   │ ✗            │ -      │\n",
      "│ 83rfb (4).png   │ ✗            │ -      │\n",
      "│ 83rfb (5).png   │ ✗            │ -      │\n",
      "│ 83rfb (6).png   │ ✗            │ -      │\n",
      "│ 83rfb (7).png   │ ✗            │ -      │\n",
      "│ 83rfb (8).png   │ ✗            │ -      │\n",
      "│ 83rfb (9).png   │ ✗            │ -      │\n",
      "│ 83rfb.png       │ ✗            │ -      │\n",
      "│ 84gr (10).png   │ ✗            │ -      │\n",
      "│ 84gr (11).png   │ ✗            │ -      │\n",
      "│ 84gr (12).png   │ ✗            │ -      │\n",
      "│ 84gr (13).png   │ ✗            │ -      │\n",
      "│ 84gr (2).png    │ ✗            │ -      │\n",
      "│ 84gr (3).png    │ ✗            │ -      │\n",
      "│ 84gr (4).png    │ ✗            │ -      │\n",
      "│ 84gr (5).png    │ ✗            │ -      │\n",
      "│ 84gr (6).png    │ ✗            │ -      │\n",
      "│ 84gr (7).png    │ ✗            │ -      │\n",
      "│ 84gr (8).png    │ ✗            │ -      │\n",
      "│ 84gr (9).png    │ ✗            │ -      │\n",
      "│ 84gr.png        │ ✗            │ -      │\n",
      "│ 84rfb (10).png  │ ✗            │ -      │\n",
      "│ 84rfb (11).png  │ ✗            │ -      │\n",
      "│ 84rfb (12).png  │ ✗            │ -      │\n",
      "│ 84rfb (13).png  │ ✓            │ 0.8    │\n",
      "│ 84rfb (2).png   │ ✗            │ -      │\n",
      "│ 84rfb (3).png   │ ✗            │ -      │\n",
      "│ 84rfb (4).png   │ ✗            │ -      │\n",
      "│ 84rfb (5).png   │ ✓            │ 0.3    │\n",
      "│ 84rfb (6).png   │ ✗            │ -      │\n",
      "│ 84rfb (7).png   │ ✗            │ -      │\n",
      "│ 84rfb (8).png   │ ✗            │ -      │\n",
      "│ 84rfb (9).png   │ ✗            │ -      │\n",
      "│ 84rfb.png       │ ✗            │ -      │\n",
      "│ 85gr (10).png   │ ✗            │ -      │\n",
      "│ 85gr (11).png   │ ✗            │ -      │\n",
      "│ 85gr (12).png   │ ✗            │ -      │\n",
      "│ 85gr (13).png   │ ✗            │ -      │\n",
      "│ 85gr (2).png    │ ✗            │ -      │\n",
      "│ 85gr (3).png    │ ✗            │ -      │\n",
      "│ 85gr (4).png    │ ✗            │ -      │\n",
      "│ 85gr (5).png    │ ✗            │ -      │\n",
      "│ 85gr (6).png    │ ✗            │ -      │\n",
      "│ 85gr (7).png    │ ✗            │ -      │\n",
      "│ 85gr (8).png    │ ✗            │ -      │\n",
      "│ 85gr (9).png    │ ✗            │ -      │\n",
      "│ 85gr.png        │ ✓            │ 0.0    │\n",
      "│ 85rfb (10).png  │ ✗            │ -      │\n",
      "│ 85rfb (11).png  │ ✗            │ -      │\n",
      "│ 85rfb (12).png  │ ✗            │ -      │\n",
      "│ 85rfb (13).png  │ ✗            │ -      │\n",
      "│ 85rfb (2).png   │ ✗            │ -      │\n",
      "│ 85rfb (3).png   │ ✗            │ -      │\n",
      "│ 85rfb (4).png   │ ✗            │ -      │\n",
      "│ 85rfb (5).png   │ ✗            │ -      │\n",
      "│ 85rfb (6).png   │ ✗            │ -      │\n",
      "│ 85rfb (7).png   │ ✗            │ -      │\n",
      "│ 85rfb (8).png   │ ✗            │ -      │\n",
      "│ 85rfb (9).png   │ ✗            │ -      │\n",
      "│ 85rfb.png       │ ✓            │ 0.2    │\n",
      "│ 86gr (10).png   │ ✗            │ -      │\n",
      "│ 86gr (11).png   │ ✗            │ -      │\n",
      "│ 86gr (12).png   │ ✗            │ -      │\n",
      "│ 86gr (13).png   │ ✗            │ -      │\n",
      "│ 86gr (2).png    │ ✗            │ -      │\n",
      "│ 86gr (3).png    │ ✗            │ -      │\n",
      "│ 86gr (4).png    │ ✗            │ -      │\n",
      "│ 86gr (5).png    │ ✗            │ -      │\n",
      "│ 86gr (6).png    │ ✗            │ -      │\n",
      "│ 86gr (7).png    │ ✗            │ -      │\n",
      "│ 86gr (8).png    │ ✗            │ -      │\n",
      "│ 86gr (9).png    │ ✗            │ -      │\n",
      "│ 86gr.png        │ ✗            │ -      │\n",
      "│ 86rfb (10).png  │ ✗            │ -      │\n",
      "│ 86rfb (11).png  │ ✗            │ -      │\n",
      "│ 86rfb (12).png  │ ✗            │ -      │\n",
      "│ 86rfb (13).png  │ ✗            │ -      │\n",
      "│ 86rfb (2).png   │ ✗            │ -      │\n",
      "│ 86rfb (3).png   │ ✗            │ -      │\n",
      "│ 86rfb (4).png   │ ✗            │ -      │\n",
      "│ 86rfb (5).png   │ ✗            │ -      │\n",
      "│ 86rfb (6).png   │ ✗            │ -      │\n",
      "│ 86rfb (7).png   │ ✗            │ -      │\n",
      "│ 86rfb (8).png   │ ✗            │ -      │\n",
      "│ 86rfb (9).png   │ ✗            │ -      │\n",
      "│ 86rfb.png       │ ✗            │ -      │\n",
      "│ 87gr (10).png   │ ✗            │ -      │\n",
      "│ 87gr (11).png   │ ✗            │ -      │\n",
      "│ 87gr (12).png   │ ✗            │ -      │\n",
      "│ 87gr (13).png   │ ✗            │ -      │\n",
      "│ 87gr (2).png    │ ✗            │ -      │\n",
      "│ 87gr (3).png    │ ✗            │ -      │\n",
      "│ 87gr (4).png    │ ✗            │ -      │\n",
      "│ 87gr (5).png    │ ✓            │ 2.4    │\n",
      "│ 87gr (6).png    │ ✗            │ -      │\n",
      "│ 87gr (7).png    │ ✗            │ -      │\n",
      "│ 87gr (8).png    │ ✗            │ -      │\n",
      "│ 87gr (9).png    │ ✗            │ -      │\n",
      "│ 87gr.png        │ ✗            │ -      │\n",
      "│ 87rfb (10).png  │ ✗            │ -      │\n",
      "│ 87rfb (11).png  │ ✗            │ -      │\n",
      "│ 87rfb (12).png  │ ✗            │ -      │\n",
      "│ 87rfb (13).png  │ ✗            │ -      │\n",
      "│ 87rfb (2).png   │ ✗            │ -      │\n",
      "│ 87rfb (3).png   │ ✓            │ 0.7    │\n",
      "│ 87rfb (4).png   │ ✗            │ -      │\n",
      "│ 87rfb (5).png   │ ✓            │ 4.6    │\n",
      "│ 87rfb (6).png   │ ✗            │ -      │\n",
      "│ 87rfb (7).png   │ ✗            │ -      │\n",
      "│ 87rfb (8).png   │ ✗            │ -      │\n",
      "│ 87rfb (9).png   │ ✗            │ -      │\n",
      "│ 87rfb.png       │ ✗            │ -      │\n",
      "│ 88gr (10).png   │ ✗            │ -      │\n",
      "│ 88gr (11).png   │ ✗            │ -      │\n",
      "│ 88gr (12).png   │ ✗            │ -      │\n",
      "│ 88gr (13).png   │ ✗            │ -      │\n",
      "│ 88gr (2).png    │ ✗            │ -      │\n",
      "│ 88gr (3).png    │ ✗            │ -      │\n",
      "│ 88gr (4).png    │ ✗            │ -      │\n",
      "│ 88gr (5).png    │ ✗            │ -      │\n",
      "│ 88gr (6).png    │ ✗            │ -      │\n",
      "│ 88gr (7).png    │ ✗            │ -      │\n",
      "│ 88gr (8).png    │ ✗            │ -      │\n",
      "│ 88gr (9).png    │ ✗            │ -      │\n",
      "│ 88gr.png        │ ✗            │ -      │\n",
      "│ 88rfb (10).png  │ ✗            │ -      │\n",
      "│ 88rfb (11).png  │ ✗            │ -      │\n",
      "│ 88rfb (12).png  │ ✗            │ -      │\n",
      "│ 88rfb (13).png  │ ✗            │ -      │\n",
      "│ 88rfb (2).png   │ ✗            │ -      │\n",
      "│ 88rfb (3).png   │ ✗            │ -      │\n",
      "│ 88rfb (4).png   │ ✗            │ -      │\n",
      "│ 88rfb (5).png   │ ✗            │ -      │\n",
      "│ 88rfb (6).png   │ ✗            │ -      │\n",
      "│ 88rfb (7).png   │ ✗            │ -      │\n",
      "│ 88rfb (8).png   │ ✗            │ -      │\n",
      "│ 88rfb (9).png   │ ✗            │ -      │\n",
      "│ 88rfb.png       │ ✗            │ -      │\n",
      "│ 89gr (10).png   │ ✗            │ -      │\n",
      "│ 89gr (11).png   │ ✗            │ -      │\n",
      "│ 89gr (12).png   │ ✗            │ -      │\n",
      "│ 89gr (13).png   │ ✗            │ -      │\n",
      "│ 89gr (2).png    │ ✓            │ 7.0    │\n",
      "│ 89gr (3).png    │ ✗            │ -      │\n",
      "│ 89gr (4).png    │ ✗            │ -      │\n",
      "│ 89gr (5).png    │ ✗            │ -      │\n",
      "│ 89gr (6).png    │ ✗            │ -      │\n",
      "│ 89gr (7).png    │ ✓            │ 0.3    │\n",
      "│ 89gr (8).png    │ ✗            │ -      │\n",
      "│ 89gr (9).png    │ ✗            │ -      │\n",
      "│ 89gr.png        │ ✗            │ -      │\n",
      "│ 89rfb (10).png  │ ✗            │ -      │\n",
      "│ 89rfb (11).png  │ ✗            │ -      │\n",
      "│ 89rfb (12).png  │ ✗            │ -      │\n",
      "│ 89rfb (13).png  │ ✗            │ -      │\n",
      "│ 89rfb (2).png   │ ✓            │ 8.5    │\n",
      "│ 89rfb (3).png   │ ✗            │ -      │\n",
      "│ 89rfb (4).png   │ ✗            │ -      │\n",
      "│ 89rfb (5).png   │ ✗            │ -      │\n",
      "│ 89rfb (6).png   │ ✗            │ -      │\n",
      "│ 89rfb (7).png   │ ✗            │ -      │\n",
      "│ 89rfb (8).png   │ ✗            │ -      │\n",
      "│ 89rfb (9).png   │ ✗            │ -      │\n",
      "│ 89rfb.png       │ ✗            │ -      │\n",
      "│ 90gr (10).png   │ ✗            │ -      │\n",
      "│ 90gr (11).png   │ ✗            │ -      │\n",
      "│ 90gr (12).png   │ ✗            │ -      │\n",
      "│ 90gr (13).png   │ ✗            │ -      │\n",
      "│ 90gr (2).png    │ ✗            │ -      │\n",
      "│ 90gr (3).png    │ ✗            │ -      │\n",
      "│ 90gr (4).png    │ ✗            │ -      │\n",
      "│ 90gr (5).png    │ ✗            │ -      │\n",
      "│ 90gr (6).png    │ ✗            │ -      │\n",
      "│ 90gr (7).png    │ ✗            │ -      │\n",
      "│ 90gr (8).png    │ ✗            │ -      │\n",
      "│ 90gr (9).png    │ ✗            │ -      │\n",
      "│ 90gr.png        │ ✗            │ -      │\n",
      "│ 90rfb (10).png  │ ✗            │ -      │\n",
      "│ 90rfb (11).png  │ ✗            │ -      │\n",
      "│ 90rfb (12).png  │ ✗            │ -      │\n",
      "│ 90rfb (13).png  │ ✗            │ -      │\n",
      "│ 90rfb (2).png   │ ✗            │ -      │\n",
      "│ 90rfb (3).png   │ ✓            │ 4.4    │\n",
      "│ 90rfb (4).png   │ ✗            │ -      │\n",
      "│ 90rfb (5).png   │ ✗            │ -      │\n",
      "│ 90rfb (6).png   │ ✗            │ -      │\n",
      "│ 90rfb (7).png   │ ✗            │ -      │\n",
      "│ 90rfb (8).png   │ ✗            │ -      │\n",
      "│ 90rfb (9).png   │ ✗            │ -      │\n",
      "│ 90rfb.png       │ ✗            │ -      │\n",
      "│ 91gr (10).png   │ ✗            │ -      │\n",
      "│ 91gr (11).png   │ ✗            │ -      │\n",
      "│ 91gr (12).png   │ ✗            │ -      │\n",
      "│ 91gr (13).png   │ ✗            │ -      │\n",
      "│ 91gr (2).png    │ ✗            │ -      │\n",
      "│ 91gr (3).png    │ ✗            │ -      │\n",
      "│ 91gr (4).png    │ ✗            │ -      │\n",
      "│ 91gr (5).png    │ ✗            │ -      │\n",
      "│ 91gr (6).png    │ ✗            │ -      │\n",
      "│ 91gr (7).png    │ ✗            │ -      │\n",
      "│ 91gr (8).png    │ ✗            │ -      │\n",
      "│ 91gr (9).png    │ ✗            │ -      │\n",
      "│ 91gr.png        │ ✗            │ -      │\n",
      "│ 91rfb (10).png  │ ✗            │ -      │\n",
      "│ 91rfb (11).png  │ ✗            │ -      │\n",
      "│ 91rfb (12).png  │ ✗            │ -      │\n",
      "│ 91rfb (13).png  │ ✗            │ -      │\n",
      "│ 91rfb (2).png   │ ✗            │ -      │\n",
      "│ 91rfb (3).png   │ ✓            │ 2.0    │\n",
      "│ 91rfb (4).png   │ ✗            │ -      │\n",
      "│ 91rfb (5).png   │ ✗            │ -      │\n",
      "│ 91rfb (6).png   │ ✗            │ -      │\n",
      "│ 91rfb (7).png   │ ✗            │ -      │\n",
      "│ 91rfb (8).png   │ ✗            │ -      │\n",
      "│ 91rfb (9).png   │ ✗            │ -      │\n",
      "│ 91rfb.png       │ ✗            │ -      │\n",
      "│ 92gr (10).png   │ ✗            │ -      │\n",
      "│ 92gr (11).png   │ ✗            │ -      │\n",
      "│ 92gr (12).png   │ ✗            │ -      │\n",
      "│ 92gr (13).png   │ ✗            │ -      │\n",
      "│ 92gr (2).png    │ ✗            │ -      │\n",
      "│ 92gr (3).png    │ ✗            │ -      │\n",
      "│ 92gr (4).png    │ ✗            │ -      │\n",
      "│ 92gr (5).png    │ ✗            │ -      │\n",
      "│ 92gr (6).png    │ ✗            │ -      │\n",
      "│ 92gr (7).png    │ ✗            │ -      │\n",
      "│ 92gr (8).png    │ ✗            │ -      │\n",
      "│ 92gr (9).png    │ ✗            │ -      │\n",
      "│ 92gr.png        │ ✗            │ -      │\n",
      "│ 92rfb (10).png  │ ✗            │ -      │\n",
      "│ 92rfb (11).png  │ ✗            │ -      │\n",
      "│ 92rfb (12).png  │ ✗            │ -      │\n",
      "│ 92rfb (13).png  │ ✗            │ -      │\n",
      "│ 92rfb (2).png   │ ✗            │ -      │\n",
      "│ 92rfb (3).png   │ ✗            │ -      │\n",
      "│ 92rfb (4).png   │ ✗            │ -      │\n",
      "│ 92rfb (5).png   │ ✗            │ -      │\n",
      "│ 92rfb (6).png   │ ✗            │ -      │\n",
      "│ 92rfb (7).png   │ ✗            │ -      │\n",
      "│ 92rfb (8).png   │ ✗            │ -      │\n",
      "│ 92rfb (9).png   │ ✗            │ -      │\n",
      "│ 92rfb.png       │ ✗            │ -      │\n",
      "│ 93gr (10).png   │ ✗            │ -      │\n",
      "│ 93gr (11).png   │ ✗            │ -      │\n",
      "│ 93gr (12).png   │ ✗            │ -      │\n",
      "│ 93gr (13).png   │ ✗            │ -      │\n",
      "│ 93gr (2).png    │ ✗            │ -      │\n",
      "│ 93gr (3).png    │ ✗            │ -      │\n",
      "│ 93gr (4).png    │ ✗            │ -      │\n",
      "│ 93gr (5).png    │ ✗            │ -      │\n",
      "│ 93gr (6).png    │ ✗            │ -      │\n",
      "│ 93gr (7).png    │ ✗            │ -      │\n",
      "│ 93gr (8).png    │ ✗            │ -      │\n",
      "│ 93gr (9).png    │ ✗            │ -      │\n",
      "│ 93gr.png        │ ✗            │ -      │\n",
      "│ 93rfb (10).png  │ ✗            │ -      │\n",
      "│ 93rfb (11).png  │ ✗            │ -      │\n",
      "│ 93rfb (12).png  │ ✗            │ -      │\n",
      "│ 93rfb (13).png  │ ✗            │ -      │\n",
      "│ 93rfb (2).png   │ ✓            │ 3.6    │\n",
      "│ 93rfb (3).png   │ ✓            │ 5.7    │\n",
      "│ 93rfb (4).png   │ ✗            │ -      │\n",
      "│ 93rfb (5).png   │ ✗            │ -      │\n",
      "│ 93rfb (6).png   │ ✗            │ -      │\n",
      "│ 93rfb (7).png   │ ✗            │ -      │\n",
      "│ 93rfb (8).png   │ ✗            │ -      │\n",
      "│ 93rfb (9).png   │ ✗            │ -      │\n",
      "│ 93rfb.png       │ ✗            │ -      │\n",
      "│ 94gr (10).png   │ ✗            │ -      │\n",
      "│ 94gr (11).png   │ ✗            │ -      │\n",
      "│ 94gr (12).png   │ ✗            │ -      │\n",
      "│ 94gr (13).png   │ ✗            │ -      │\n",
      "│ 94gr (2).png    │ ✗            │ -      │\n",
      "│ 94gr (3).png    │ ✗            │ -      │\n",
      "│ 94gr (4).png    │ ✗            │ -      │\n",
      "│ 94gr (5).png    │ ✗            │ -      │\n",
      "│ 94gr (6).png    │ ✗            │ -      │\n",
      "│ 94gr (7).png    │ ✗            │ -      │\n",
      "│ 94gr (8).png    │ ✗            │ -      │\n",
      "│ 94gr (9).png    │ ✗            │ -      │\n",
      "│ 94gr.png        │ ✗            │ -      │\n",
      "│ 94rfb (10).png  │ ✗            │ -      │\n",
      "│ 94rfb (11).png  │ ✗            │ -      │\n",
      "│ 94rfb (12).png  │ ✗            │ -      │\n",
      "│ 94rfb (13).png  │ ✗            │ -      │\n",
      "│ 94rfb (2).png   │ ✗            │ -      │\n",
      "│ 94rfb (3).png   │ ✗            │ -      │\n",
      "│ 94rfb (4).png   │ ✗            │ -      │\n",
      "│ 94rfb (5).png   │ ✗            │ -      │\n",
      "│ 94rfb (6).png   │ ✓            │ 0.6    │\n",
      "│ 94rfb (7).png   │ ✗            │ -      │\n",
      "│ 94rfb (8).png   │ ✗            │ -      │\n",
      "│ 94rfb (9).png   │ ✗            │ -      │\n",
      "│ 94rfb.png       │ ✗            │ -      │\n",
      "│ 95gr (10).png   │ ✗            │ -      │\n",
      "│ 95gr (11).png   │ ✗            │ -      │\n",
      "│ 95gr (12).png   │ ✗            │ -      │\n",
      "│ 95gr (13).png   │ ✗            │ -      │\n",
      "│ 95gr (2).png    │ ✗            │ -      │\n",
      "│ 95gr (3).png    │ ✗            │ -      │\n",
      "│ 95gr (4).png    │ ✗            │ -      │\n",
      "│ 95gr (5).png    │ ✗            │ -      │\n",
      "│ 95gr (6).png    │ ✗            │ -      │\n",
      "│ 95gr (7).png    │ ✗            │ -      │\n",
      "│ 95gr (8).png    │ ✗            │ -      │\n",
      "│ 95gr (9).png    │ ✗            │ -      │\n",
      "│ 95gr.png        │ ✗            │ -      │\n",
      "│ 95rfb (10).png  │ ✗            │ -      │\n",
      "│ 95rfb (11).png  │ ✓            │ 0.1    │\n",
      "│ 95rfb (12).png  │ ✗            │ -      │\n",
      "│ 95rfb (13).png  │ ✗            │ -      │\n",
      "│ 95rfb (2).png   │ ✗            │ -      │\n",
      "│ 95rfb (3).png   │ ✗            │ -      │\n",
      "│ 95rfb (4).png   │ ✗            │ -      │\n",
      "│ 95rfb (5).png   │ ✗            │ -      │\n",
      "│ 95rfb (6).png   │ ✗            │ -      │\n",
      "│ 95rfb (7).png   │ ✗            │ -      │\n",
      "│ 95rfb (8).png   │ ✓            │ 0.3    │\n",
      "│ 95rfb (9).png   │ ✗            │ -      │\n",
      "│ 95rfb.png       │ ✗            │ -      │\n",
      "│ 96gr (10).png   │ ✗            │ -      │\n",
      "│ 96gr (11).png   │ ✗            │ -      │\n",
      "│ 96gr (12).png   │ ✗            │ -      │\n",
      "│ 96gr (13).png   │ ✗            │ -      │\n",
      "│ 96gr (2).png    │ ✗            │ -      │\n",
      "│ 96gr (3).png    │ ✗            │ -      │\n",
      "│ 96gr (4).png    │ ✗            │ -      │\n",
      "│ 96gr (5).png    │ ✗            │ -      │\n",
      "│ 96gr (6).png    │ ✗            │ -      │\n",
      "│ 96gr (7).png    │ ✗            │ -      │\n",
      "│ 96gr (8).png    │ ✗            │ -      │\n",
      "│ 96gr (9).png    │ ✗            │ -      │\n",
      "│ 96gr.png        │ ✗            │ -      │\n",
      "│ 96rfb (10).png  │ ✗            │ -      │\n",
      "│ 96rfb (11).png  │ ✗            │ -      │\n",
      "│ 96rfb (12).png  │ ✓            │ 2.4    │\n",
      "│ 96rfb (13).png  │ ✗            │ -      │\n",
      "│ 96rfb (2).png   │ ✗            │ -      │\n",
      "│ 96rfb (3).png   │ ✗            │ -      │\n",
      "│ 96rfb (4).png   │ ✗            │ -      │\n",
      "│ 96rfb (5).png   │ ✗            │ -      │\n",
      "│ 96rfb (6).png   │ ✗            │ -      │\n",
      "│ 96rfb (7).png   │ ✓            │ 0.1    │\n",
      "│ 96rfb (8).png   │ ✗            │ -      │\n",
      "│ 96rfb (9).png   │ ✗            │ -      │\n",
      "│ 96rfb.png       │ ✗            │ -      │\n",
      "│ 97gr (10).png   │ ✗            │ -      │\n",
      "│ 97gr (11).png   │ ✗            │ -      │\n",
      "│ 97gr (12).png   │ ✗            │ -      │\n",
      "│ 97gr (13).png   │ ✗            │ -      │\n",
      "│ 97gr (2).png    │ ✗            │ -      │\n",
      "│ 97gr (3).png    │ ✗            │ -      │\n",
      "│ 97gr (4).png    │ ✗            │ -      │\n",
      "│ 97gr (5).png    │ ✗            │ -      │\n",
      "│ 97gr (6).png    │ ✗            │ -      │\n",
      "│ 97gr (7).png    │ ✗            │ -      │\n",
      "│ 97gr (8).png    │ ✗            │ -      │\n",
      "│ 97gr (9).png    │ ✗            │ -      │\n",
      "│ 97gr.png        │ ✗            │ -      │\n",
      "│ 97rfb (10).png  │ ✗            │ -      │\n",
      "│ 97rfb (11).png  │ ✗            │ -      │\n",
      "│ 97rfb (12).png  │ ✗            │ -      │\n",
      "│ 97rfb (13).png  │ ✓            │ 1.0    │\n",
      "│ 97rfb (2).png   │ ✗            │ -      │\n",
      "│ 97rfb (3).png   │ ✗            │ -      │\n",
      "│ 97rfb (4).png   │ ✗            │ -      │\n",
      "│ 97rfb (5).png   │ ✗            │ -      │\n",
      "│ 97rfb (6).png   │ ✗            │ -      │\n",
      "│ 97rfb (7).png   │ ✗            │ -      │\n",
      "│ 97rfb (8).png   │ ✓            │ 0.1    │\n",
      "│ 97rfb (9).png   │ ✗            │ -      │\n",
      "│ 97rfb.png       │ ✗            │ -      │\n",
      "│ 98gr (10).png   │ ✗            │ -      │\n",
      "│ 98gr (11).png   │ ✗            │ -      │\n",
      "│ 98gr (12).png   │ ✗            │ -      │\n",
      "│ 98gr (13).png   │ ✗            │ -      │\n",
      "│ 98gr (2).png    │ ✗            │ -      │\n",
      "│ 98gr (3).png    │ ✗            │ -      │\n",
      "│ 98gr (4).png    │ ✗            │ -      │\n",
      "│ 98gr (5).png    │ ✓            │ 2.9    │\n",
      "│ 98gr (6).png    │ ✗            │ -      │\n",
      "│ 98gr (7).png    │ ✗            │ -      │\n",
      "│ 98gr (8).png    │ ✗            │ -      │\n",
      "│ 98gr (9).png    │ ✗            │ -      │\n",
      "│ 98gr.png        │ ✗            │ -      │\n",
      "│ 98rfb (10).png  │ ✗            │ -      │\n",
      "│ 98rfb (11).png  │ ✗            │ -      │\n",
      "│ 98rfb (12).png  │ ✗            │ -      │\n",
      "│ 98rfb (13).png  │ ✗            │ -      │\n",
      "│ 98rfb (2).png   │ ✓            │ 0.6    │\n",
      "│ 98rfb (3).png   │ ✗            │ -      │\n",
      "│ 98rfb (4).png   │ ✗            │ -      │\n",
      "│ 98rfb (5).png   │ ✗            │ -      │\n",
      "│ 98rfb (6).png   │ ✓            │ 0.4    │\n",
      "│ 98rfb (7).png   │ ✗            │ -      │\n",
      "│ 98rfb (8).png   │ ✗            │ -      │\n",
      "│ 98rfb (9).png   │ ✗            │ -      │\n",
      "│ 98rfb.png       │ ✗            │ -      │\n",
      "│ 99gr (10).png   │ ✗            │ -      │\n",
      "│ 99gr (11).png   │ ✗            │ -      │\n",
      "│ 99gr (12).png   │ ✗            │ -      │\n",
      "│ 99gr (13).png   │ ✗            │ -      │\n",
      "│ 99gr (2).png    │ ✗            │ -      │\n",
      "│ 99gr (3).png    │ ✗            │ -      │\n",
      "│ 99gr (4).png    │ ✗            │ -      │\n",
      "│ 99gr (5).png    │ ✗            │ -      │\n",
      "│ 99gr (6).png    │ ✗            │ -      │\n",
      "│ 99gr (7).png    │ ✗            │ -      │\n",
      "│ 99gr (8).png    │ ✗            │ -      │\n",
      "│ 99gr (9).png    │ ✗            │ -      │\n",
      "│ 99gr.png        │ ✗            │ -      │\n",
      "│ 99rfb (10).png  │ ✗            │ -      │\n",
      "│ 99rfb (11).png  │ ✗            │ -      │\n",
      "│ 99rfb (12).png  │ ✗            │ -      │\n",
      "│ 99rfb (13).png  │ ✗            │ -      │\n",
      "│ 99rfb (2).png   │ ✗            │ -      │\n",
      "│ 99rfb (3).png   │ ✗            │ -      │\n",
      "│ 99rfb (4).png   │ ✗            │ -      │\n",
      "│ 99rfb (5).png   │ ✗            │ -      │\n",
      "│ 99rfb (6).png   │ ✗            │ -      │\n",
      "│ 99rfb (7).png   │ ✗            │ -      │\n",
      "│ 99rfb (8).png   │ ✗            │ -      │\n",
      "│ 99rfb (9).png   │ ✗            │ -      │\n",
      "│ 99rfb.png       │ ✗            │ -      │\n",
      "└─────────────────┴──────────────┴────────┘\n",
      "\n",
      "Summary:\n",
      "Total images: 520\n",
      "Detection rate: 6.9%\n",
      "\n",
      "Results saved to: output_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/26/25 10:50:58] INFO     ModelManager initialized                          \n",
      "                    INFO     EarPredictor initialized with threshold=0.5       \n",
      "[10/26/25 10:50:59] INFO     ImageProcessor initialized with device=cpu        \n",
      "                    INFO     Processing 520 images from input_2                \n",
      "[10/26/25 10:51:01] INFO     Running batch prediction on 520 images            \n",
      "                    INFO     Created Unet model with resnet18 encoder          \n",
      "                    INFO     Loading model weights from                        \n",
      "                             C:\\Users\\Trise\\.cache\\earsegmentationai\\models\\ear\n",
      "                             segmentation_model_v1_46.pth                      \n",
      "                    WARNING  Loading legacy model format                       \n",
      "[10/26/25 10:51:02] INFO     Model loaded successfully                         \n",
      "[10/26/25 10:53:17] INFO     Saved batch results to output_2                   \n",
      "                    INFO     Batch processing complete. Detection rate: 6.9%   \n"
     ]
    }
   ],
   "source": [
    "# Process with visualization\n",
    "!earsegmentationai process-image input_2 --save-viz --output \"output_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c3ddf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1e7f0db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d8d61f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "607ad728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f991038",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b52ed0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bdb3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ear_segmentation'...\n",
      "Updating files:  99% (903/908)\n",
      "Updating files: 100% (908/908)\n",
      "Updating files: 100% (908/908), done.\n",
      "Filtering content:  50% (2/4)\n",
      "Filtering content:  75% (3/4), 75.04 MiB | 2.52 MiB/s\n",
      "Filtering content:  75% (3/4), 163.06 MiB | 4.22 MiB/s\n",
      "Filtering content: 100% (4/4), 163.06 MiB | 4.22 MiB/s\n",
      "Filtering content: 100% (4/4), 300.34 MiB | 4.91 MiB/s, done.\n",
      "fatal: active `post-checkout` hook found during `git clone`:\n",
      "\tA:/PROJECT/AUTO MICROTIA/Ear-segmentation-ai/ear_segmentation/.git/hooks/post-checkout\n",
      "For security reasons, this is disallowed by default.\n",
      "If this is intentional and the hook should actually be run, please\n",
      "run the command again with `GIT_CLONE_PROTECTION_ACTIVE=false`\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jorge-jrzz/ear_segmentation\n",
    "!cd ear_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b56ea0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (8.3.221)\n",
      "Requirement already satisfied: requests>=2.23.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (0.14.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: psutil in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (7.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (1.24.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: polars in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (1.34.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: typing-extensions in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from polars->ultralytics) (1.34.0)\n",
      "Requirement already satisfied: six>=1.5 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d4ae78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: opencv-python in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (1.24.1)\n",
      "Requirement already satisfied: pillow in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (9.3.0)\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.221-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: requests in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from torchvision) (2.32.5)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: psutil in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (7.1.1)\n",
      "Collecting polars\n",
      "  Using cached polars-1.34.0-py3-none-any.whl (772 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Using cached ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: packaging>=20.0 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests->torchvision) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests->torchvision) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests->torchvision) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from requests->torchvision) (3.4.4)\n",
      "Collecting polars-runtime-32==1.34.0\n",
      "  Downloading polars_runtime_32-1.34.0-cp39-abi3-win_amd64.whl (40.1 MB)\n",
      "     ---------------------------------------- 0.0/40.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/40.1 MB 1.3 MB/s eta 0:00:32\n",
      "     ---------------------------------------- 0.1/40.1 MB 1.1 MB/s eta 0:00:39\n",
      "     ---------------------------------------- 0.2/40.1 MB 1.3 MB/s eta 0:00:31\n",
      "     ---------------------------------------- 0.4/40.1 MB 1.9 MB/s eta 0:00:21\n",
      "      --------------------------------------- 0.6/40.1 MB 2.5 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 1.1/40.1 MB 3.9 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 1.5/40.1 MB 4.7 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 2.2/40.1 MB 6.1 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.7/40.1 MB 6.7 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.3/40.1 MB 7.4 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 4.0/40.1 MB 8.0 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 4.7/40.1 MB 8.6 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.4/40.1 MB 9.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 6.1/40.1 MB 9.5 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 6.8/40.1 MB 9.8 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 7.4/40.1 MB 10.1 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 8.1/40.1 MB 10.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 8.8/40.1 MB 10.6 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 9.5/40.1 MB 10.8 MB/s eta 0:00:03\n",
      "     --------- ----------------------------- 10.2/40.1 MB 11.0 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 10.8/40.1 MB 13.9 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 11.5/40.1 MB 14.2 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 12.2/40.1 MB 14.6 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 12.9/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 13.6/40.1 MB 15.2 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 14.4/40.1 MB 15.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.1/40.1 MB 15.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 14.9 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.2/40.1 MB 10.2 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 15.3/40.1 MB 10.1 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 15.4/40.1 MB 9.5 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 15.5/40.1 MB 9.4 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 15.9/40.1 MB 9.1 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 16.5/40.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 17.3/40.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 17.7/40.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 18.4/40.1 MB 8.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 19.0/40.1 MB 9.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 19.4/40.1 MB 8.8 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 19.5/40.1 MB 8.5 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.0/40.1 MB 8.4 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 20.4/40.1 MB 8.3 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 20.7/40.1 MB 8.1 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 20.7/40.1 MB 7.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 20.8/40.1 MB 7.8 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 21.3/40.1 MB 7.5 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 21.7/40.1 MB 7.4 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 22.1/40.1 MB 7.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 22.2/40.1 MB 7.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 22.4/40.1 MB 6.9 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 22.8/40.1 MB 6.8 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 23.1/40.1 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 23.3/40.1 MB 6.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 23.6/40.1 MB 6.5 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 23.8/40.1 MB 6.4 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.0/40.1 MB 6.2 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 24.2/40.1 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 24.5/40.1 MB 6.0 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 24.7/40.1 MB 5.9 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.0/40.1 MB 5.8 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 25.3/40.1 MB 5.7 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 25.5/40.1 MB 7.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 25.8/40.1 MB 7.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 26.0/40.1 MB 7.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 26.3/40.1 MB 7.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 26.5/40.1 MB 6.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 26.8/40.1 MB 6.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 27.1/40.1 MB 6.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 27.1/40.1 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 27.3/40.1 MB 6.4 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 27.7/40.1 MB 6.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 27.9/40.1 MB 6.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 28.0/40.1 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 28.2/40.1 MB 6.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 28.4/40.1 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 28.6/40.1 MB 5.7 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 28.8/40.1 MB 5.6 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 29.0/40.1 MB 5.5 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 29.2/40.1 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 29.4/40.1 MB 5.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 29.6/40.1 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 29.8/40.1 MB 5.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.0/40.1 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 30.2/40.1 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 30.4/40.1 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 30.6/40.1 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 30.9/40.1 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.1/40.1 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 31.3/40.1 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 31.5/40.1 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 31.7/40.1 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 31.9/40.1 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 32.2/40.1 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 32.4/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 32.6/40.1 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 32.9/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.1/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 33.3/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 33.6/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 33.8/40.1 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.0/40.1 MB 4.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 34.2/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 34.4/40.1 MB 4.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 34.6/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 34.9/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 35.1/40.1 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 35.3/40.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 35.5/40.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 35.7/40.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 36.0/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 36.2/40.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 36.4/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 36.6/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 36.9/40.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 37.1/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 37.4/40.1 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 37.5/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 37.9/40.1 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 38.2/40.1 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 38.4/40.1 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 38.6/40.1 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 38.9/40.1 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 39.1/40.1 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.3/40.1 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.6/40.1 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  39.9/40.1 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.1/40.1 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.1/40.1 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.1/40.1 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 40.1/40.1 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in a:\\project\\auto microtia\\ear-segmentation-ai\\ear_seg_env.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Installing collected packages: polars-runtime-32, ultralytics-thop, polars, ultralytics\n",
      "Successfully installed polars-1.34.0 polars-runtime-32-1.34.0 ultralytics-8.3.221 ultralytics-thop-2.0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision opencv-python numpy pillow ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ba26d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Processing 520 images with enhancement...\n",
      "📸 1/520: 100gr (10).png\n",
      "   ❌ No detection\n",
      "📸 2/520: 100gr (11).png\n",
      "   ❌ No detection\n",
      "📸 3/520: 100gr (12).png\n",
      "   ❌ No detection\n",
      "📸 4/520: 100gr (13).png\n",
      "   ❌ No detection\n",
      "📸 5/520: 100gr (2).png\n",
      "   ❌ No detection\n",
      "📸 6/520: 100gr (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.63)\n",
      "📸 7/520: 100gr (4).png\n",
      "   ❌ No detection\n",
      "📸 8/520: 100gr (5).png\n",
      "   ❌ No detection\n",
      "📸 9/520: 100gr (6).png\n",
      "   ❌ No detection\n",
      "📸 10/520: 100gr (7).png\n",
      "   ❌ No detection\n",
      "📸 11/520: 100gr (8).png\n",
      "   ❌ No detection\n",
      "📸 12/520: 100gr (9).png\n",
      "   ❌ No detection\n",
      "📸 13/520: 100gr.png\n",
      "   ❌ No detection\n",
      "📸 14/520: 100rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 15/520: 100rfb (11).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.56)\n",
      "📸 16/520: 100rfb (12).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.63)\n",
      "📸 17/520: 100rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 18/520: 100rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 19/520: 100rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.65)\n",
      "📸 20/520: 100rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 21/520: 100rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 22/520: 100rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.50)\n",
      "📸 23/520: 100rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.39)\n",
      "📸 24/520: 100rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 25/520: 100rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 26/520: 100rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.31)\n",
      "📸 27/520: 81gr (10).png\n",
      "   ❌ No detection\n",
      "📸 28/520: 81gr (11).png\n",
      "   ❌ No detection\n",
      "📸 29/520: 81gr (12).png\n",
      "   ❌ No detection\n",
      "📸 30/520: 81gr (13).png\n",
      "   ❌ No detection\n",
      "📸 31/520: 81gr (2).png\n",
      "   ❌ No detection\n",
      "📸 32/520: 81gr (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.34)\n",
      "📸 33/520: 81gr (4).png\n",
      "   ❌ No detection\n",
      "📸 34/520: 81gr (5).png\n",
      "   ❌ No detection\n",
      "📸 35/520: 81gr (6).png\n",
      "   ❌ No detection\n",
      "📸 36/520: 81gr (7).png\n",
      "   ❌ No detection\n",
      "📸 37/520: 81gr (8).png\n",
      "   ❌ No detection\n",
      "📸 38/520: 81gr (9).png\n",
      "   ❌ No detection\n",
      "📸 39/520: 81gr.png\n",
      "   ❌ No detection\n",
      "📸 40/520: 81rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 41/520: 81rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 42/520: 81rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.81)\n",
      "📸 43/520: 81rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.43)\n",
      "📸 44/520: 81rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 45/520: 81rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.50)\n",
      "📸 46/520: 81rfb (4).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.52)\n",
      "📸 47/520: 81rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.62)\n",
      "📸 48/520: 81rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.68)\n",
      "📸 49/520: 81rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 50/520: 81rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.55)\n",
      "📸 51/520: 81rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 52/520: 81rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.73)\n",
      "📸 53/520: 82gr (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.38)\n",
      "📸 54/520: 82gr (11).png\n",
      "   ❌ No detection\n",
      "📸 55/520: 82gr (12).png\n",
      "   ❌ No detection\n",
      "📸 56/520: 82gr (13).png\n",
      "   ❌ No detection\n",
      "📸 57/520: 82gr (2).png\n",
      "   ❌ No detection\n",
      "📸 58/520: 82gr (3).png\n",
      "   ❌ No detection\n",
      "📸 59/520: 82gr (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.68)\n",
      "📸 60/520: 82gr (5).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.47)\n",
      "📸 61/520: 82gr (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.44)\n",
      "📸 62/520: 82gr (7).png\n",
      "   ❌ No detection\n",
      "📸 63/520: 82gr (8).png\n",
      "   ❌ No detection\n",
      "📸 64/520: 82gr (9).png\n",
      "   ❌ No detection\n",
      "📸 65/520: 82gr.png\n",
      "   ❌ No detection\n",
      "📸 66/520: 82rfb (10).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.52)\n",
      "📸 67/520: 82rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 68/520: 82rfb (12).png\n",
      "   ❌ No detection\n",
      "📸 69/520: 82rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 70/520: 82rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.38)\n",
      "📸 71/520: 82rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 72/520: 82rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.75)\n",
      "📸 73/520: 82rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.32)\n",
      "📸 74/520: 82rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.48)\n",
      "📸 75/520: 82rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 76/520: 82rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 77/520: 82rfb (9).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.61)\n",
      "📸 78/520: 82rfb.png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.77)\n",
      "📸 79/520: 83gr (10).png\n",
      "   ❌ No detection\n",
      "📸 80/520: 83gr (11).png\n",
      "   ❌ No detection\n",
      "📸 81/520: 83gr (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.64)\n",
      "📸 82/520: 83gr (13).png\n",
      "   ❌ No detection\n",
      "📸 83/520: 83gr (2).png\n",
      "   ❌ No detection\n",
      "📸 84/520: 83gr (3).png\n",
      "   ❌ No detection\n",
      "📸 85/520: 83gr (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 86/520: 83gr (5).png\n",
      "   ❌ No detection\n",
      "📸 87/520: 83gr (6).png\n",
      "   ❌ No detection\n",
      "📸 88/520: 83gr (7).png\n",
      "   ❌ No detection\n",
      "📸 89/520: 83gr (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.51)\n",
      "📸 90/520: 83gr (9).png\n",
      "   ❌ No detection\n",
      "📸 91/520: 83gr.png\n",
      "   ❌ No detection\n",
      "📸 92/520: 83rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.31)\n",
      "📸 93/520: 83rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 94/520: 83rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.62)\n",
      "📸 95/520: 83rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 96/520: 83rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.60)\n",
      "📸 97/520: 83rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.37)\n",
      "📸 98/520: 83rfb (4).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.60)\n",
      "📸 99/520: 83rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 100/520: 83rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.48)\n",
      "📸 101/520: 83rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.54)\n",
      "📸 102/520: 83rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 103/520: 83rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 104/520: 83rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.31)\n",
      "📸 105/520: 84gr (10).png\n",
      "   ❌ No detection\n",
      "📸 106/520: 84gr (11).png\n",
      "   ❌ No detection\n",
      "📸 107/520: 84gr (12).png\n",
      "   ❌ No detection\n",
      "📸 108/520: 84gr (13).png\n",
      "   ❌ No detection\n",
      "📸 109/520: 84gr (2).png\n",
      "   ❌ No detection\n",
      "📸 110/520: 84gr (3).png\n",
      "   ❌ No detection\n",
      "📸 111/520: 84gr (4).png\n",
      "   ❌ No detection\n",
      "📸 112/520: 84gr (5).png\n",
      "   ❌ No detection\n",
      "📸 113/520: 84gr (6).png\n",
      "   ❌ No detection\n",
      "📸 114/520: 84gr (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.64)\n",
      "📸 115/520: 84gr (8).png\n",
      "   ❌ No detection\n",
      "📸 116/520: 84gr (9).png\n",
      "   ❌ No detection\n",
      "📸 117/520: 84gr.png\n",
      "   ❌ No detection\n",
      "📸 118/520: 84rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 119/520: 84rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.32)\n",
      "📸 120/520: 84rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 121/520: 84rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 122/520: 84rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 123/520: 84rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 124/520: 84rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 125/520: 84rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 126/520: 84rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 127/520: 84rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.36)\n",
      "📸 128/520: 84rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 129/520: 84rfb (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 130/520: 84rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 131/520: 85gr (10).png\n",
      "   ❌ No detection\n",
      "📸 132/520: 85gr (11).png\n",
      "   ❌ No detection\n",
      "📸 133/520: 85gr (12).png\n",
      "   ❌ No detection\n",
      "📸 134/520: 85gr (13).png\n",
      "   ❌ No detection\n",
      "📸 135/520: 85gr (2).png\n",
      "   ❌ No detection\n",
      "📸 136/520: 85gr (3).png\n",
      "   ❌ No detection\n",
      "📸 137/520: 85gr (4).png\n",
      "   ❌ No detection\n",
      "📸 138/520: 85gr (5).png\n",
      "   ❌ No detection\n",
      "📸 139/520: 85gr (6).png\n",
      "   ❌ No detection\n",
      "📸 140/520: 85gr (7).png\n",
      "   ❌ No detection\n",
      "📸 141/520: 85gr (8).png\n",
      "   ❌ No detection\n",
      "📸 142/520: 85gr (9).png\n",
      "   ❌ No detection\n",
      "📸 143/520: 85gr.png\n",
      "   ❌ No detection\n",
      "📸 144/520: 85rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 145/520: 85rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.58)\n",
      "📸 146/520: 85rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.60)\n",
      "📸 147/520: 85rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.48)\n",
      "📸 148/520: 85rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.31)\n",
      "📸 149/520: 85rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 150/520: 85rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.43)\n",
      "📸 151/520: 85rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 152/520: 85rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 153/520: 85rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 154/520: 85rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.77)\n",
      "📸 155/520: 85rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 156/520: 85rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.58)\n",
      "📸 157/520: 86gr (10).png\n",
      "   ❌ No detection\n",
      "📸 158/520: 86gr (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.40)\n",
      "📸 159/520: 86gr (12).png\n",
      "   ❌ No detection\n",
      "📸 160/520: 86gr (13).png\n",
      "   ❌ No detection\n",
      "📸 161/520: 86gr (2).png\n",
      "   ❌ No detection\n",
      "📸 162/520: 86gr (3).png\n",
      "   ❌ No detection\n",
      "📸 163/520: 86gr (4).png\n",
      "   ❌ No detection\n",
      "📸 164/520: 86gr (5).png\n",
      "   ❌ No detection\n",
      "📸 165/520: 86gr (6).png\n",
      "   ❌ No detection\n",
      "📸 166/520: 86gr (7).png\n",
      "   ❌ No detection\n",
      "📸 167/520: 86gr (8).png\n",
      "   ❌ No detection\n",
      "📸 168/520: 86gr (9).png\n",
      "   ❌ No detection\n",
      "📸 169/520: 86gr.png\n",
      "   ❌ No detection\n",
      "📸 170/520: 86rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 171/520: 86rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.54)\n",
      "📸 172/520: 86rfb (12).png\n",
      "   ❌ No detection\n",
      "📸 173/520: 86rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.38)\n",
      "📸 174/520: 86rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 175/520: 86rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.49)\n",
      "📸 176/520: 86rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 177/520: 86rfb (5).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.53)\n",
      "📸 178/520: 86rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 179/520: 86rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 180/520: 86rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 181/520: 86rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 182/520: 86rfb.png\n",
      "   ❌ No detection\n",
      "📸 183/520: 87gr (10).png\n",
      "   ❌ No detection\n",
      "📸 184/520: 87gr (11).png\n",
      "   ❌ No detection\n",
      "📸 185/520: 87gr (12).png\n",
      "   ❌ No detection\n",
      "📸 186/520: 87gr (13).png\n",
      "   ❌ No detection\n",
      "📸 187/520: 87gr (2).png\n",
      "   ❌ No detection\n",
      "📸 188/520: 87gr (3).png\n",
      "   ❌ No detection\n",
      "📸 189/520: 87gr (4).png\n",
      "   ❌ No detection\n",
      "📸 190/520: 87gr (5).png\n",
      "   ❌ No detection\n",
      "📸 191/520: 87gr (6).png\n",
      "   ❌ No detection\n",
      "📸 192/520: 87gr (7).png\n",
      "   ❌ No detection\n",
      "📸 193/520: 87gr (8).png\n",
      "   ❌ No detection\n",
      "📸 194/520: 87gr (9).png\n",
      "   ❌ No detection\n",
      "📸 195/520: 87gr.png\n",
      "   ❌ No detection\n",
      "📸 196/520: 87rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 197/520: 87rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 198/520: 87rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.45)\n",
      "📸 199/520: 87rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.65)\n",
      "📸 200/520: 87rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 201/520: 87rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.49)\n",
      "📸 202/520: 87rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 203/520: 87rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 204/520: 87rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 205/520: 87rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 206/520: 87rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.47)\n",
      "📸 207/520: 87rfb (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 208/520: 87rfb.png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.76)\n",
      "📸 209/520: 88gr (10).png\n",
      "   ❌ No detection\n",
      "📸 210/520: 88gr (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.54)\n",
      "📸 211/520: 88gr (12).png\n",
      "   ❌ No detection\n",
      "📸 212/520: 88gr (13).png\n",
      "   ❌ No detection\n",
      "📸 213/520: 88gr (2).png\n",
      "   ❌ No detection\n",
      "📸 214/520: 88gr (3).png\n",
      "   ❌ No detection\n",
      "📸 215/520: 88gr (4).png\n",
      "   ❌ No detection\n",
      "📸 216/520: 88gr (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.48)\n",
      "📸 217/520: 88gr (6).png\n",
      "   ❌ No detection\n",
      "📸 218/520: 88gr (7).png\n",
      "   ❌ No detection\n",
      "📸 219/520: 88gr (8).png\n",
      "   ❌ No detection\n",
      "📸 220/520: 88gr (9).png\n",
      "   ❌ No detection\n",
      "📸 221/520: 88gr.png\n",
      "   ❌ No detection\n",
      "📸 222/520: 88rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 223/520: 88rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.67)\n",
      "📸 224/520: 88rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 225/520: 88rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.46)\n",
      "📸 226/520: 88rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.40)\n",
      "📸 227/520: 88rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 228/520: 88rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 229/520: 88rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 230/520: 88rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 231/520: 88rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 232/520: 88rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.47)\n",
      "📸 233/520: 88rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 234/520: 88rfb.png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.55)\n",
      "📸 235/520: 89gr (10).png\n",
      "   ❌ No detection\n",
      "📸 236/520: 89gr (11).png\n",
      "   ❌ No detection\n",
      "📸 237/520: 89gr (12).png\n",
      "   ❌ No detection\n",
      "📸 238/520: 89gr (13).png\n",
      "   ❌ No detection\n",
      "📸 239/520: 89gr (2).png\n",
      "   ❌ No detection\n",
      "📸 240/520: 89gr (3).png\n",
      "   ❌ No detection\n",
      "📸 241/520: 89gr (4).png\n",
      "   ❌ No detection\n",
      "📸 242/520: 89gr (5).png\n",
      "   ❌ No detection\n",
      "📸 243/520: 89gr (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.63)\n",
      "📸 244/520: 89gr (7).png\n",
      "   ❌ No detection\n",
      "📸 245/520: 89gr (8).png\n",
      "   ❌ No detection\n",
      "📸 246/520: 89gr (9).png\n",
      "   ❌ No detection\n",
      "📸 247/520: 89gr.png\n",
      "   ❌ No detection\n",
      "📸 248/520: 89rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 249/520: 89rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 250/520: 89rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.50)\n",
      "📸 251/520: 89rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 252/520: 89rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.79)\n",
      "📸 253/520: 89rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.56)\n",
      "📸 254/520: 89rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.53)\n",
      "📸 255/520: 89rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 256/520: 89rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.53)\n",
      "📸 257/520: 89rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 258/520: 89rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.53)\n",
      "📸 259/520: 89rfb (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.36)\n",
      "📸 260/520: 89rfb.png\n",
      "   ❌ No detection\n",
      "📸 261/520: 90gr (10).png\n",
      "   ❌ No detection\n",
      "📸 262/520: 90gr (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.79)\n",
      "📸 263/520: 90gr (12).png\n",
      "   ❌ No detection\n",
      "📸 264/520: 90gr (13).png\n",
      "   ❌ No detection\n",
      "📸 265/520: 90gr (2).png\n",
      "   ❌ No detection\n",
      "📸 266/520: 90gr (3).png\n",
      "   ❌ No detection\n",
      "📸 267/520: 90gr (4).png\n",
      "   ❌ No detection\n",
      "📸 268/520: 90gr (5).png\n",
      "   ❌ No detection\n",
      "📸 269/520: 90gr (6).png\n",
      "   ❌ No detection\n",
      "📸 270/520: 90gr (7).png\n",
      "   ❌ No detection\n",
      "📸 271/520: 90gr (8).png\n",
      "   ❌ No detection\n",
      "📸 272/520: 90gr (9).png\n",
      "   ❌ No detection\n",
      "📸 273/520: 90gr.png\n",
      "   ❌ No detection\n",
      "📸 274/520: 90rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.58)\n",
      "📸 275/520: 90rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 276/520: 90rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.35)\n",
      "📸 277/520: 90rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 278/520: 90rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.44)\n",
      "📸 279/520: 90rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.61)\n",
      "📸 280/520: 90rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 281/520: 90rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.43)\n",
      "📸 282/520: 90rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.38)\n",
      "📸 283/520: 90rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.56)\n",
      "📸 284/520: 90rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 285/520: 90rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 286/520: 90rfb.png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.72)\n",
      "📸 287/520: 91gr (10).png\n",
      "   ❌ No detection\n",
      "📸 288/520: 91gr (11).png\n",
      "   ❌ No detection\n",
      "📸 289/520: 91gr (12).png\n",
      "   ❌ No detection\n",
      "📸 290/520: 91gr (13).png\n",
      "   ❌ No detection\n",
      "📸 291/520: 91gr (2).png\n",
      "   ❌ No detection\n",
      "📸 292/520: 91gr (3).png\n",
      "   ❌ No detection\n",
      "📸 293/520: 91gr (4).png\n",
      "   ❌ No detection\n",
      "📸 294/520: 91gr (5).png\n",
      "   ❌ No detection\n",
      "📸 295/520: 91gr (6).png\n",
      "   ❌ No detection\n",
      "📸 296/520: 91gr (7).png\n",
      "   ❌ No detection\n",
      "📸 297/520: 91gr (8).png\n",
      "   ❌ No detection\n",
      "📸 298/520: 91gr (9).png\n",
      "   ❌ No detection\n",
      "📸 299/520: 91gr.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.65)\n",
      "📸 300/520: 91rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.37)\n",
      "📸 301/520: 91rfb (11).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.63)\n",
      "📸 302/520: 91rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 303/520: 91rfb (13).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.48)\n",
      "📸 304/520: 91rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 305/520: 91rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.55)\n",
      "📸 306/520: 91rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 307/520: 91rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 308/520: 91rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.40)\n",
      "📸 309/520: 91rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 310/520: 91rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 311/520: 91rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 312/520: 91rfb.png\n",
      "   ❌ No detection\n",
      "📸 313/520: 92gr (10).png\n",
      "   ❌ No detection\n",
      "📸 314/520: 92gr (11).png\n",
      "   ❌ No detection\n",
      "📸 315/520: 92gr (12).png\n",
      "   ❌ No detection\n",
      "📸 316/520: 92gr (13).png\n",
      "   ❌ No detection\n",
      "📸 317/520: 92gr (2).png\n",
      "   ❌ No detection\n",
      "📸 318/520: 92gr (3).png\n",
      "   ❌ No detection\n",
      "📸 319/520: 92gr (4).png\n",
      "   ❌ No detection\n",
      "📸 320/520: 92gr (5).png\n",
      "   ❌ No detection\n",
      "📸 321/520: 92gr (6).png\n",
      "   ❌ No detection\n",
      "📸 322/520: 92gr (7).png\n",
      "   ❌ No detection\n",
      "📸 323/520: 92gr (8).png\n",
      "   ❌ No detection\n",
      "📸 324/520: 92gr (9).png\n",
      "   ❌ No detection\n",
      "📸 325/520: 92gr.png\n",
      "   ❌ No detection\n",
      "📸 326/520: 92rfb (10).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.31)\n",
      "📸 327/520: 92rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 328/520: 92rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.38)\n",
      "📸 329/520: 92rfb (13).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.57)\n",
      "📸 330/520: 92rfb (2).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.32)\n",
      "📸 331/520: 92rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 332/520: 92rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 333/520: 92rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 334/520: 92rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.48)\n",
      "📸 335/520: 92rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 336/520: 92rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 337/520: 92rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 338/520: 92rfb.png\n",
      "   ❌ No detection\n",
      "📸 339/520: 93gr (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.72)\n",
      "📸 340/520: 93gr (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 341/520: 93gr (12).png\n",
      "   ❌ No detection\n",
      "📸 342/520: 93gr (13).png\n",
      "   ❌ No detection\n",
      "📸 343/520: 93gr (2).png\n",
      "   ❌ No detection\n",
      "📸 344/520: 93gr (3).png\n",
      "   ❌ No detection\n",
      "📸 345/520: 93gr (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 346/520: 93gr (5).png\n",
      "   ❌ No detection\n",
      "📸 347/520: 93gr (6).png\n",
      "   ❌ No detection\n",
      "📸 348/520: 93gr (7).png\n",
      "   ❌ No detection\n",
      "📸 349/520: 93gr (8).png\n",
      "   ❌ No detection\n",
      "📸 350/520: 93gr (9).png\n",
      "   ❌ No detection\n",
      "📸 351/520: 93gr.png\n",
      "   ❌ No detection\n",
      "📸 352/520: 93rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 353/520: 93rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 354/520: 93rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 355/520: 93rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 356/520: 93rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 357/520: 93rfb (3).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.62)\n",
      "📸 358/520: 93rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 359/520: 93rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 360/520: 93rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 361/520: 93rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.71)\n",
      "📸 362/520: 93rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 363/520: 93rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 364/520: 93rfb.png\n",
      "   ❌ No detection\n",
      "📸 365/520: 94gr (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.34)\n",
      "📸 366/520: 94gr (11).png\n",
      "   ❌ No detection\n",
      "📸 367/520: 94gr (12).png\n",
      "   ❌ No detection\n",
      "📸 368/520: 94gr (13).png\n",
      "   ❌ No detection\n",
      "📸 369/520: 94gr (2).png\n",
      "   ❌ No detection\n",
      "📸 370/520: 94gr (3).png\n",
      "   ❌ No detection\n",
      "📸 371/520: 94gr (4).png\n",
      "   ❌ No detection\n",
      "📸 372/520: 94gr (5).png\n",
      "   ❌ No detection\n",
      "📸 373/520: 94gr (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.47)\n",
      "📸 374/520: 94gr (7).png\n",
      "   ❌ No detection\n",
      "📸 375/520: 94gr (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.50)\n",
      "📸 376/520: 94gr (9).png\n",
      "   ❌ No detection\n",
      "📸 377/520: 94gr.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.72)\n",
      "📸 378/520: 94rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 379/520: 94rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 380/520: 94rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.54)\n",
      "📸 381/520: 94rfb (13).png\n",
      "   ❌ No detection\n",
      "📸 382/520: 94rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 383/520: 94rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.51)\n",
      "📸 384/520: 94rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 385/520: 94rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 386/520: 94rfb (6).png\n",
      "   ❌ No detection\n",
      "📸 387/520: 94rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 388/520: 94rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 389/520: 94rfb (9).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.62)\n",
      "📸 390/520: 94rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.75)\n",
      "📸 391/520: 95gr (10).png\n",
      "   ❌ No detection\n",
      "📸 392/520: 95gr (11).png\n",
      "   ❌ No detection\n",
      "📸 393/520: 95gr (12).png\n",
      "   ❌ No detection\n",
      "📸 394/520: 95gr (13).png\n",
      "   ❌ No detection\n",
      "📸 395/520: 95gr (2).png\n",
      "   ❌ No detection\n",
      "📸 396/520: 95gr (3).png\n",
      "   ❌ No detection\n",
      "📸 397/520: 95gr (4).png\n",
      "   ❌ No detection\n",
      "📸 398/520: 95gr (5).png\n",
      "   ❌ No detection\n",
      "📸 399/520: 95gr (6).png\n",
      "   ❌ No detection\n",
      "📸 400/520: 95gr (7).png\n",
      "   ❌ No detection\n",
      "📸 401/520: 95gr (8).png\n",
      "   ❌ No detection\n",
      "📸 402/520: 95gr (9).png\n",
      "   ❌ No detection\n",
      "📸 403/520: 95gr.png\n",
      "   ❌ No detection\n",
      "📸 404/520: 95rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 405/520: 95rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 406/520: 95rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 407/520: 95rfb (13).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.61)\n",
      "📸 408/520: 95rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 409/520: 95rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.52)\n",
      "📸 410/520: 95rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 411/520: 95rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 412/520: 95rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.63)\n",
      "📸 413/520: 95rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.42)\n",
      "📸 414/520: 95rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 415/520: 95rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 416/520: 95rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.46)\n",
      "📸 417/520: 96gr (10).png\n",
      "   ❌ No detection\n",
      "📸 418/520: 96gr (11).png\n",
      "   ❌ No detection\n",
      "📸 419/520: 96gr (12).png\n",
      "   ❌ No detection\n",
      "📸 420/520: 96gr (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.31)\n",
      "📸 421/520: 96gr (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.40)\n",
      "📸 422/520: 96gr (3).png\n",
      "   ❌ No detection\n",
      "📸 423/520: 96gr (4).png\n",
      "   ❌ No detection\n",
      "📸 424/520: 96gr (5).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.69)\n",
      "📸 425/520: 96gr (6).png\n",
      "   ❌ No detection\n",
      "📸 426/520: 96gr (7).png\n",
      "   ❌ No detection\n",
      "📸 427/520: 96gr (8).png\n",
      "   ❌ No detection\n",
      "📸 428/520: 96gr (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.47)\n",
      "📸 429/520: 96gr.png\n",
      "   ❌ No detection\n",
      "📸 430/520: 96rfb (10).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.68)\n",
      "📸 431/520: 96rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.33)\n",
      "📸 432/520: 96rfb (12).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.85)\n",
      "📸 433/520: 96rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.50)\n",
      "📸 434/520: 96rfb (2).png\n",
      "   ❌ No detection\n",
      "📸 435/520: 96rfb (3).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.61)\n",
      "📸 436/520: 96rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 437/520: 96rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 438/520: 96rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.47)\n",
      "📸 439/520: 96rfb (7).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.32)\n",
      "📸 440/520: 96rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 441/520: 96rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 442/520: 96rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.55)\n",
      "📸 443/520: 97gr (10).png\n",
      "   ❌ No detection\n",
      "📸 444/520: 97gr (11).png\n",
      "   ❌ No detection\n",
      "📸 445/520: 97gr (12).png\n",
      "   ❌ No detection\n",
      "📸 446/520: 97gr (13).png\n",
      "   ❌ No detection\n",
      "📸 447/520: 97gr (2).png\n",
      "   ❌ No detection\n",
      "📸 448/520: 97gr (3).png\n",
      "   ❌ No detection\n",
      "📸 449/520: 97gr (4).png\n",
      "   ❌ No detection\n",
      "📸 450/520: 97gr (5).png\n",
      "   ❌ No detection\n",
      "📸 451/520: 97gr (6).png\n",
      "   ❌ No detection\n",
      "📸 452/520: 97gr (7).png\n",
      "   ❌ No detection\n",
      "📸 453/520: 97gr (8).png\n",
      "   ❌ No detection\n",
      "📸 454/520: 97gr (9).png\n",
      "   ❌ No detection\n",
      "📸 455/520: 97gr.png\n",
      "   ❌ No detection\n",
      "📸 456/520: 97rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 457/520: 97rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.65)\n",
      "📸 458/520: 97rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 459/520: 97rfb (13).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.56)\n",
      "📸 460/520: 97rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.75)\n",
      "📸 461/520: 97rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 462/520: 97rfb (4).png\n",
      "   ❌ No detection\n",
      "📸 463/520: 97rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 464/520: 97rfb (6).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.43)\n",
      "📸 465/520: 97rfb (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.54)\n",
      "📸 466/520: 97rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 467/520: 97rfb (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.51)\n",
      "📸 468/520: 97rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.76)\n",
      "📸 469/520: 98gr (10).png\n",
      "   ❌ No detection\n",
      "📸 470/520: 98gr (11).png\n",
      "   ❌ No detection\n",
      "📸 471/520: 98gr (12).png\n",
      "   ❌ No detection\n",
      "📸 472/520: 98gr (13).png\n",
      "   ❌ No detection\n",
      "📸 473/520: 98gr (2).png\n",
      "   ❌ No detection\n",
      "📸 474/520: 98gr (3).png\n",
      "   ❌ No detection\n",
      "📸 475/520: 98gr (4).png\n",
      "   ❌ No detection\n",
      "📸 476/520: 98gr (5).png\n",
      "   ❌ No detection\n",
      "📸 477/520: 98gr (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.58)\n",
      "📸 478/520: 98gr (7).png\n",
      "   ❌ No detection\n",
      "📸 479/520: 98gr (8).png\n",
      "   ❌ No detection\n",
      "📸 480/520: 98gr (9).png\n",
      "   ❌ No detection\n",
      "📸 481/520: 98gr.png\n",
      "   ❌ No detection\n",
      "📸 482/520: 98rfb (10).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.36)\n",
      "📸 483/520: 98rfb (11).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.61)\n",
      "📸 484/520: 98rfb (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.40)\n",
      "📸 485/520: 98rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.60)\n",
      "📸 486/520: 98rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 487/520: 98rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 488/520: 98rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.56)\n",
      "📸 489/520: 98rfb (5).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.63)\n",
      "📸 490/520: 98rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 491/520: 98rfb (7).png\n",
      "   ✅ DETECTED! (venhanced, conf: 0.50)\n",
      "📸 492/520: 98rfb (8).png\n",
      "   ❌ No detection\n",
      "📸 493/520: 98rfb (9).png\n",
      "   ❌ No detection\n",
      "📸 494/520: 98rfb.png\n",
      "   ✅ DETECTED! (vresized, conf: 0.69)\n",
      "📸 495/520: 99gr (10).png\n",
      "   ❌ No detection\n",
      "📸 496/520: 99gr (11).png\n",
      "   ❌ No detection\n",
      "📸 497/520: 99gr (12).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.45)\n",
      "📸 498/520: 99gr (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 499/520: 99gr (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.41)\n",
      "📸 500/520: 99gr (3).png\n",
      "   ❌ No detection\n",
      "📸 501/520: 99gr (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.41)\n",
      "📸 502/520: 99gr (5).png\n",
      "   ❌ No detection\n",
      "📸 503/520: 99gr (6).png\n",
      "   ❌ No detection\n",
      "📸 504/520: 99gr (7).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.57)\n",
      "📸 505/520: 99gr (8).png\n",
      "   ❌ No detection\n",
      "📸 506/520: 99gr (9).png\n",
      "   ❌ No detection\n",
      "📸 507/520: 99gr.png\n",
      "   ❌ No detection\n",
      "📸 508/520: 99rfb (10).png\n",
      "   ❌ No detection\n",
      "📸 509/520: 99rfb (11).png\n",
      "   ❌ No detection\n",
      "📸 510/520: 99rfb (12).png\n",
      "   ❌ No detection\n",
      "📸 511/520: 99rfb (13).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.55)\n",
      "📸 512/520: 99rfb (2).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 513/520: 99rfb (3).png\n",
      "   ❌ No detection\n",
      "📸 514/520: 99rfb (4).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.52)\n",
      "📸 515/520: 99rfb (5).png\n",
      "   ❌ No detection\n",
      "📸 516/520: 99rfb (6).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.51)\n",
      "📸 517/520: 99rfb (7).png\n",
      "   ❌ No detection\n",
      "📸 518/520: 99rfb (8).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.55)\n",
      "📸 519/520: 99rfb (9).png\n",
      "   ✅ DETECTED! (vresized, conf: 0.59)\n",
      "📸 520/520: 99rfb.png\n",
      "   ❌ No detection\n",
      "\n",
      "📊 ENHANCED DETECTION RESULTS:\n",
      "   Total: 520\n",
      "   Detected: 173\n",
      "   Detection rate: 33.3%\n"
     ]
    }
   ],
   "source": [
    "# enhance_and_detect.py\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def enhance_image(image, target_size=(640, 640)):\n",
    "    \"\"\"Enhance small images for better detection\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Method 1: Simple resize (may cause distortion)\n",
    "    resized = cv2.resize(image, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Method 2: Pad to square then resize (preserves aspect ratio)\n",
    "    max_dim = max(h, w)\n",
    "    pad_h = (max_dim - h) // 2\n",
    "    pad_w = (max_dim - w) // 2\n",
    "    \n",
    "    padded = cv2.copyMakeBorder(\n",
    "        image, pad_h, pad_h, pad_w, pad_w, \n",
    "        cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
    "    )\n",
    "    padded_resized = cv2.resize(padded, target_size, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Method 3: Apply contrast enhancement\n",
    "    lab = cv2.cvtColor(padded_resized, cv2.COLOR_BGR2LAB)\n",
    "    lab[:,:,0] = cv2.createCLAHE(clipLimit=2.0).apply(lab[:,:,0])\n",
    "    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return enhanced, resized, padded_resized\n",
    "\n",
    "def detect_with_enhancement(model, image_path, output_dir=\"enhanced_output\"):\n",
    "    \"\"\"Detect ears with image enhancement\"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    # Create enhanced versions\n",
    "    enhanced, resized, padded = enhance_image(img)\n",
    "    \n",
    "    # Test all three versions\n",
    "    best_result = None\n",
    "    best_confidence = 0\n",
    "    \n",
    "    versions = [\n",
    "        (\"enhanced\", enhanced),\n",
    "        (\"resized\", resized), \n",
    "        (\"padded\", padded)\n",
    "    ]\n",
    "    \n",
    "    for version_name, version_img in versions:\n",
    "        results = model.predict(version_img, imgsz=640, conf=0.3, verbose=False)\n",
    "        \n",
    "        if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
    "            confidence = results[0].boxes.conf[0].item()\n",
    "            \n",
    "            if confidence > best_confidence:\n",
    "                best_confidence = confidence\n",
    "                best_result = {\n",
    "                    'version': version_name,\n",
    "                    'image': version_img,\n",
    "                    'confidence': confidence,\n",
    "                    'boxes': results[0].boxes,\n",
    "                    'masks': results[0].masks\n",
    "                }\n",
    "    \n",
    "    # Save best result\n",
    "    if best_result:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        base_name = Path(image_path).stem\n",
    "        \n",
    "        # Save enhanced image with detection\n",
    "        annotated = best_result['image'].copy()\n",
    "        if best_result['boxes']:\n",
    "            # Draw bounding boxes\n",
    "            for box in best_result['boxes']:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(annotated, f\"{best_result['confidence']:.2f}\", \n",
    "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_{best_result['version']}_detected.jpg\")\n",
    "        cv2.imwrite(output_path, annotated)\n",
    "        \n",
    "        return {\n",
    "            'detected': True,\n",
    "            'confidence': best_result['confidence'],\n",
    "            'version': best_result['version'],\n",
    "            'output_path': output_path\n",
    "        }\n",
    "    \n",
    "    return {'detected': False, 'confidence': 0}\n",
    "\n",
    "def batch_enhance_and_detect(input_dir, output_dir=\"enhanced_batch_output\"):\n",
    "    \"\"\"Process all images with enhancement\"\"\"\n",
    "    model = YOLO('ear_segmentation/models/best_v4.pt')\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "    print(f\"🔍 Processing {len(image_files)} images with enhancement...\")\n",
    "    \n",
    "    results = []\n",
    "    for i, img_path in enumerate(image_files):\n",
    "        print(f\"📸 {i+1}/{len(image_files)}: {Path(img_path).name}\")\n",
    "        \n",
    "        result = detect_with_enhancement(model, img_path, output_dir)\n",
    "        \n",
    "        if result['detected']:\n",
    "            print(f\"   ✅ DETECTED! (v{result['version']}, conf: {result['confidence']:.2f})\")\n",
    "            results.append(True)\n",
    "        else:\n",
    "            print(f\"   ❌ No detection\")\n",
    "            results.append(False)\n",
    "    \n",
    "    # Statistics\n",
    "    detected = sum(results)\n",
    "    detection_rate = (detected / len(results)) * 100\n",
    "    print(f\"\\n📊 ENHANCED DETECTION RESULTS:\")\n",
    "    print(f\"   Total: {len(results)}\")\n",
    "    print(f\"   Detected: {detected}\")\n",
    "    print(f\"   Detection rate: {detection_rate:.1f}%\")\n",
    "    \n",
    "    return detection_rate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_enhance_and_detect(\"input_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "824f7e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 YOLO Ear Segmentation Batch Processing\n",
      "✅ YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "✅ Model type: segment\n",
      "🎯 Processing: input_2\n",
      "🔍 Processing 520 images from input_2\n",
      "📸 1/520: 100gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 2/520: 100gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 3/520: 100gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 4/520: 100gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 5/520: 100gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 6/520: 100gr (3).png\n",
      "   ✓ Detected: True, Area: 20.1%, Objects: 1\n",
      "📸 7/520: 100gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 8/520: 100gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 9/520: 100gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 10/520: 100gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 11/520: 100gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 12/520: 100gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 13/520: 100gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 14/520: 100rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 15/520: 100rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 16/520: 100rfb (12).png\n",
      "   ✓ Detected: True, Area: 22.6%, Objects: 1\n",
      "📸 17/520: 100rfb (13).png\n",
      "   ✓ Detected: True, Area: 29.2%, Objects: 1\n",
      "📸 18/520: 100rfb (2).png\n",
      "   ✓ Detected: True, Area: 20.8%, Objects: 3\n",
      "📸 19/520: 100rfb (3).png\n",
      "   ✓ Detected: True, Area: 20.3%, Objects: 1\n",
      "📸 20/520: 100rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 21/520: 100rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 22/520: 100rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 23/520: 100rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 24/520: 100rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 25/520: 100rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 26/520: 100rfb.png\n",
      "   ✓ Detected: True, Area: 15.0%, Objects: 1\n",
      "📸 27/520: 81gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 28/520: 81gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 29/520: 81gr (12).png\n",
      "   ✓ Detected: True, Area: 18.7%, Objects: 1\n",
      "📸 30/520: 81gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 31/520: 81gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 32/520: 81gr (3).png\n",
      "   ✓ Detected: True, Area: 20.6%, Objects: 1\n",
      "📸 33/520: 81gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 34/520: 81gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 35/520: 81gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 36/520: 81gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 37/520: 81gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 38/520: 81gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 39/520: 81gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 40/520: 81rfb (10).png\n",
      "   ✓ Detected: True, Area: 11.6%, Objects: 1\n",
      "📸 41/520: 81rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 42/520: 81rfb (12).png\n",
      "   ✓ Detected: True, Area: 17.6%, Objects: 1\n",
      "📸 43/520: 81rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 44/520: 81rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 45/520: 81rfb (3).png\n",
      "   ✓ Detected: True, Area: 24.2%, Objects: 1\n",
      "📸 46/520: 81rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 47/520: 81rfb (5).png\n",
      "   ✓ Detected: True, Area: 21.9%, Objects: 2\n",
      "📸 48/520: 81rfb (6).png\n",
      "   ✓ Detected: True, Area: 14.1%, Objects: 1\n",
      "📸 49/520: 81rfb (7).png\n",
      "   ✓ Detected: True, Area: 17.2%, Objects: 1\n",
      "📸 50/520: 81rfb (8).png\n",
      "   ✓ Detected: True, Area: 23.3%, Objects: 2\n",
      "📸 51/520: 81rfb (9).png\n",
      "   ✓ Detected: True, Area: 16.9%, Objects: 1\n",
      "📸 52/520: 81rfb.png\n",
      "   ✓ Detected: True, Area: 17.8%, Objects: 3\n",
      "📸 53/520: 82gr (10).png\n",
      "   ✓ Detected: True, Area: 20.6%, Objects: 1\n",
      "📸 54/520: 82gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 55/520: 82gr (12).png\n",
      "   ✓ Detected: True, Area: 21.6%, Objects: 1\n",
      "📸 56/520: 82gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 57/520: 82gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 58/520: 82gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 59/520: 82gr (4).png\n",
      "   ✓ Detected: True, Area: 5.8%, Objects: 1\n",
      "📸 60/520: 82gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 61/520: 82gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 62/520: 82gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 63/520: 82gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 64/520: 82gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 65/520: 82gr.png\n",
      "   ✓ Detected: True, Area: 16.2%, Objects: 1\n",
      "📸 66/520: 82rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 67/520: 82rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 68/520: 82rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 69/520: 82rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 70/520: 82rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 71/520: 82rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 72/520: 82rfb (4).png\n",
      "   ✓ Detected: True, Area: 18.4%, Objects: 1\n",
      "📸 73/520: 82rfb (5).png\n",
      "   ✓ Detected: True, Area: 25.1%, Objects: 2\n",
      "📸 74/520: 82rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 75/520: 82rfb (7).png\n",
      "   ✓ Detected: True, Area: 15.5%, Objects: 1\n",
      "📸 76/520: 82rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 77/520: 82rfb (9).png\n",
      "   ✓ Detected: True, Area: 24.2%, Objects: 3\n",
      "📸 78/520: 82rfb.png\n",
      "   ✓ Detected: True, Area: 15.0%, Objects: 2\n",
      "📸 79/520: 83gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 80/520: 83gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 81/520: 83gr (12).png\n",
      "   ✓ Detected: True, Area: 20.3%, Objects: 2\n",
      "📸 82/520: 83gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 83/520: 83gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 84/520: 83gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 85/520: 83gr (4).png\n",
      "   ✓ Detected: True, Area: 24.3%, Objects: 1\n",
      "📸 86/520: 83gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 87/520: 83gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 88/520: 83gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 89/520: 83gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 90/520: 83gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 91/520: 83gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 92/520: 83rfb (10).png\n",
      "   ✓ Detected: True, Area: 24.5%, Objects: 1\n",
      "📸 93/520: 83rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 94/520: 83rfb (12).png\n",
      "   ✓ Detected: True, Area: 22.2%, Objects: 2\n",
      "📸 95/520: 83rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 96/520: 83rfb (2).png\n",
      "   ✓ Detected: True, Area: 23.6%, Objects: 1\n",
      "📸 97/520: 83rfb (3).png\n",
      "   ✓ Detected: True, Area: 17.7%, Objects: 1\n",
      "📸 98/520: 83rfb (4).png\n",
      "   ✓ Detected: True, Area: 24.2%, Objects: 1\n",
      "📸 99/520: 83rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 100/520: 83rfb (6).png\n",
      "   ✓ Detected: True, Area: 21.1%, Objects: 1\n",
      "📸 101/520: 83rfb (7).png\n",
      "   ✓ Detected: True, Area: 17.0%, Objects: 1\n",
      "📸 102/520: 83rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 103/520: 83rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 104/520: 83rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 105/520: 84gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 106/520: 84gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 107/520: 84gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 108/520: 84gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 109/520: 84gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 110/520: 84gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 111/520: 84gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 112/520: 84gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 113/520: 84gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 114/520: 84gr (7).png\n",
      "   ✓ Detected: True, Area: 17.9%, Objects: 1\n",
      "📸 115/520: 84gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 116/520: 84gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 117/520: 84gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 118/520: 84rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 119/520: 84rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 120/520: 84rfb (12).png\n",
      "   ✓ Detected: True, Area: 21.2%, Objects: 2\n",
      "📸 121/520: 84rfb (13).png\n",
      "   ✓ Detected: True, Area: 24.3%, Objects: 1\n",
      "📸 122/520: 84rfb (2).png\n",
      "   ✓ Detected: True, Area: 18.6%, Objects: 1\n",
      "📸 123/520: 84rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 124/520: 84rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 125/520: 84rfb (5).png\n",
      "   ✓ Detected: True, Area: 23.6%, Objects: 1\n",
      "📸 126/520: 84rfb (6).png\n",
      "   ✓ Detected: True, Area: 24.0%, Objects: 1\n",
      "📸 127/520: 84rfb (7).png\n",
      "   ✓ Detected: True, Area: 19.9%, Objects: 1\n",
      "📸 128/520: 84rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 129/520: 84rfb (9).png\n",
      "   ✓ Detected: True, Area: 24.9%, Objects: 1\n",
      "📸 130/520: 84rfb.png\n",
      "   ✓ Detected: True, Area: 22.8%, Objects: 1\n",
      "📸 131/520: 85gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 132/520: 85gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 133/520: 85gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 134/520: 85gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 135/520: 85gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 136/520: 85gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 137/520: 85gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 138/520: 85gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 139/520: 85gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 140/520: 85gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 141/520: 85gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 142/520: 85gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 143/520: 85gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 144/520: 85rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 145/520: 85rfb (11).png\n",
      "   ✓ Detected: True, Area: 23.4%, Objects: 1\n",
      "📸 146/520: 85rfb (12).png\n",
      "   ✓ Detected: True, Area: 18.1%, Objects: 1\n",
      "📸 147/520: 85rfb (13).png\n",
      "   ✓ Detected: True, Area: 23.1%, Objects: 1\n",
      "📸 148/520: 85rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 149/520: 85rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 150/520: 85rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 151/520: 85rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 152/520: 85rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 153/520: 85rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 154/520: 85rfb (8).png\n",
      "   ✓ Detected: True, Area: 12.5%, Objects: 1\n",
      "📸 155/520: 85rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 156/520: 85rfb.png\n",
      "   ✓ Detected: True, Area: 25.5%, Objects: 1\n",
      "📸 157/520: 86gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 158/520: 86gr (11).png\n",
      "   ✓ Detected: True, Area: 11.1%, Objects: 1\n",
      "📸 159/520: 86gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 160/520: 86gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 161/520: 86gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 162/520: 86gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 163/520: 86gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 164/520: 86gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 165/520: 86gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 166/520: 86gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 167/520: 86gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 168/520: 86gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 169/520: 86gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 170/520: 86rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 171/520: 86rfb (11).png\n",
      "   ✓ Detected: True, Area: 13.7%, Objects: 2\n",
      "📸 172/520: 86rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 173/520: 86rfb (13).png\n",
      "   ✓ Detected: True, Area: 27.2%, Objects: 1\n",
      "📸 174/520: 86rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 175/520: 86rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 176/520: 86rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 177/520: 86rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 178/520: 86rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 179/520: 86rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 180/520: 86rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 181/520: 86rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 182/520: 86rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 183/520: 87gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 184/520: 87gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 185/520: 87gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 186/520: 87gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 187/520: 87gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 188/520: 87gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 189/520: 87gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 190/520: 87gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 191/520: 87gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 192/520: 87gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 193/520: 87gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 194/520: 87gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 195/520: 87gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 196/520: 87rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 197/520: 87rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 198/520: 87rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 199/520: 87rfb (13).png\n",
      "   ✓ Detected: True, Area: 18.4%, Objects: 2\n",
      "📸 200/520: 87rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 201/520: 87rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 202/520: 87rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 203/520: 87rfb (5).png\n",
      "   ✓ Detected: True, Area: 27.2%, Objects: 1\n",
      "📸 204/520: 87rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 205/520: 87rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 206/520: 87rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 207/520: 87rfb (9).png\n",
      "   ✓ Detected: True, Area: 20.0%, Objects: 1\n",
      "📸 208/520: 87rfb.png\n",
      "   ✓ Detected: True, Area: 16.3%, Objects: 4\n",
      "📸 209/520: 88gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 210/520: 88gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 211/520: 88gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 212/520: 88gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 213/520: 88gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 214/520: 88gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 215/520: 88gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 216/520: 88gr (5).png\n",
      "   ✓ Detected: True, Area: 21.7%, Objects: 1\n",
      "📸 217/520: 88gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 218/520: 88gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 219/520: 88gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 220/520: 88gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 221/520: 88gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 222/520: 88rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 223/520: 88rfb (11).png\n",
      "   ✓ Detected: True, Area: 19.5%, Objects: 2\n",
      "📸 224/520: 88rfb (12).png\n",
      "   ✓ Detected: True, Area: 19.7%, Objects: 1\n",
      "📸 225/520: 88rfb (13).png\n",
      "   ✓ Detected: True, Area: 26.9%, Objects: 2\n",
      "📸 226/520: 88rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 227/520: 88rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 228/520: 88rfb (4).png\n",
      "   ✓ Detected: True, Area: 17.5%, Objects: 1\n",
      "📸 229/520: 88rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 230/520: 88rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 231/520: 88rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 232/520: 88rfb (8).png\n",
      "   ✓ Detected: True, Area: 25.0%, Objects: 1\n",
      "📸 233/520: 88rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 234/520: 88rfb.png\n",
      "   ✓ Detected: True, Area: 17.3%, Objects: 2\n",
      "📸 235/520: 89gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 236/520: 89gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 237/520: 89gr (12).png\n",
      "   ✓ Detected: True, Area: 17.6%, Objects: 1\n",
      "📸 238/520: 89gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 239/520: 89gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 240/520: 89gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 241/520: 89gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 242/520: 89gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 243/520: 89gr (6).png\n",
      "   ✓ Detected: True, Area: 19.7%, Objects: 1\n",
      "📸 244/520: 89gr (7).png\n",
      "   ✓ Detected: True, Area: 17.7%, Objects: 1\n",
      "📸 245/520: 89gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 246/520: 89gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 247/520: 89gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 248/520: 89rfb (10).png\n",
      "   ✓ Detected: True, Area: 17.3%, Objects: 1\n",
      "📸 249/520: 89rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 250/520: 89rfb (12).png\n",
      "   ✓ Detected: True, Area: 13.9%, Objects: 1\n",
      "📸 251/520: 89rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 252/520: 89rfb (2).png\n",
      "   ✓ Detected: True, Area: 8.8%, Objects: 1\n",
      "📸 253/520: 89rfb (3).png\n",
      "   ✓ Detected: True, Area: 27.8%, Objects: 1\n",
      "📸 254/520: 89rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 255/520: 89rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 256/520: 89rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 257/520: 89rfb (7).png\n",
      "   ✓ Detected: True, Area: 17.8%, Objects: 1\n",
      "📸 258/520: 89rfb (8).png\n",
      "   ✓ Detected: True, Area: 21.3%, Objects: 1\n",
      "📸 259/520: 89rfb (9).png\n",
      "   ✓ Detected: True, Area: 22.2%, Objects: 1\n",
      "📸 260/520: 89rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 261/520: 90gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 262/520: 90gr (11).png\n",
      "   ✓ Detected: True, Area: 15.6%, Objects: 1\n",
      "📸 263/520: 90gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 264/520: 90gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 265/520: 90gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 266/520: 90gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 267/520: 90gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 268/520: 90gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 269/520: 90gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 270/520: 90gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 271/520: 90gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 272/520: 90gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 273/520: 90gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 274/520: 90rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 275/520: 90rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 276/520: 90rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 277/520: 90rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 278/520: 90rfb (2).png\n",
      "   ✓ Detected: True, Area: 17.8%, Objects: 1\n",
      "📸 279/520: 90rfb (3).png\n",
      "   ✓ Detected: True, Area: 16.9%, Objects: 1\n",
      "📸 280/520: 90rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 281/520: 90rfb (5).png\n",
      "   ✓ Detected: True, Area: 21.6%, Objects: 1\n",
      "📸 282/520: 90rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 283/520: 90rfb (7).png\n",
      "   ✓ Detected: True, Area: 23.6%, Objects: 1\n",
      "📸 284/520: 90rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 285/520: 90rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 286/520: 90rfb.png\n",
      "   ✓ Detected: True, Area: 19.5%, Objects: 2\n",
      "📸 287/520: 91gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 288/520: 91gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 289/520: 91gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 290/520: 91gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 291/520: 91gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 292/520: 91gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 293/520: 91gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 294/520: 91gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 295/520: 91gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 296/520: 91gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 297/520: 91gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 298/520: 91gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 299/520: 91gr.png\n",
      "   ✓ Detected: True, Area: 20.3%, Objects: 1\n",
      "📸 300/520: 91rfb (10).png\n",
      "   ✓ Detected: True, Area: 23.0%, Objects: 2\n",
      "📸 301/520: 91rfb (11).png\n",
      "   ✓ Detected: True, Area: 17.0%, Objects: 4\n",
      "📸 302/520: 91rfb (12).png\n",
      "   ✓ Detected: True, Area: 21.9%, Objects: 2\n",
      "📸 303/520: 91rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 304/520: 91rfb (2).png\n",
      "   ✓ Detected: True, Area: 11.3%, Objects: 1\n",
      "📸 305/520: 91rfb (3).png\n",
      "   ✓ Detected: True, Area: 17.8%, Objects: 1\n",
      "📸 306/520: 91rfb (4).png\n",
      "   ✓ Detected: True, Area: 15.5%, Objects: 1\n",
      "📸 307/520: 91rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 308/520: 91rfb (6).png\n",
      "   ✓ Detected: True, Area: 17.3%, Objects: 1\n",
      "📸 309/520: 91rfb (7).png\n",
      "   ✓ Detected: True, Area: 24.6%, Objects: 1\n",
      "📸 310/520: 91rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 311/520: 91rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 312/520: 91rfb.png\n",
      "   ✓ Detected: True, Area: 23.8%, Objects: 1\n",
      "📸 313/520: 92gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 314/520: 92gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 315/520: 92gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 316/520: 92gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 317/520: 92gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 318/520: 92gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 319/520: 92gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 320/520: 92gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 321/520: 92gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 322/520: 92gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 323/520: 92gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 324/520: 92gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 325/520: 92gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 326/520: 92rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 327/520: 92rfb (11).png\n",
      "   ✓ Detected: True, Area: 14.2%, Objects: 2\n",
      "📸 328/520: 92rfb (12).png\n",
      "   ✓ Detected: True, Area: 16.0%, Objects: 1\n",
      "📸 329/520: 92rfb (13).png\n",
      "   ✓ Detected: True, Area: 29.4%, Objects: 1\n",
      "📸 330/520: 92rfb (2).png\n",
      "   ✓ Detected: True, Area: 16.6%, Objects: 1\n",
      "📸 331/520: 92rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 332/520: 92rfb (4).png\n",
      "   ✓ Detected: True, Area: 28.0%, Objects: 1\n",
      "📸 333/520: 92rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 334/520: 92rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 335/520: 92rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 336/520: 92rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 337/520: 92rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 338/520: 92rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 339/520: 93gr (10).png\n",
      "   ✓ Detected: True, Area: 18.8%, Objects: 1\n",
      "📸 340/520: 93gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 341/520: 93gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 342/520: 93gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 343/520: 93gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 344/520: 93gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 345/520: 93gr (4).png\n",
      "   ✓ Detected: True, Area: 20.8%, Objects: 2\n",
      "📸 346/520: 93gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 347/520: 93gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 348/520: 93gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 349/520: 93gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 350/520: 93gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 351/520: 93gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 352/520: 93rfb (10).png\n",
      "   ✓ Detected: True, Area: 17.5%, Objects: 1\n",
      "📸 353/520: 93rfb (11).png\n",
      "   ✓ Detected: True, Area: 13.6%, Objects: 1\n",
      "📸 354/520: 93rfb (12).png\n",
      "   ✓ Detected: True, Area: 23.6%, Objects: 1\n",
      "📸 355/520: 93rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 356/520: 93rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 357/520: 93rfb (3).png\n",
      "   ✓ Detected: True, Area: 17.1%, Objects: 1\n",
      "📸 358/520: 93rfb (4).png\n",
      "   ✓ Detected: True, Area: 16.4%, Objects: 1\n",
      "📸 359/520: 93rfb (5).png\n",
      "   ✓ Detected: True, Area: 25.2%, Objects: 1\n",
      "📸 360/520: 93rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 361/520: 93rfb (7).png\n",
      "   ✓ Detected: True, Area: 19.9%, Objects: 1\n",
      "📸 362/520: 93rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 363/520: 93rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 364/520: 93rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 365/520: 94gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 366/520: 94gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 367/520: 94gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 368/520: 94gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 369/520: 94gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 370/520: 94gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 371/520: 94gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 372/520: 94gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 373/520: 94gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 374/520: 94gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 375/520: 94gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 376/520: 94gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 377/520: 94gr.png\n",
      "   ✓ Detected: True, Area: 18.5%, Objects: 2\n",
      "📸 378/520: 94rfb (10).png\n",
      "   ✓ Detected: True, Area: 21.8%, Objects: 1\n",
      "📸 379/520: 94rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 380/520: 94rfb (12).png\n",
      "   ✓ Detected: True, Area: 22.6%, Objects: 1\n",
      "📸 381/520: 94rfb (13).png\n",
      "   ✓ Detected: True, Area: 21.5%, Objects: 2\n",
      "📸 382/520: 94rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 383/520: 94rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 384/520: 94rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 385/520: 94rfb (5).png\n",
      "   ✓ Detected: True, Area: 20.7%, Objects: 3\n",
      "📸 386/520: 94rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 387/520: 94rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 388/520: 94rfb (8).png\n",
      "   ✓ Detected: True, Area: 13.5%, Objects: 2\n",
      "📸 389/520: 94rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 390/520: 94rfb.png\n",
      "   ✓ Detected: True, Area: 17.4%, Objects: 3\n",
      "📸 391/520: 95gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 392/520: 95gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 393/520: 95gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 394/520: 95gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 395/520: 95gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 396/520: 95gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 397/520: 95gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 398/520: 95gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 399/520: 95gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 400/520: 95gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 401/520: 95gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 402/520: 95gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 403/520: 95gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 404/520: 95rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 405/520: 95rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 406/520: 95rfb (12).png\n",
      "   ✓ Detected: True, Area: 26.0%, Objects: 1\n",
      "📸 407/520: 95rfb (13).png\n",
      "   ✓ Detected: True, Area: 23.9%, Objects: 1\n",
      "📸 408/520: 95rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 409/520: 95rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 410/520: 95rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 411/520: 95rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 412/520: 95rfb (6).png\n",
      "   ✓ Detected: True, Area: 24.8%, Objects: 1\n",
      "📸 413/520: 95rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 414/520: 95rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 415/520: 95rfb (9).png\n",
      "   ✓ Detected: True, Area: 15.7%, Objects: 1\n",
      "📸 416/520: 95rfb.png\n",
      "   ✓ Detected: True, Area: 22.4%, Objects: 1\n",
      "📸 417/520: 96gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 418/520: 96gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 419/520: 96gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 420/520: 96gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 421/520: 96gr (2).png\n",
      "   ✓ Detected: True, Area: 20.4%, Objects: 1\n",
      "📸 422/520: 96gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 423/520: 96gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 424/520: 96gr (5).png\n",
      "   ✓ Detected: True, Area: 21.6%, Objects: 1\n",
      "📸 425/520: 96gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 426/520: 96gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 427/520: 96gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 428/520: 96gr (9).png\n",
      "   ✓ Detected: True, Area: 19.1%, Objects: 1\n",
      "📸 429/520: 96gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 430/520: 96rfb (10).png\n",
      "   ✓ Detected: True, Area: 18.1%, Objects: 1\n",
      "📸 431/520: 96rfb (11).png\n",
      "   ✓ Detected: True, Area: 22.7%, Objects: 2\n",
      "📸 432/520: 96rfb (12).png\n",
      "   ✓ Detected: True, Area: 15.2%, Objects: 2\n",
      "📸 433/520: 96rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 434/520: 96rfb (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 435/520: 96rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 436/520: 96rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 437/520: 96rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 438/520: 96rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 439/520: 96rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 440/520: 96rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 441/520: 96rfb (9).png\n",
      "   ✓ Detected: True, Area: 23.4%, Objects: 1\n",
      "📸 442/520: 96rfb.png\n",
      "   ✓ Detected: True, Area: 19.5%, Objects: 1\n",
      "📸 443/520: 97gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 444/520: 97gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 445/520: 97gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 446/520: 97gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 447/520: 97gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 448/520: 97gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 449/520: 97gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 450/520: 97gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 451/520: 97gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 452/520: 97gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 453/520: 97gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 454/520: 97gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 455/520: 97gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 456/520: 97rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 457/520: 97rfb (11).png\n",
      "   ✓ Detected: True, Area: 14.2%, Objects: 1\n",
      "📸 458/520: 97rfb (12).png\n",
      "   ✓ Detected: True, Area: 24.6%, Objects: 2\n",
      "📸 459/520: 97rfb (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 460/520: 97rfb (2).png\n",
      "   ✓ Detected: True, Area: 25.0%, Objects: 1\n",
      "📸 461/520: 97rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 462/520: 97rfb (4).png\n",
      "   ✓ Detected: True, Area: 14.6%, Objects: 2\n",
      "📸 463/520: 97rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 464/520: 97rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 465/520: 97rfb (7).png\n",
      "   ✓ Detected: True, Area: 24.7%, Objects: 1\n",
      "📸 466/520: 97rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 467/520: 97rfb (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 468/520: 97rfb.png\n",
      "   ✓ Detected: True, Area: 15.0%, Objects: 4\n",
      "📸 469/520: 98gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 470/520: 98gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 471/520: 98gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 472/520: 98gr (13).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 473/520: 98gr (2).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 474/520: 98gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 475/520: 98gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 476/520: 98gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 477/520: 98gr (6).png\n",
      "   ✓ Detected: True, Area: 24.6%, Objects: 1\n",
      "📸 478/520: 98gr (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 479/520: 98gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 480/520: 98gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 481/520: 98gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 482/520: 98rfb (10).png\n",
      "   ✓ Detected: True, Area: 21.1%, Objects: 1\n",
      "📸 483/520: 98rfb (11).png\n",
      "   ✓ Detected: True, Area: 23.1%, Objects: 1\n",
      "📸 484/520: 98rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 485/520: 98rfb (13).png\n",
      "   ✓ Detected: True, Area: 18.7%, Objects: 2\n",
      "📸 486/520: 98rfb (2).png\n",
      "   ✓ Detected: True, Area: 15.8%, Objects: 2\n",
      "📸 487/520: 98rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 488/520: 98rfb (4).png\n",
      "   ✓ Detected: True, Area: 17.4%, Objects: 1\n",
      "📸 489/520: 98rfb (5).png\n",
      "   ✓ Detected: True, Area: 20.9%, Objects: 2\n",
      "📸 490/520: 98rfb (6).png\n",
      "   ✓ Detected: True, Area: 24.2%, Objects: 1\n",
      "📸 491/520: 98rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 492/520: 98rfb (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 493/520: 98rfb (9).png\n",
      "   ✓ Detected: True, Area: 18.1%, Objects: 1\n",
      "📸 494/520: 98rfb.png\n",
      "   ✓ Detected: True, Area: 17.3%, Objects: 2\n",
      "📸 495/520: 99gr (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 496/520: 99gr (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 497/520: 99gr (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 498/520: 99gr (13).png\n",
      "   ✓ Detected: True, Area: 22.5%, Objects: 1\n",
      "📸 499/520: 99gr (2).png\n",
      "   ✓ Detected: True, Area: 24.3%, Objects: 1\n",
      "📸 500/520: 99gr (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 501/520: 99gr (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 502/520: 99gr (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 503/520: 99gr (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 504/520: 99gr (7).png\n",
      "   ✓ Detected: True, Area: 22.0%, Objects: 1\n",
      "📸 505/520: 99gr (8).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 506/520: 99gr (9).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 507/520: 99gr.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 508/520: 99rfb (10).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 509/520: 99rfb (11).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 510/520: 99rfb (12).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 511/520: 99rfb (13).png\n",
      "   ✓ Detected: True, Area: 25.1%, Objects: 2\n",
      "📸 512/520: 99rfb (2).png\n",
      "   ✓ Detected: True, Area: 25.9%, Objects: 2\n",
      "📸 513/520: 99rfb (3).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 514/520: 99rfb (4).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 515/520: 99rfb (5).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 516/520: 99rfb (6).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 517/520: 99rfb (7).png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "📸 518/520: 99rfb (8).png\n",
      "   ✓ Detected: True, Area: 20.8%, Objects: 1\n",
      "📸 519/520: 99rfb (9).png\n",
      "   ✓ Detected: True, Area: 19.1%, Objects: 2\n",
      "📸 520/520: 99rfb.png\n",
      "   ✗ Detected: False, Area: -, Objects: 0\n",
      "\n",
      "📊 YOLO BATCH PROCESSING RESULTS:\n",
      "   Total images: 520\n",
      "   Ears detected: 146\n",
      "   Detection rate: 28.1%\n",
      "   Total ear objects found: 196\n",
      "   Results saved to: yolo_output\n",
      "📄 Summary saved: yolo_output\\processing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# batch_segment_ears.py\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class YOLOEarSegmenter:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the YOLO segmentation model\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO(self.model_path)\n",
    "            print(f\"✅ YOLO model loaded: {self.model_path}\")\n",
    "            print(f\"✅ Model type: {self.model.task}\")  # Should be 'segment'\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading YOLO model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process_image(self, image_path, output_dir=\"yolo_output\", conf=0.5):\n",
    "        \"\"\"Process a single image with YOLO segmentation\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ Model not loaded\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            results = self.model.predict(image_path, imgsz=640, conf=conf, verbose=False)\n",
    "            \n",
    "            if len(results) == 0:\n",
    "                return None\n",
    "            \n",
    "            result = results[0]\n",
    "            \n",
    "            # Create output directory\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            base_name = Path(image_path).stem\n",
    "            \n",
    "            # Check if any ears were detected\n",
    "            ear_detected = len(result.boxes) > 0 if result.boxes is not None else False\n",
    "            \n",
    "            # Save annotated image\n",
    "            annotated_img = result.plot()\n",
    "            annotated_path = os.path.join(output_dir, f\"{base_name}_annotated.jpg\")\n",
    "            cv2.imwrite(annotated_path, annotated_img)\n",
    "            \n",
    "            # Save mask if available\n",
    "            mask_path = None\n",
    "            if result.masks is not None and len(result.masks) > 0:\n",
    "                # Get the first mask (assuming one ear per image)\n",
    "                mask = result.masks[0].data[0].cpu().numpy()\n",
    "                mask = (mask * 255).astype(np.uint8)\n",
    "                mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "                cv2.imwrite(mask_path, mask)\n",
    "            \n",
    "            # Calculate area percentage\n",
    "            area_percent = 0\n",
    "            if ear_detected and result.masks is not None:\n",
    "                total_pixels = mask.shape[0] * mask.shape[1]\n",
    "                ear_pixels = np.sum(mask > 0)\n",
    "                area_percent = (ear_pixels / total_pixels) * 100\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'ear_detected': ear_detected,\n",
    "                'area_percent': area_percent,\n",
    "                'annotated_path': annotated_path,\n",
    "                'mask_path': mask_path,\n",
    "                'num_detections': len(result.boxes) if result.boxes is not None else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def batch_process(self, input_dir, output_dir=\"yolo_batch_output\", conf=0.5, max_images=None):\n",
    "        \"\"\"Process all images in a directory\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ Model not loaded\")\n",
    "            return\n",
    "        \n",
    "        # Find images\n",
    "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(glob.glob(os.path.join(input_dir, ext)))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"❌ No images found in {input_dir}\")\n",
    "            return\n",
    "        \n",
    "        if max_images:\n",
    "            image_files = image_files[:max_images]\n",
    "        \n",
    "        print(f\"🔍 Processing {len(image_files)} images from {input_dir}\")\n",
    "        \n",
    "        results = []\n",
    "        for i, img_path in enumerate(image_files):\n",
    "            print(f\"📸 {i+1}/{len(image_files)}: {os.path.basename(img_path)}\")\n",
    "            \n",
    "            result = self.process_image(img_path, output_dir, conf)\n",
    "            if result:\n",
    "                status = \"✓\" if result['ear_detected'] else \"✗\"\n",
    "                area_info = f\"{result['area_percent']:.1f}%\" if result['ear_detected'] else \"-\"\n",
    "                detections = result['num_detections'] if result['ear_detected'] else 0\n",
    "                \n",
    "                print(f\"   {status} Detected: {result['ear_detected']}, Area: {area_info}, Objects: {detections}\")\n",
    "                \n",
    "                results.append((img_path, result['ear_detected'], result['area_percent'], result['num_detections']))\n",
    "            else:\n",
    "                print(f\"   ✗ Processing failed\")\n",
    "                results.append((img_path, False, 0, 0))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        detected_count = sum(1 for _, detected, _, _ in results if detected)\n",
    "        detection_rate = (detected_count / len(results)) * 100\n",
    "        total_detections = sum(detections for _, _, _, detections in results)\n",
    "        \n",
    "        print(f\"\\n📊 YOLO BATCH PROCESSING RESULTS:\")\n",
    "        print(f\"   Total images: {len(results)}\")\n",
    "        print(f\"   Ears detected: {detected_count}\")\n",
    "        print(f\"   Detection rate: {detection_rate:.1f}%\")\n",
    "        print(f\"   Total ear objects found: {total_detections}\")\n",
    "        print(f\"   Results saved to: {output_dir}\")\n",
    "        \n",
    "        # Save results summary\n",
    "        self.save_summary(results, output_dir)\n",
    "        return results\n",
    "    \n",
    "    def save_summary(self, results, output_dir):\n",
    "        \"\"\"Save processing summary to CSV\"\"\"\n",
    "        summary_path = os.path.join(output_dir, \"processing_summary.csv\")\n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(\"Image,Ear_Detected,Area_Percent,Num_Detections\\n\")\n",
    "            for img_path, detected, area, detections in results:\n",
    "                f.write(f\"{os.path.basename(img_path)},{detected},{area:.2f},{detections}\\n\")\n",
    "        print(f\"📄 Summary saved: {summary_path}\")\n",
    "\n",
    "def main():\n",
    "    print(\"🚀 YOLO Ear Segmentation Batch Processing\")\n",
    "    \n",
    "    # Initialize with your YOLO model\n",
    "    model_path = r\"A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\"\n",
    "    segmenter = YOLOEarSegmenter(model_path)\n",
    "    \n",
    "    if segmenter.model is None:\n",
    "        print(\"❌ Failed to load YOLO model\")\n",
    "        return\n",
    "    \n",
    "    # Test the model on your dataset\n",
    "    input_directory = \"input_2\"  # Your 520-image dataset\n",
    "    if os.path.exists(input_directory):\n",
    "        print(f\"🎯 Processing: {input_directory}\")\n",
    "        \n",
    "        # You can adjust confidence threshold here (0.5 is default)\n",
    "        results = segmenter.batch_process(\n",
    "            input_directory, \n",
    "            \"yolo_output\", \n",
    "            conf=0.5,  # Lower to 0.3 if missing detections, raise to 0.7 if too many false positives\n",
    "            max_images=None  # Process all images\n",
    "        )\n",
    "    else:\n",
    "        print(f\"❌ Directory not found: {input_directory}\")\n",
    "        print(\"💡 Please update the input_directory path\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f3d7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 YOLO Ear Segmentation Batch Processing\n",
      "✅ YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "✅ Model type: segment\n",
      "🎯 Processing: input\n",
      "🔍 Processing 5 images from input\n",
      "📸 1/5: 2D EAR 1.jpg\n",
      "   ✓ Detected: True, Area: 13.7%, Objects: 1\n",
      "📸 2/5: 2D EAR 2.jpg\n",
      "   ✓ Detected: True, Area: 19.0%, Objects: 1\n",
      "📸 3/5: 2D EAR 3.jpg\n",
      "   ✓ Detected: True, Area: 13.0%, Objects: 1\n",
      "📸 4/5: 2D EAR 4.jpg\n",
      "   ✓ Detected: True, Area: 9.1%, Objects: 1\n",
      "📸 5/5: 2D EAR 5.jpg\n",
      "   ✓ Detected: True, Area: 12.2%, Objects: 1\n",
      "\n",
      "📊 YOLO BATCH PROCESSING RESULTS:\n",
      "   Total images: 5\n",
      "   Ears detected: 5\n",
      "   Detection rate: 100.0%\n",
      "   Total ear objects found: 5\n",
      "   Results saved to: yolo_output\n",
      "📄 Summary saved: yolo_output\\processing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# batch_segment_ears.py\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class YOLOEarSegmenter:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the YOLO segmentation model\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO(self.model_path)\n",
    "            print(f\"✅ YOLO model loaded: {self.model_path}\")\n",
    "            print(f\"✅ Model type: {self.model.task}\")  # Should be 'segment'\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading YOLO model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def process_image(self, image_path, output_dir=\"yolo_output\", conf=0.5):\n",
    "        \"\"\"Process a single image with YOLO segmentation\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ Model not loaded\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            results = self.model.predict(image_path, imgsz=640, conf=conf, verbose=False)\n",
    "            \n",
    "            if len(results) == 0:\n",
    "                return None\n",
    "            \n",
    "            result = results[0]\n",
    "            \n",
    "            # Create output directory\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            base_name = Path(image_path).stem\n",
    "            \n",
    "            # Check if any ears were detected\n",
    "            ear_detected = len(result.boxes) > 0 if result.boxes is not None else False\n",
    "            \n",
    "            # Save annotated image\n",
    "            annotated_img = result.plot()\n",
    "            annotated_path = os.path.join(output_dir, f\"{base_name}_annotated.jpg\")\n",
    "            cv2.imwrite(annotated_path, annotated_img)\n",
    "            \n",
    "            # Save mask if available\n",
    "            mask_path = None\n",
    "            if result.masks is not None and len(result.masks) > 0:\n",
    "                # Get the first mask (assuming one ear per image)\n",
    "                mask = result.masks[0].data[0].cpu().numpy()\n",
    "                mask = (mask * 255).astype(np.uint8)\n",
    "                mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")\n",
    "                cv2.imwrite(mask_path, mask)\n",
    "            \n",
    "            # Calculate area percentage\n",
    "            area_percent = 0\n",
    "            if ear_detected and result.masks is not None:\n",
    "                total_pixels = mask.shape[0] * mask.shape[1]\n",
    "                ear_pixels = np.sum(mask > 0)\n",
    "                area_percent = (ear_pixels / total_pixels) * 100\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'ear_detected': ear_detected,\n",
    "                'area_percent': area_percent,\n",
    "                'annotated_path': annotated_path,\n",
    "                'mask_path': mask_path,\n",
    "                'num_detections': len(result.boxes) if result.boxes is not None else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def batch_process(self, input_dir, output_dir=\"yolo_batch_output\", conf=0.5, max_images=None):\n",
    "        \"\"\"Process all images in a directory\"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"❌ Model not loaded\")\n",
    "            return\n",
    "        \n",
    "        # Find images\n",
    "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(glob.glob(os.path.join(input_dir, ext)))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"❌ No images found in {input_dir}\")\n",
    "            return\n",
    "        \n",
    "        if max_images:\n",
    "            image_files = image_files[:max_images]\n",
    "        \n",
    "        print(f\"🔍 Processing {len(image_files)} images from {input_dir}\")\n",
    "        \n",
    "        results = []\n",
    "        for i, img_path in enumerate(image_files):\n",
    "            print(f\"📸 {i+1}/{len(image_files)}: {os.path.basename(img_path)}\")\n",
    "            \n",
    "            result = self.process_image(img_path, output_dir, conf)\n",
    "            if result:\n",
    "                status = \"✓\" if result['ear_detected'] else \"✗\"\n",
    "                area_info = f\"{result['area_percent']:.1f}%\" if result['ear_detected'] else \"-\"\n",
    "                detections = result['num_detections'] if result['ear_detected'] else 0\n",
    "                \n",
    "                print(f\"   {status} Detected: {result['ear_detected']}, Area: {area_info}, Objects: {detections}\")\n",
    "                \n",
    "                results.append((img_path, result['ear_detected'], result['area_percent'], result['num_detections']))\n",
    "            else:\n",
    "                print(f\"   ✗ Processing failed\")\n",
    "                results.append((img_path, False, 0, 0))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        detected_count = sum(1 for _, detected, _, _ in results if detected)\n",
    "        detection_rate = (detected_count / len(results)) * 100\n",
    "        total_detections = sum(detections for _, _, _, detections in results)\n",
    "        \n",
    "        print(f\"\\n📊 YOLO BATCH PROCESSING RESULTS:\")\n",
    "        print(f\"   Total images: {len(results)}\")\n",
    "        print(f\"   Ears detected: {detected_count}\")\n",
    "        print(f\"   Detection rate: {detection_rate:.1f}%\")\n",
    "        print(f\"   Total ear objects found: {total_detections}\")\n",
    "        print(f\"   Results saved to: {output_dir}\")\n",
    "        \n",
    "        # Save results summary\n",
    "        self.save_summary(results, output_dir)\n",
    "        return results\n",
    "    \n",
    "    def save_summary(self, results, output_dir):\n",
    "        \"\"\"Save processing summary to CSV\"\"\"\n",
    "        summary_path = os.path.join(output_dir, \"processing_summary.csv\")\n",
    "        with open(summary_path, 'w') as f:\n",
    "            f.write(\"Image,Ear_Detected,Area_Percent,Num_Detections\\n\")\n",
    "            for img_path, detected, area, detections in results:\n",
    "                f.write(f\"{os.path.basename(img_path)},{detected},{area:.2f},{detections}\\n\")\n",
    "        print(f\"📄 Summary saved: {summary_path}\")\n",
    "\n",
    "def main():\n",
    "    print(\"🚀 YOLO Ear Segmentation Batch Processing\")\n",
    "    \n",
    "    # Initialize with your YOLO model\n",
    "    model_path = r\"A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\"\n",
    "    segmenter = YOLOEarSegmenter(model_path)\n",
    "    \n",
    "    if segmenter.model is None:\n",
    "        print(\"❌ Failed to load YOLO model\")\n",
    "        return\n",
    "    \n",
    "    # Test the model on your dataset\n",
    "    input_directory = \"input\"  \n",
    "    if os.path.exists(input_directory):\n",
    "        print(f\"🎯 Processing: {input_directory}\")\n",
    "        \n",
    "        # You can adjust confidence threshold here (0.5 is default)\n",
    "        results = segmenter.batch_process(\n",
    "            input_directory, \n",
    "            \"yolo_output\", \n",
    "            conf=0.5,  # Lower to 0.3 if missing detections, raise to 0.7 if too many false positives\n",
    "            max_images=None  # Process all images\n",
    "        )\n",
    "    else:\n",
    "        print(f\"❌ Directory not found: {input_directory}\")\n",
    "        print(\"💡 Please update the input_directory path\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6665c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python pillow numpy tkinter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ear_seg_env.venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
