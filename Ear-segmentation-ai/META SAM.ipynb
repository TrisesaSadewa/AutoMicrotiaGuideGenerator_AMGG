{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91853989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Cleaning up conflicting packages and fixing environment...\n",
      "   EXEC: a:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_seg_env.venv\\Scripts\\python.exe -m pip uninstall -y earsegmentationai sam-2 torch torchvision torchaudio numpy\n",
      "\n",
      "â¬‡ï¸ INSTALLING NUMPY: a:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_seg_env.venv\\Scripts\\python.exe -m pip install numpy<2.0.0 --no-cache-dir\n",
      "\n",
      "â¬‡ï¸ INSTALLING TORCH: a:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_seg_env.venv\\Scripts\\python.exe -m pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu117 --no-cache-dir\n",
      "\n",
      "â¬‡ï¸ INSTALLING DEPS: a:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_seg_env.venv\\Scripts\\python.exe -m pip install numpy<2.0.0 ultralytics opencv-python matplotlib scipy numpy-stl segment-anything\n",
      "\n",
      "âœ… Environment Repair Complete!\n",
      "ğŸ“¢ PLEASE RESTART THE KERNEL NOW (Kernel > Restart) before running your code.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"ğŸ§¹ Cleaning up conflicting packages and fixing environment...\")\n",
    "\n",
    "python_exe = sys.executable\n",
    "\n",
    "# 1. UNINSTALL conflicts first\n",
    "# We remove 'earsegmentationai' and 'sam-2' because they enforce broken dependency rules.\n",
    "# We also remove numpy/torch to ensure a clean re-link.\n",
    "uninstall_cmd = [\n",
    "    python_exe, \"-m\", \"pip\", \"uninstall\", \"-y\",\n",
    "    \"earsegmentationai\",\n",
    "    \"sam-2\",\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"torchaudio\",\n",
    "    \"numpy\" \n",
    "]\n",
    "\n",
    "print(f\"   EXEC: {' '.join(uninstall_cmd)}\")\n",
    "try:\n",
    "    subprocess.check_call(uninstall_cmd)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"   âš ï¸ Warning: Some packages were not found (this is fine).\")\n",
    "\n",
    "# 2. INSTALL NUMPY (CRITICAL FIX)\n",
    "# We strictly pin numpy < 2.0.0 because PyTorch 2.0.1 crashes with NumPy 2.x\n",
    "# We install this FIRST so Torch links against it correctly.\n",
    "install_numpy_cmd = [\n",
    "    python_exe, \"-m\", \"pip\", \"install\",\n",
    "    \"numpy<2.0.0\",\n",
    "    \"--no-cache-dir\"\n",
    "]\n",
    "\n",
    "print(f\"\\nâ¬‡ï¸ INSTALLING NUMPY: {' '.join(install_numpy_cmd)}\")\n",
    "subprocess.check_call(install_numpy_cmd)\n",
    "\n",
    "# 3. INSTALL the correct Torch stack (Torch 2.0.1 + CUDA 11.7)\n",
    "install_torch_cmd = [\n",
    "    python_exe, \"-m\", \"pip\", \"install\",\n",
    "    \"torch==2.0.1\",\n",
    "    \"torchvision==0.15.2\",\n",
    "    \"torchaudio==2.0.2\",\n",
    "    \"--index-url\", \"https://download.pytorch.org/whl/cu117\",\n",
    "    \"--no-cache-dir\"\n",
    "]\n",
    "\n",
    "print(f\"\\nâ¬‡ï¸ INSTALLING TORCH: {' '.join(install_torch_cmd)}\")\n",
    "subprocess.check_call(install_torch_cmd)\n",
    "\n",
    "# 4. INSTALL required libraries\n",
    "# CRITICAL: We add \"numpy<2.0.0\" here again to prevent ultralytics/scipy from upgrading it\n",
    "install_deps_cmd = [\n",
    "    python_exe, \"-m\", \"pip\", \"install\",\n",
    "    \"numpy<2.0.0\",\n",
    "    \"ultralytics\",\n",
    "    \"opencv-python\",\n",
    "    \"matplotlib\",\n",
    "    \"scipy\",\n",
    "    \"numpy-stl\",\n",
    "    \"segment-anything\"\n",
    "]\n",
    "\n",
    "print(f\"\\nâ¬‡ï¸ INSTALLING DEPS: {' '.join(install_deps_cmd)}\")\n",
    "subprocess.check_call(install_deps_cmd)\n",
    "\n",
    "print(\"\\nâœ… Environment Repair Complete!\")\n",
    "print(\"ğŸ“¢ PLEASE RESTART THE KERNEL NOW (Kernel > Restart) before running your code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d53c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install samgeo\n",
    "#pip install --upgrade samgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d79c90d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ WORKING MODELS CONFIRMED:\n",
      "   âœ… YOLO: Available\n",
      "   âœ… SAM: Available\n",
      "   âŒ Transformers: Skipped (protobuf issue)\n",
      "   âŒ MediaPipe: Not available\n",
      "\n",
      "ğŸ“ Surgical Guide Specifications:\n",
      "   Base thickness: 2.0mm\n",
      "   Helix thickness: 5.0mm\n",
      "   Skin tolerance: 2.0mm\n",
      "   Suture holes: 1.2x2.7mm\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ WORKING MODELS CONFIRMED:\")\n",
    "print(f\"   âœ… YOLO: Available\")\n",
    "print(f\"   âœ… SAM: Available\")\n",
    "print(f\"   âŒ Transformers: Skipped (protobuf issue)\")\n",
    "print(f\"   âŒ MediaPipe: Not available\")\n",
    "\n",
    "# Microtia guide parameters\n",
    "BASE_THICKNESS = 2.0\n",
    "HELIX_THICKNESS = 5.0\n",
    "SKIN_TOLERANCE = 2.0\n",
    "SUTURE_HOLE_SIZE = (1.2, 2.7)\n",
    "\n",
    "print(f\"\\nğŸ“ Surgical Guide Specifications:\")\n",
    "print(f\"   Base thickness: {BASE_THICKNESS}mm\")\n",
    "print(f\"   Helix thickness: {HELIX_THICKNESS}mm\") \n",
    "print(f\"   Skin tolerance: {SKIN_TOLERANCE}mm\")\n",
    "print(f\"   Suture holes: {SUTURE_HOLE_SIZE[0]}x{SUTURE_HOLE_SIZE[1]}mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36da08f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MicrotiaSurgicalGuide class defined!\n",
      "âœ… numpy-stl imported successfully. 3D generation is ENABLED.\n",
      "âœ… Torch imported: 2.0.1+cu117\n",
      "âœ… Device ready: cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "class MicrotiaSurgicalGuide:\n",
    "    def __init__(self, yolo_model_path):\n",
    "        self.yolo_model_path = yolo_model_path\n",
    "        self.yolo_model = None\n",
    "        self.sam_predictor = None\n",
    "        \n",
    "        self.load_models()\n",
    "        \n",
    "        # Surgical guide parameters\n",
    "        self.base_thickness = 2.0\n",
    "        self.helix_thickness = 5.0\n",
    "        self.skin_tolerance = 2.0\n",
    "        self.suture_hole_size = (1.2, 2.7)\n",
    "    \n",
    "    def download_sam_checkpoint(self):\n",
    "        \"\"\"Download SAM checkpoint if needed\"\"\"\n",
    "        import urllib.request\n",
    "        sam_checkpoints = {\n",
    "            \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n",
    "            \"vit_l\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\"\n",
    "        }\n",
    "        \n",
    "        checkpoint_dir = \"sam_checkpoints\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Try to find existing checkpoint\n",
    "        for model_type, url in sam_checkpoints.items():\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"sam_{model_type}.pth\")\n",
    "            if os.path.exists(checkpoint_path):\n",
    "                print(f\"ğŸ“ Found existing SAM checkpoint: {checkpoint_path}\")\n",
    "                return checkpoint_path, model_type\n",
    "        \n",
    "        # Download vit_b (smallest) if none found\n",
    "        print(\"ğŸ“¥ Downloading SAM checkpoint (vit_b)...\")\n",
    "        model_type = \"vit_b\"\n",
    "        url = sam_checkpoints[model_type]\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"sam_{model_type}.pth\")\n",
    "        \n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, checkpoint_path)\n",
    "            print(f\"âœ… Downloaded SAM checkpoint: {checkpoint_path}\")\n",
    "            return checkpoint_path, model_type\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to download SAM checkpoint: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"Load YOLO and SAM models\"\"\"\n",
    "        # Load YOLO\n",
    "        try:\n",
    "            self.yolo_model = YOLO(self.yolo_model_path)\n",
    "            print(f\"âœ… YOLO model loaded: {self.yolo_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading YOLO model: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Load SAM\n",
    "        try:\n",
    "            checkpoint_path, model_type = self.download_sam_checkpoint()\n",
    "            if checkpoint_path and model_type:\n",
    "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "                sam.to(device=device)\n",
    "                self.sam_predictor = SamPredictor(sam)\n",
    "                print(f\"âœ… SAM model loaded ({model_type}) on {device}\")\n",
    "            else:\n",
    "                print(\"âŒ Could not load SAM model\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading SAM model: {e}\")\n",
    "    \n",
    "    def yolo_sam_hybrid_segment(self, image_path, conf=0.3):\n",
    "        \"\"\"\n",
    "        Hybrid segmentation: YOLO for detection + SAM for precise segmentation\n",
    "        \"\"\"\n",
    "        print(f\"   ğŸ” Running YOLO+SAM hybrid segmentation...\")\n",
    "        \n",
    "        # Step 1: YOLO detection\n",
    "        yolo_results = self.yolo_model.predict(image_path, imgsz=640, conf=conf, verbose=False)\n",
    "        \n",
    "        if len(yolo_results) == 0 or yolo_results[0].boxes is None:\n",
    "            print(\"   âŒ YOLO: No ears detected\")\n",
    "            return None\n",
    "        \n",
    "        # Get bounding box from YOLO\n",
    "        bbox = yolo_results[0].boxes.xyxy[0].cpu().numpy()\n",
    "        print(f\"   ğŸ“¦ YOLO detected ear with bbox: {bbox}\")\n",
    "        \n",
    "        # Step 2: SAM segmentation with YOLO bbox as prompt\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        try:\n",
    "            self.sam_predictor.set_image(image_rgb)\n",
    "            \n",
    "            # Use YOLO bbox as prompt for SAM\n",
    "            input_box = np.array(bbox)\n",
    "            masks, scores, logits = self.sam_predictor.predict(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                box=input_box[None, :],\n",
    "                multimask_output=False,  # Get single best mask\n",
    "            )\n",
    "            \n",
    "            best_mask = masks[0]\n",
    "            sam_mask = (best_mask * 255).astype(np.uint8)\n",
    "            \n",
    "            print(f\"   âœ… SAM: Generated high-quality mask (score: {scores[0]:.3f})\")\n",
    "            return sam_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ SAM segmentation failed: {e}\")\n",
    "            # Fallback to YOLO mask\n",
    "            if yolo_results[0].masks is not None:\n",
    "                yolo_mask = yolo_results[0].masks[0].data[0].cpu().numpy()\n",
    "                yolo_mask = (yolo_mask * 255).astype(np.uint8)\n",
    "                print(\"   ğŸ”„ Using YOLO mask as fallback\")\n",
    "                return yolo_mask\n",
    "            return None\n",
    "    \n",
    "    def preprocess_mask(self, mask):\n",
    "        \"\"\"Clean and SMOOTH mask for 3D modeling (FR-05)\"\"\"\n",
    "        if mask.dtype != np.uint8:\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # 1. Upscale for better resolution before smoothing (2x)\n",
    "        mask = cv2.resize(mask, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # 2. Threshold\n",
    "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # 3. Clean noise (Morphological Open/Close)\n",
    "        kernel = np.ones((5,5), np.uint8) # Increased kernel size\n",
    "        cleaned_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # 4. GAUSSIAN BLUR (The key to removing pixels)\n",
    "        # Blur the edges, then threshold back to crisp lines\n",
    "        blurred = cv2.GaussianBlur(cleaned_mask, (15, 15), 0)\n",
    "        _, smooth_mask = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # 5. Keep only largest contour\n",
    "        contours, _ = cv2.findContours(smooth_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        final_mask = np.zeros_like(smooth_mask)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            cv2.fillPoly(final_mask, [largest_contour], 255)\n",
    "            \n",
    "        # 6. Downscale back to original (optional, or keep high res for better 3D)\n",
    "        # We will keep it 2x because it makes the 3D model smoother\n",
    "        \n",
    "        return final_mask\n",
    "    \n",
    "    def create_contours_with_tolerance(self, mask, tolerance_mm, pixels_per_mm=10):\n",
    "        \"\"\"Create outer and inner contours with skin tolerance\"\"\"\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            return None, None\n",
    "            \n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "        tolerance_pixels = int(tolerance_mm * pixels_per_mm)\n",
    "        \n",
    "        # Create outer contour (expanded for skin tolerance)\n",
    "        outer_contour = self.offset_contour(main_contour, tolerance_pixels)\n",
    "        \n",
    "        return outer_contour, main_contour  # outer=base, inner=helix\n",
    "    \n",
    "    def offset_contour(self, contour, offset_pixels):\n",
    "        \"\"\"Offset contour by specified distance\"\"\"\n",
    "        if offset_pixels == 0:\n",
    "            return contour\n",
    "            \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        padding = abs(offset_pixels) + 10\n",
    "        \n",
    "        mask = np.zeros((h + 2 * padding, w + 2 * padding), dtype=np.uint8)\n",
    "        contour_shifted = contour - [x, y] + [padding, padding]\n",
    "        cv2.fillPoly(mask, [contour_shifted], 255)\n",
    "        \n",
    "        kernel_size = abs(offset_pixels) * 2 + 1\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        \n",
    "        if offset_pixels > 0:\n",
    "            processed_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        else:\n",
    "            processed_mask = cv2.erate(mask, kernel, iterations=1)\n",
    "            \n",
    "        new_contours, _ = cv2.findContours(processed_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if new_contours:\n",
    "            new_contour = max(new_contours, key=cv2.contourArea)\n",
    "            return new_contour + [x - padding, y - padding]\n",
    "        return contour\n",
    "    \n",
    "    def find_curvature_points(self, contour, num_points=2):\n",
    "        \"\"\"Find high curvature points for suture holes\"\"\"\n",
    "        if contour is None or len(contour) < 3:\n",
    "            return []\n",
    "            \n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx_contour = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        points = approx_contour.reshape(-1, 2)\n",
    "        \n",
    "        if len(points) < 3:\n",
    "            return []\n",
    "        \n",
    "        curvatures = []\n",
    "        for i in range(len(points)):\n",
    "            p1 = points[i-1]\n",
    "            p2 = points[i]\n",
    "            p3 = points[(i+1) % len(points)]\n",
    "            \n",
    "            v1 = p1 - p2\n",
    "            v2 = p3 - p2\n",
    "            \n",
    "            dot_product = np.dot(v1, v2)\n",
    "            norm_v1 = np.linalg.norm(v1)\n",
    "            norm_v2 = np.linalg.norm(v2)\n",
    "            \n",
    "            if norm_v1 == 0 or norm_v2 == 0:\n",
    "                continue\n",
    "                \n",
    "            cosine = dot_product / (norm_v1 * norm_v2)\n",
    "            cosine = np.clip(cosine, -1.0, 1.0)\n",
    "            angle = np.arccos(cosine)\n",
    "            curvature = np.pi - angle  # Higher for sharper angles\n",
    "            \n",
    "            curvatures.append((p2[0], p2[1], curvature))\n",
    "        \n",
    "        if not curvatures:\n",
    "            return []\n",
    "            \n",
    "        # Sort by curvature and take top points\n",
    "        curvatures.sort(key=lambda x: x[2], reverse=True)\n",
    "        suture_points = [(x, y) for x, y, curvature in curvatures[:num_points]]\n",
    "        \n",
    "        return suture_points\n",
    "\n",
    "print(\"âœ… MicrotiaSurgicalGuide class defined!\")\n",
    "\n",
    "# Fix for STL_AVAILABLE\n",
    "try:\n",
    "    from stl import mesh\n",
    "    STL_AVAILABLE = True\n",
    "    print(\"âœ… numpy-stl imported successfully. 3D generation is ENABLED.\")\n",
    "except ImportError:\n",
    "    STL_AVAILABLE = False\n",
    "    print(\"âŒ numpy-stl not found. 3D generation will be SKIPPED.\")\n",
    "    print(\"   Run: !pip install numpy-stl\")\n",
    "\n",
    "print(f\"âœ… Torch imported: {torch.__version__}\")\n",
    "print(f\"âœ… Device ready: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa4f91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stl import mesh\n",
    "import cv2\n",
    "import math\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "# --- 1. GEOMETRY HELPERS (SMOOTHING & FACES) ---\n",
    "\n",
    "def resample_contour(contour, n_points=500, smooth_factor=0.01):\n",
    "    \"\"\"\n",
    "    Uses B-Spline interpolation to turn a jagged contour into a smooth, organic curve.\n",
    "    Matches FR-05 (Contour Smoothing) requirements.\n",
    "    \"\"\"\n",
    "    if len(contour.shape) > 2:\n",
    "        contour = contour.squeeze()\n",
    "        \n",
    "    # Close the contour loop\n",
    "    if not np.array_equal(contour[0], contour[-1]):\n",
    "        contour = np.vstack((contour, contour[0]))\n",
    "    \n",
    "    # Need at least 4 points for cubic spline\n",
    "    if len(contour) < 4:\n",
    "        return contour\n",
    "        \n",
    "    x, y = contour.T\n",
    "    try:\n",
    "        # Create Spline (k=3 cubic, s=smoothness)\n",
    "        tck, u = splprep([x, y], u=None, s=smooth_factor * len(contour), per=1, k=3)\n",
    "        # Generate new even points\n",
    "        u_new = np.linspace(u.min(), u.max(), n_points)\n",
    "        x_new, y_new = splev(u_new, tck, der=0)\n",
    "        return np.column_stack((x_new, y_new)).astype(np.float32)\n",
    "    except Exception:\n",
    "        return contour\n",
    "\n",
    "def create_strip_faces(n_points, start_idx_A, start_idx_B):\n",
    "    \"\"\"Connect two rings of points with triangles\"\"\"\n",
    "    faces = []\n",
    "    for i in range(n_points - 1):\n",
    "        faces.append([start_idx_A + i, start_idx_B + i, start_idx_A + i + 1])\n",
    "        faces.append([start_idx_B + i, start_idx_B + i + 1, start_idx_A + i + 1])\n",
    "    # Close loop\n",
    "    faces.append([start_idx_A + n_points - 1, start_idx_B + n_points - 1, start_idx_A])\n",
    "    faces.append([start_idx_B + n_points - 1, start_idx_B, start_idx_A])\n",
    "    return faces\n",
    "\n",
    "# --- 2. SUTURE HOLE GENERATOR (NEW) ---\n",
    "\n",
    "def create_suture_holes_stl(suture_points, output_path, thickness=10.0, hole_radius=0.8):\n",
    "    \"\"\"\n",
    "    Generates a separate STL of 'Drill Bits' to subtract from the main guide.\n",
    "    \"\"\"\n",
    "    if not suture_points: return False\n",
    "    print(f\"   ğŸ•³ï¸ Generating Suture Hole Cutters ({len(suture_points)} holes)...\")\n",
    "    \n",
    "    all_faces = []\n",
    "    all_vertices = []\n",
    "    segments = 12 # Cylinder smoothness\n",
    "    \n",
    "    for cx, cy in suture_points:\n",
    "        start_idx = len(all_vertices)\n",
    "        # Bottom circle\n",
    "        for i in range(segments):\n",
    "            angle = 2 * math.pi * i / segments\n",
    "            all_vertices.append([cx + hole_radius*math.cos(angle), cy + hole_radius*math.sin(angle), -5])\n",
    "        # Top circle\n",
    "        for i in range(segments):\n",
    "            angle = 2 * math.pi * i / segments\n",
    "            all_vertices.append([cx + hole_radius*math.cos(angle), cy + hole_radius*math.sin(angle), thickness+5])\n",
    "            \n",
    "        # Faces\n",
    "        for i in range(segments):\n",
    "            next_i = (i + 1) % segments\n",
    "            all_faces.append([start_idx+i, start_idx+next_i, start_idx+i+segments])\n",
    "            all_faces.append([start_idx+next_i, start_idx+next_i+segments, start_idx+i+segments])\n",
    "\n",
    "    # Save STL\n",
    "    hole_mesh = mesh.Mesh(np.zeros(len(all_faces), dtype=mesh.Mesh.dtype))\n",
    "    for i, face in enumerate(all_faces):\n",
    "        for j in range(3):\n",
    "            hole_mesh.vectors[i][j] = all_vertices[face[j]]\n",
    "    hole_mesh.save(output_path)\n",
    "    return True\n",
    "\n",
    "# --- 3. MAIN HOLLOW GUIDE GENERATOR ---\n",
    "\n",
    "def create_hollow_guide_model(outer_contour, main_contour, output_path, \n",
    "                              base_thickness=2.0, helix_thickness=5.0, \n",
    "                              wall_width_mm=3.0, scale_factor=0.1):\n",
    "    \"\"\"Generates the Smooth Hollow Surgical Guide\"\"\"\n",
    "    if 'STL_AVAILABLE' in globals() and not STL_AVAILABLE: return False\n",
    "    print(f\"   ğŸ“ Generating SMOOTH HOLLOW guide...\")\n",
    "    \n",
    "    try:\n",
    "        # A. Create Inner Void Contour\n",
    "        pixels_per_mm = 10 \n",
    "        wall_offset_pixels = int(wall_width_mm * pixels_per_mm)\n",
    "        \n",
    "        # Calculate Offset\n",
    "        M = cv2.moments(main_contour)\n",
    "        cX, cY = (int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])) if M[\"m00\"] != 0 else (1000,1000)\n",
    "        \n",
    "        mask_h, mask_w = 2000, 2000\n",
    "        temp_mask = np.zeros((mask_h, mask_w), dtype=np.uint8)\n",
    "        shift_x, shift_y = 1000-cX, 1000-cY\n",
    "        cv2.fillPoly(temp_mask, [main_contour + [shift_x, shift_y]], 255)\n",
    "        \n",
    "        kernel = np.ones((wall_offset_pixels*2+1, wall_offset_pixels*2+1), np.uint8)\n",
    "        eroded_mask = cv2.erode(temp_mask, kernel, iterations=1)\n",
    "        \n",
    "        inner_contours, _ = cv2.findContours(eroded_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        inner_void_contour = (max(inner_contours, key=cv2.contourArea) - [shift_x, shift_y]) if inner_contours else main_contour\n",
    "\n",
    "        # B. Resample & Smooth All Contours\n",
    "        N_POINTS = 500\n",
    "        c_base  = resample_contour(outer_contour, N_POINTS, smooth_factor=2.0) * scale_factor\n",
    "        c_helix = resample_contour(main_contour, N_POINTS, smooth_factor=0.5) * scale_factor\n",
    "        c_void  = resample_contour(inner_void_contour, N_POINTS, smooth_factor=0.5) * scale_factor\n",
    "        \n",
    "        # C. Build Mesh Layers\n",
    "        all_vertices, all_faces = [], []\n",
    "        \n",
    "        # Helper to add ring\n",
    "        def add_ring(contour, z_height):\n",
    "            start = len(all_vertices)\n",
    "            for p in contour: all_vertices.append([p[0], p[1], z_height])\n",
    "            return start\n",
    "\n",
    "        # Layer 1: Base Flange\n",
    "        idx_base_bot = add_ring(c_base, 0)\n",
    "        idx_base_top = add_ring(c_base, base_thickness)\n",
    "        idx_helix_bot = add_ring(c_helix, 0)\n",
    "        idx_helix_top = add_ring(c_helix, base_thickness)\n",
    "        \n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_base_bot, idx_helix_bot)) # Floor\n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_base_top, idx_helix_top)) # Ceiling\n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_base_bot, idx_base_top))  # Outer Wall\n",
    "        \n",
    "        # Layer 2: Helix Wall\n",
    "        total_h = base_thickness + helix_thickness\n",
    "        idx_helix_high = add_ring(c_helix, total_h)\n",
    "        idx_void_bot   = add_ring(c_void, 0)\n",
    "        idx_void_high  = add_ring(c_void, total_h)\n",
    "        \n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_helix_top, idx_helix_high)) # Outer Vert\n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_helix_high, idx_void_high)) # Top Rim\n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_void_high, idx_void_bot))   # Inner Vert\n",
    "        all_faces.extend(create_strip_faces(N_POINTS, idx_helix_bot, idx_void_bot))   # Bottom Seal\n",
    "\n",
    "        # Save\n",
    "        guide_mesh = mesh.Mesh(np.zeros(len(all_faces), dtype=mesh.Mesh.dtype))\n",
    "        for i, face in enumerate(all_faces):\n",
    "            for j in range(3): guide_mesh.vectors[i][j] = all_vertices[face[j]]\n",
    "        guide_mesh.save(output_path)\n",
    "        print(f\"   âœ… Smooth Hollow Guide saved: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_guide_visualization(original_mask, outer_contour, inner_contour, suture_points, output_path):\n",
    "    try:\n",
    "        vis = cv2.cvtColor(original_mask, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.drawContours(vis, [outer_contour], -1, (128,0,128), 3)\n",
    "        cv2.drawContours(vis, [inner_contour], -1, (0,255,255), 3)\n",
    "        for x,y in suture_points: cv2.rectangle(vis, (int(x)-8, int(y)-4), (int(x)+8, int(y)+4), (0,0,255), -1)\n",
    "        cv2.imwrite(output_path.replace('.stl', '_visualization.jpg'), vis)\n",
    "        return True\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccfa7aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Canny Edge Logic (Literature Based) Defined\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_cartilage_skeleton(image_path, binary_mask_path):\n",
    "    \"\"\"\n",
    "    Implements a 'Canny Edge' approach (common in literature) to find ear contours.\n",
    "    1. Uses the AI mask to isolate the ear.\n",
    "    2. Applies Canny Edge Detection to find the steep slopes of the cartilage.\n",
    "    3. Filters for the longest continuous curves (Helix and Anti-Helix).\n",
    "    \"\"\"\n",
    "    # 1. Load Original Image & Mask\n",
    "    img = cv2.imread(image_path)\n",
    "    mask = cv2.imread(binary_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None or mask is None: return None\n",
    "    \n",
    "    # 2. Preprocessing (Standard in literature)\n",
    "    # Mask the image to remove hair/background noise\n",
    "    ear_zone = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Convert to Grayscale\n",
    "    gray = cv2.cvtColor(ear_zone, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Histogram Equalization (CLAHE) to fix lighting differences\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Strong Gaussian Blur to ignore pores/skin texture\n",
    "    # We only want the major ridges\n",
    "    blurred = cv2.GaussianBlur(enhanced, (9, 9), 0)\n",
    "    \n",
    "    # 3. Canny Edge Detection (The Paper's Method)\n",
    "    # Finds the \"edges\" where the cartilage rises from the skin\n",
    "    # Thresholds: 30 (low) and 100 (high) are standard starting points for ears\n",
    "    edges = cv2.Canny(blurred, 30, 100)\n",
    "    \n",
    "    # 4. Post-Processing to Connect Gaps (Morphology)\n",
    "    # Dilate edges slightly to connect broken lines\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # 5. Contour Filtering (The \"Complex\" Extraction)\n",
    "    # We only want the BIG curves (Helix + Anti-Helix), not small noise\n",
    "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    clean_skeleton = np.zeros_like(mask)\n",
    "    \n",
    "    if contours:\n",
    "        # Sort contours by length (arcLength), longest first\n",
    "        sorted_cnts = sorted(contours, key=lambda x: cv2.arcLength(x, False), reverse=True)\n",
    "        \n",
    "        # Keep the Top 3 longest curves\n",
    "        # Usually: 1. Outer Helix, 2. Anti-Helix (Y-shape), 3. Tragus/Lobe\n",
    "        for i in range(min(5, len(sorted_cnts))):\n",
    "            cnt = sorted_cnts[i]\n",
    "            if cv2.contourArea(cnt) > 50 or cv2.arcLength(cnt, False) > 100:\n",
    "                # Draw thick lines to ensure 3D printer wall thickness\n",
    "                cv2.drawContours(clean_skeleton, [cnt], -1, 255, thickness=15) \n",
    "                \n",
    "    # 6. Merge with Outer Frame\n",
    "    # We always need the outer solid shape (Base Plate) + The new Inner Skeleton\n",
    "    # Convert original mask to a simple outline\n",
    "    outer_contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if outer_contours:\n",
    "        main_blob = max(outer_contours, key=cv2.contourArea)\n",
    "        # Draw the base plate outline\n",
    "        cv2.drawContours(clean_skeleton, [main_blob], -1, 255, thickness=10)\n",
    "        \n",
    "    # Final close to ensure watertightness\n",
    "    clean_skeleton = cv2.morphologyEx(clean_skeleton, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    return clean_skeleton\n",
    "\n",
    "print(\"âœ… Canny Edge Logic (Literature Based) Defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dbcfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_microtia_guide(image_path, output_dir=\"surgical_guides\", conf=0.3):\n",
    "    \"\"\"Pipeline: Image -> Ridge Skeleton -> Hollow Guide + Suture Holes\"\"\"\n",
    "    \n",
    "    # Init Model\n",
    "    model_path = r\"A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\"\n",
    "    guide_generator = MicrotiaSurgicalGuide(model_path)\n",
    "    if guide_generator.yolo_model is None: return None\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = Path(image_path).stem\n",
    "    print(f\"\\nğŸ¯ PROCESSING: {base_name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Segmentation (Get the Blob)\n",
    "    hybrid_mask = guide_generator.yolo_sam_hybrid_segment(image_path, conf=conf)\n",
    "    if hybrid_mask is None: return None\n",
    "    \n",
    "    blob_mask_path = os.path.join(output_dir, f\"{base_name}_blob_mask.png\")\n",
    "    cv2.imwrite(blob_mask_path, hybrid_mask)\n",
    "    \n",
    "    # 2. RIDGE DETECTION (The Fix for 'Completely Different')\n",
    "    # Use the blob mask + original image to find the skeleton\n",
    "    skeleton_mask = extract_cartilage_skeleton(image_path, blob_mask_path)\n",
    "    \n",
    "    if skeleton_mask is None:\n",
    "        print(\"âš ï¸ Ridge detection failed, falling back to blob.\")\n",
    "        skeleton_mask = guide_generator.preprocess_mask(hybrid_mask)\n",
    "    \n",
    "    # Save the skeleton mask so you can verify it matches the reference photo\n",
    "    skel_path = os.path.join(output_dir, f\"{base_name}_skeleton_mask.png\")\n",
    "    cv2.imwrite(skel_path, skeleton_mask)\n",
    "    print(f\"   ğŸ’€ Skeleton Mask generated (Check {skel_path})\")\n",
    "\n",
    "    # 3. Contours (Using the new Skeleton Mask)\n",
    "    # We process the skeleton mask to smooth it out\n",
    "    processed_mask = guide_generator.preprocess_mask(skeleton_mask)\n",
    "    \n",
    "    outer_contour, inner_contour = guide_generator.create_contours_with_tolerance(\n",
    "        processed_mask, guide_generator.skin_tolerance, pixels_per_mm=10\n",
    "    )\n",
    "    if outer_contour is None: return None\n",
    "    \n",
    "    # 4. Centerline & Suture Points\n",
    "    pixels_per_mm = 10\n",
    "    half_wall_pixels = int(1.5 * pixels_per_mm)\n",
    "    \n",
    "    temp_mask = np.zeros_like(processed_mask)\n",
    "    M = cv2.moments(inner_contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX, cY = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "        shift_x, shift_y = temp_mask.shape[1]//2 - cX, temp_mask.shape[0]//2 - cY\n",
    "        shifted_contour = inner_contour + [shift_x, shift_y]\n",
    "        \n",
    "        temp_canvas = np.zeros_like(processed_mask)\n",
    "        cv2.fillPoly(temp_canvas, [shifted_contour], 255)\n",
    "        kernel = np.ones((half_wall_pixels*2+1, half_wall_pixels*2+1), np.uint8)\n",
    "        eroded_canvas = cv2.erode(temp_canvas, kernel, iterations=1)\n",
    "        mid_contours, _ = cv2.findContours(eroded_canvas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        centerline_contour = (max(mid_contours, key=cv2.contourArea) - [shift_x, shift_y]) if mid_contours else inner_contour\n",
    "    else:\n",
    "        centerline_contour = inner_contour\n",
    "\n",
    "    suture_points = guide_generator.find_curvature_points(centerline_contour)\n",
    "    \n",
    "    # 5. Generate Outputs\n",
    "    guide_path = os.path.join(output_dir, f\"{base_name}_microtia_guide.stl\")\n",
    "    holes_path = os.path.join(output_dir, f\"{base_name}_suture_holes.stl\")\n",
    "    \n",
    "    # Visualization\n",
    "    try:\n",
    "        vis_img = cv2.cvtColor(processed_mask, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.drawContours(vis_img, [outer_contour], -1, (128,0,128), 2)\n",
    "        cv2.drawContours(vis_img, [inner_contour], -1, (0,255,255), 2)\n",
    "        cv2.drawContours(vis_img, [centerline_contour], -1, (255,255,0), 1)\n",
    "        for x,y in suture_points: cv2.rectangle(vis_img, (int(x)-6, int(y)-3), (int(x)+6, int(y)+3), (0,0,255), -1)\n",
    "        cv2.imwrite(guide_path.replace('.stl', '_visualization.jpg'), vis_img)\n",
    "        vis_success = True\n",
    "    except: vis_success = False\n",
    "    \n",
    "    # 3D Models\n",
    "    model_success = False\n",
    "    if 'STL_AVAILABLE' in globals() and STL_AVAILABLE:\n",
    "        model_success = create_hollow_guide_model(\n",
    "            outer_contour,      \n",
    "            inner_contour,      \n",
    "            guide_path,\n",
    "            base_thickness=2.0,\n",
    "            helix_thickness=5.0,\n",
    "            wall_width_mm=3.0\n",
    "        )\n",
    "        if model_success:\n",
    "            create_suture_holes_stl(suture_points, holes_path)\n",
    "\n",
    "    result = {\n",
    "        'success': vis_success or model_success,\n",
    "        'image_name': base_name,\n",
    "        'mask_path': skel_path,\n",
    "        'guide_path': guide_path,\n",
    "        'holes_path': holes_path,\n",
    "        'suture_points': len(suture_points),\n",
    "        'segmentation_method': 'YOLO+SAM Hybrid (Skeleton Mode)'\n",
    "    }\n",
    "    \n",
    "    if model_success:\n",
    "        print(f\"   âœ¨ Guide: {guide_path}\")\n",
    "        print(f\"   âœ¨ Holes: {holes_path}\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c17b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Found 5 images\n",
      "ğŸš€ Starting batch processing with YOLO+SAM hybrid...\n",
      "\n",
      "============================================================\n",
      "ğŸ“¸ Processing 1/5: 2D EAR 1.jpg\n",
      "============================================================\n",
      "âœ… YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "ğŸ“ Found existing SAM checkpoint: sam_checkpoints\\sam_vit_b.pth\n",
      "âœ… SAM model loaded (vit_b) on cuda\n",
      "\n",
      "ğŸ¯ PROCESSING: 2D EAR 1\n",
      "==================================================\n",
      "   ğŸ” Running YOLO+SAM hybrid segmentation...\n",
      "   ğŸ“¦ YOLO detected ear with bbox: [     496.27      291.01      1226.2      1141.4]\n",
      "   âœ… SAM: Generated high-quality mask (score: 0.838)\n",
      "   ğŸ’€ Skeleton Mask generated (Check surgical_guides\\2D EAR 1_skeleton_mask.png)\n",
      "   ğŸ“ Generating SMOOTH HOLLOW guide...\n",
      "   âœ… Smooth Hollow Guide saved: surgical_guides\\2D EAR 1_microtia_guide.stl\n",
      "   ğŸ•³ï¸ Generating Suture Hole Cutters (2 holes)...\n",
      "   âœ¨ Guide: surgical_guides\\2D EAR 1_microtia_guide.stl\n",
      "   âœ¨ Holes: surgical_guides\\2D EAR 1_suture_holes.stl\n",
      "   âœ… SUCCESS\n",
      "   Method: YOLO+SAM Hybrid (Skeleton Mode)\n",
      "   Suture points: 2\n",
      "   3D Guide: âœ… Generated\n",
      "\n",
      "============================================================\n",
      "ğŸ“¸ Processing 2/5: 2D EAR 2.jpg\n",
      "============================================================\n",
      "âœ… YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "ğŸ“ Found existing SAM checkpoint: sam_checkpoints\\sam_vit_b.pth\n",
      "âœ… SAM model loaded (vit_b) on cuda\n",
      "\n",
      "ğŸ¯ PROCESSING: 2D EAR 2\n",
      "==================================================\n",
      "   ğŸ” Running YOLO+SAM hybrid segmentation...\n",
      "   ğŸ“¦ YOLO detected ear with bbox: [      367.1      58.573      703.82      594.86]\n",
      "   âœ… SAM: Generated high-quality mask (score: 0.920)\n",
      "   ğŸ’€ Skeleton Mask generated (Check surgical_guides\\2D EAR 2_skeleton_mask.png)\n",
      "   ğŸ“ Generating SMOOTH HOLLOW guide...\n",
      "   âœ… Smooth Hollow Guide saved: surgical_guides\\2D EAR 2_microtia_guide.stl\n",
      "   ğŸ•³ï¸ Generating Suture Hole Cutters (2 holes)...\n",
      "   âœ¨ Guide: surgical_guides\\2D EAR 2_microtia_guide.stl\n",
      "   âœ¨ Holes: surgical_guides\\2D EAR 2_suture_holes.stl\n",
      "   âœ… SUCCESS\n",
      "   Method: YOLO+SAM Hybrid (Skeleton Mode)\n",
      "   Suture points: 2\n",
      "   3D Guide: âœ… Generated\n",
      "\n",
      "============================================================\n",
      "ğŸ“¸ Processing 3/5: 2D EAR 3.jpg\n",
      "============================================================\n",
      "âœ… YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "ğŸ“ Found existing SAM checkpoint: sam_checkpoints\\sam_vit_b.pth\n",
      "âœ… SAM model loaded (vit_b) on cuda\n",
      "\n",
      "ğŸ¯ PROCESSING: 2D EAR 3\n",
      "==================================================\n",
      "   ğŸ” Running YOLO+SAM hybrid segmentation...\n",
      "   ğŸ“¦ YOLO detected ear with bbox: [     131.34       32.75      212.06      140.69]\n",
      "   âœ… SAM: Generated high-quality mask (score: 0.983)\n",
      "   ğŸ’€ Skeleton Mask generated (Check surgical_guides\\2D EAR 3_skeleton_mask.png)\n",
      "   ğŸ“ Generating SMOOTH HOLLOW guide...\n",
      "   âœ… Smooth Hollow Guide saved: surgical_guides\\2D EAR 3_microtia_guide.stl\n",
      "   ğŸ•³ï¸ Generating Suture Hole Cutters (2 holes)...\n",
      "   âœ¨ Guide: surgical_guides\\2D EAR 3_microtia_guide.stl\n",
      "   âœ¨ Holes: surgical_guides\\2D EAR 3_suture_holes.stl\n",
      "   âœ… SUCCESS\n",
      "   Method: YOLO+SAM Hybrid (Skeleton Mode)\n",
      "   Suture points: 2\n",
      "   3D Guide: âœ… Generated\n",
      "\n",
      "============================================================\n",
      "ğŸ“¸ Processing 4/5: 2D EAR 4.jpg\n",
      "============================================================\n",
      "âœ… YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "ğŸ“ Found existing SAM checkpoint: sam_checkpoints\\sam_vit_b.pth\n",
      "âœ… SAM model loaded (vit_b) on cuda\n",
      "\n",
      "ğŸ¯ PROCESSING: 2D EAR 4\n",
      "==================================================\n",
      "   ğŸ” Running YOLO+SAM hybrid segmentation...\n",
      "   ğŸ“¦ YOLO detected ear with bbox: [     842.25      25.892      1157.1      614.91]\n",
      "   âœ… SAM: Generated high-quality mask (score: 0.968)\n",
      "   ğŸ’€ Skeleton Mask generated (Check surgical_guides\\2D EAR 4_skeleton_mask.png)\n",
      "   ğŸ“ Generating SMOOTH HOLLOW guide...\n",
      "   âœ… Smooth Hollow Guide saved: surgical_guides\\2D EAR 4_microtia_guide.stl\n",
      "   ğŸ•³ï¸ Generating Suture Hole Cutters (2 holes)...\n",
      "   âœ¨ Guide: surgical_guides\\2D EAR 4_microtia_guide.stl\n",
      "   âœ¨ Holes: surgical_guides\\2D EAR 4_suture_holes.stl\n",
      "   âœ… SUCCESS\n",
      "   Method: YOLO+SAM Hybrid (Skeleton Mode)\n",
      "   Suture points: 2\n",
      "   3D Guide: âœ… Generated\n",
      "\n",
      "============================================================\n",
      "ğŸ“¸ Processing 5/5: 2D EAR 5.jpg\n",
      "============================================================\n",
      "âœ… YOLO model loaded: A:\\PROJECT\\AUTO MICROTIA\\Ear-segmentation-ai\\ear_segmentation\\models\\best_v4.pt\n",
      "ğŸ“ Found existing SAM checkpoint: sam_checkpoints\\sam_vit_b.pth\n",
      "âœ… SAM model loaded (vit_b) on cuda\n",
      "\n",
      "ğŸ¯ PROCESSING: 2D EAR 5\n",
      "==================================================\n",
      "   ğŸ” Running YOLO+SAM hybrid segmentation...\n",
      "   ğŸ“¦ YOLO detected ear with bbox: [     92.444      8.4654      171.51      128.26]\n",
      "   âœ… SAM: Generated high-quality mask (score: 0.992)\n",
      "   ğŸ’€ Skeleton Mask generated (Check surgical_guides\\2D EAR 5_skeleton_mask.png)\n",
      "   ğŸ“ Generating SMOOTH HOLLOW guide...\n",
      "   âœ… Smooth Hollow Guide saved: surgical_guides\\2D EAR 5_microtia_guide.stl\n",
      "   ğŸ•³ï¸ Generating Suture Hole Cutters (2 holes)...\n",
      "   âœ¨ Guide: surgical_guides\\2D EAR 5_microtia_guide.stl\n",
      "   âœ¨ Holes: surgical_guides\\2D EAR 5_suture_holes.stl\n",
      "   âœ… SUCCESS\n",
      "   Method: YOLO+SAM Hybrid (Skeleton Mode)\n",
      "   Suture points: 2\n",
      "   3D Guide: âœ… Generated\n",
      "\n",
      "ğŸ¯ BATCH PROCESSING COMPLETE!\n",
      "ğŸ“Š Results: 5/5 successful guides\n",
      "ğŸ“ Output folder: surgical_guides\n"
     ]
    }
   ],
   "source": [
    "def batch_process_with_comparison(input_dir=\"input\", output_dir=\"surgical_guides\", max_images=None):\n",
    "    \"\"\"Process all images and compare YOLO vs YOLO+SAM results\"\"\"\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"âŒ Input directory not found: {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(input_dir, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(input_dir, \"*.png\")) + \\\n",
    "                  glob.glob(os.path.join(input_dir, \"*.jpeg\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"âŒ No images found in {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    if max_images:\n",
    "        image_files = image_files[:max_images]\n",
    "    \n",
    "    print(f\"ğŸ” Found {len(image_files)} images\")\n",
    "    print(\"ğŸš€ Starting batch processing with YOLO+SAM hybrid...\")\n",
    "    \n",
    "    results = []\n",
    "    successful_guides = 0\n",
    "    \n",
    "    for i, img_path in enumerate(image_files):\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(f\"ğŸ“¸ Processing {i+1}/{len(image_files)}: {Path(img_path).name}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        result = create_microtia_guide(img_path, output_dir)\n",
    "        \n",
    "        if result and result['success']:\n",
    "            successful_guides += 1\n",
    "            status = \"âœ… SUCCESS\"\n",
    "        else:\n",
    "            status = \"âŒ FAILED\"\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   {status}\")\n",
    "            print(f\"   Method: {result['segmentation_method']}\")\n",
    "            print(f\"   Suture points: {result['suture_points']}\")\n",
    "            if result['guide_path']:\n",
    "                print(f\"   3D Guide: âœ… Generated\")\n",
    "            else:\n",
    "                print(f\"   3D Guide: âŒ Not generated\")\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nğŸ¯ BATCH PROCESSING COMPLETE!\")\n",
    "    print(f\"ğŸ“Š Results: {successful_guides}/{len(image_files)} successful guides\")\n",
    "    print(f\"ğŸ“ Output folder: {output_dir}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the batch processing\n",
    "results = batch_process_with_comparison(\n",
    "    input_dir=\"input\",\n",
    "    output_dir=\"surgical_guides\",\n",
    "    max_images=None  # Process all images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a269a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No processed masks found. Please run the generation pipeline first.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def generate_surgical_reference_card(image_path, mask_path, output_path):\n",
    "    \"\"\"\n",
    "    Generates a 'Djoko Kuswanto Style' Surgical Planning Card.\n",
    "    Robustly handles mask loading to prevent shape errors.\n",
    "    \"\"\"\n",
    "    # 1. Load Image and Mask\n",
    "    img = cv2.imread(image_path)\n",
    "    # Load mask as-is first, then convert carefully\n",
    "    mask = cv2.imread(mask_path)\n",
    "    \n",
    "    if img is None or mask is None:\n",
    "        print(f\"âŒ Error loading files.\\nImg: {image_path}\\nMask: {mask_path}\")\n",
    "        return\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # --- FIX FOR \"TOO MANY VALUES TO UNPACK\" ---\n",
    "    # Ensure mask is strictly 1-channel Grayscale\n",
    "    if len(mask.shape) == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Now this will work safely because shape is guaranteed to be (h, w)\n",
    "    h, w = mask.shape\n",
    "    # -------------------------------------------\n",
    "\n",
    "    # 2. Extract Edges (The Rib Framework Outline)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours: \n",
    "        print(\"âŒ No contours found in mask.\")\n",
    "        return\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Create a blank canvas for the template\n",
    "    template = np.ones((h, w, 3), dtype=np.uint8) * 255 # White background\n",
    "    \n",
    "    # Draw the Base Plate (Gray) - Represents the 6th/7th Rib Base\n",
    "    cv2.drawContours(template, [main_contour], -1, (220, 220, 220), -1)\n",
    "    cv2.drawContours(template, [main_contour], -1, (50, 50, 50), 2)\n",
    "    \n",
    "    # 3. IDENTIFY ANATOMICAL ZONES (The \"Y\" Shape)\n",
    "    # We erode the mask deeply to find the \"Core\" (Anti-helix area)\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    eroded = cv2.erode(mask, kernel, iterations=4)\n",
    "    core_contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    annotated_img = template.copy()\n",
    "    \n",
    "    suture_targets = []\n",
    "    \n",
    "    # Draw The \"Relief\" (8th Rib Piece) - The Anti-Helix\n",
    "    if core_contours:\n",
    "        core_cnt = max(core_contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(annotated_img, [core_cnt], -1, (255, 200, 200), -1) # Light Blue/Red fill\n",
    "        cv2.drawContours(annotated_img, [core_cnt], -1, (255, 0, 0), 2)     # Blue Outline\n",
    "        \n",
    "        # Calculate centroids for hole placement\n",
    "        # Top of the Y (Superior Crus)\n",
    "        try:\n",
    "            top_y_idx = core_cnt[:,:,1].argmin()\n",
    "            top_y = tuple(core_cnt[top_y_idx][0])\n",
    "            suture_targets.append((top_y, \"Superior Crus\\n(Anchor 1)\"))\n",
    "        except: pass\n",
    "        \n",
    "        # Middle of Y (Anti-Helix Body)\n",
    "        M = cv2.moments(core_cnt)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "            suture_targets.append(((cx, cy), \"Anti-Helix Body\\n(Anchor 2)\"))\n",
    "            \n",
    "        # Bottom Tail\n",
    "        try:\n",
    "            bot_y_idx = core_cnt[:,:,1].argmax()\n",
    "            bot_y = tuple(core_cnt[bot_y_idx][0])\n",
    "            suture_targets.append((bot_y, \"Cauda Helix\\n(Anchor 3)\"))\n",
    "        except: pass\n",
    "\n",
    "    # 4. PLOT THE REFERENCE CARD\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Background Grid\n",
    "    plt.imshow(annotated_img)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # Plot Suture Targets\n",
    "    for (x, y), label in suture_targets:\n",
    "        plt.scatter(x, y, c='red', s=150, edgecolors='white', linewidth=2, zorder=5)\n",
    "        plt.text(x + 20, y, label, color='darkred', fontsize=10, fontweight='bold',\n",
    "                 bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "    # Plot Outer Helix Anchors (Manually estimated from contour)\n",
    "    try:\n",
    "        outer_points = main_contour[:, 0, :]\n",
    "        right_idx = outer_points[:, 0].argmax()\n",
    "        rx, ry = outer_points[right_idx]\n",
    "        \n",
    "        plt.scatter(rx - 30, ry, c='green', s=150, edgecolors='white', linewidth=2, zorder=5)\n",
    "        plt.text(rx, ry, \"Helix Rim\\n(Stabilizer)\", color='darkgreen', fontsize=10, fontweight='bold',\n",
    "                 bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "    except: pass\n",
    "\n",
    "    # Titles and Legends\n",
    "    plt.title(\"SURGICAL PRE-OPERATIVE PLAN: SUTURE FIXATION MAP\", fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Grid Scale: 10px (~1mm)\", fontsize=8)\n",
    "    \n",
    "    textstr = '\\n'.join((\n",
    "        r'$\\bf{Technique:}$ Nagata 2-Stage',\n",
    "        r'$\\bf{Red\\ Zone:}$ 8th Rib (Anti-Helix)',\n",
    "        r'$\\bf{Gray\\ Zone:}$ 6th/7th Rib (Base)',\n",
    "        r'$\\bf{Dots:}$ Recommended Wire Points'\n",
    "    ))\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Save\n",
    "    print(f\"   ğŸ’¾ Saving Surgical Reference Card: {output_path}\")\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# --- EXECUTE ---\n",
    "processed_masks = glob.glob(\"surgical_guides/*_segmentation_mask.png\")\n",
    "original_images = glob.glob(\"input/*.jpg\") + glob.glob(\"input/*.png\")\n",
    "\n",
    "if processed_masks:\n",
    "    mask_file = processed_masks[0]\n",
    "    # Simple matching strategy\n",
    "    base_name = Path(mask_file).name.replace(\"_segmentation_mask.png\", \"\")\n",
    "    \n",
    "    # Try to find matching image\n",
    "    matching_inputs = [f for f in original_images if base_name in f]\n",
    "    \n",
    "    if matching_inputs:\n",
    "        img_file = matching_inputs[0]\n",
    "        output_png = os.path.join(\"surgical_guides\", f\"{base_name}_SURGICAL_PLAN.png\")\n",
    "        generate_surgical_reference_card(img_file, mask_file, output_png)\n",
    "    else:\n",
    "        # Fallback: Just use the first image available if name match fails\n",
    "        if original_images:\n",
    "            print(f\"âš ï¸ Exact name match not found. Using {original_images[0]} as reference background.\")\n",
    "            output_png = os.path.join(\"surgical_guides\", f\"{base_name}_SURGICAL_PLAN.png\")\n",
    "            generate_surgical_reference_card(original_images[0], mask_file, output_png)\n",
    "else:\n",
    "    print(\"âŒ No processed masks found. Please run the generation pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ace2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š COMPREHENSIVE SUMMARY\n",
      "========================================\n",
      "Total images processed: 5\n",
      "Successful guides: 5\n",
      "Success rate: 100.0%\n",
      "Summary file: surgical_guides\\processing_summary.csv\n",
      "3D STL files generated: 10\n",
      "\n",
      "âœ… PROCESSING SUCCESSFUL!\n",
      "ğŸ’¡ Check the 'surgical_guides' folder for:\n",
      "   - Segmentation masks\n",
      "   - 3D surgical guide STL files\n",
      "   - Guide visualizations\n",
      "   - Processing summary\n",
      "\n",
      "ğŸ‰ MICROTIA SURGICAL GUIDE GENERATION COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "def generate_processing_summary(results, output_dir=\"surgical_guides\"):\n",
    "    \"\"\"Generate comprehensive processing summary\"\"\"\n",
    "    import csv\n",
    "    from datetime import datetime\n",
    "    \n",
    "    summary_path = os.path.join(output_dir, \"processing_summary.csv\")\n",
    "    \n",
    "    # Collect statistics\n",
    "    successful_guides = sum(1 for r in results if r and r['success'])\n",
    "    total_images = len(results)\n",
    "    \n",
    "    # Write CSV summary\n",
    "    with open(summary_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Image', 'Status', 'Method', 'Suture_Points', '3D_Guide', 'Mask_Generated'])\n",
    "        \n",
    "        for result in results:\n",
    "            if result:\n",
    "                writer.writerow([\n",
    "                    result['image_name'],\n",
    "                    'SUCCESS' if result['success'] else 'FAILED',\n",
    "                    result['segmentation_method'],\n",
    "                    result['suture_points'],\n",
    "                    'YES' if result['guide_path'] else 'NO',\n",
    "                    'YES' if result['mask_path'] else 'NO'\n",
    "                ])\n",
    "            else:\n",
    "                writer.writerow(['Unknown', 'FAILED', 'Unknown', 0, 'NO', 'NO'])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nğŸ“Š COMPREHENSIVE SUMMARY\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Successful guides: {successful_guides}\")\n",
    "    print(f\"Success rate: {(successful_guides/total_images)*100:.1f}%\" if total_images > 0 else \"0%\")\n",
    "    print(f\"Summary file: {summary_path}\")\n",
    "    \n",
    "    # Check STL files\n",
    "    stl_files = glob.glob(os.path.join(output_dir, \"*.stl\"))\n",
    "    print(f\"3D STL files generated: {len(stl_files)}\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    if successful_guides > 0:\n",
    "        print(f\"\\nâœ… PROCESSING SUCCESSFUL!\")\n",
    "        print(\"ğŸ’¡ Check the 'surgical_guides' folder for:\")\n",
    "        print(\"   - Segmentation masks\")\n",
    "        print(\"   - 3D surgical guide STL files\")\n",
    "        print(\"   - Guide visualizations\")\n",
    "        print(\"   - Processing summary\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ PROCESSING FAILED\")\n",
    "        print(\"ğŸ’¡ Check the error messages above for troubleshooting\")\n",
    "    \n",
    "    return summary_path\n",
    "\n",
    "# Generate summary\n",
    "if results:\n",
    "    summary_file = generate_processing_summary(results)\n",
    "    print(f\"\\nğŸ‰ MICROTIA SURGICAL GUIDE GENERATION COMPLETED!\")\n",
    "else:\n",
    "    print(\"âŒ No results to summarize\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ear_seg_env.venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
